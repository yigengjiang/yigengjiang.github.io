[{"content":"Abstract This proposal presents a complete architecture toward Artificial General Intelligence (AGI). The architecture is built upon a core epistemological assumption: â€œThe predictive power of the forward dynamics model is equivalent to the ability to understand the physical world.â€ Based on this, we construct a recursive evolutionary system where: 1) The base agent internalizes environmental regularities by training a high-fidelity forward model (i.e., world model); 2) Intrinsic motivation acts as the â€œcognitive gradientâ€ of the world model, driving the agent to actively explore unknown domains to patch model deficiencies; 3) Recursive Meta-Architectural Search (RMAS) optimizes neural network topology through generational evolution to emerge stronger world simulation capabilities. This system aims to achieve a cognitive leap from â€œpassive adaptationâ€ to â€œactive simulation and planning.â€ 1. Theoretical Axiom: Forward Model Equivalence Before defining the specific architecture, we first establish the core axiom of this system: Axiom $H_{equiv}$: The Agent is the World Model A complete agent must possess an internal function $f_{world}$ that can accurately predict the future state $s_{t+1}$ based on the current state $s_t$ and action $a_t$. $$s_{t+1} \\approx f_{world}(s_t, a_t; \\theta)$$ Corollary A (Simulation): If $f_{world}$ is sufficiently accurate, the agent can perform counterfactual reasoning in its â€œmind,â€ i.e., â€œsimulation.â€ Corollary B (Understanding): The prediction error $\\mathcal{L}_{pred} = \\Vert f_{world}(s_t, a_t) - s_{t+1} \\Vert$ is the only objective metric for measuring the agentâ€™s â€œunderstanding.â€ Understanding is compression. Prediction is decompression. 2. Core Architecture Components 2.1 World Model To avoid ineffective prediction in high-dimensional pixel space (addressing the â€œTV noiseâ€ problem raised by Yann LeCun), our world model is built upon latent space. This module contains three coupled neural networks: Feature Encoder (Inverse Model): Filters uncontrollable noise. By solving the inverse dynamics problem $\\hat{a}_t = g(\\phi(s_t), \\phi(s_{t+1}))$, it extracts causally-relevant features $\\phi(s)$. Tells the agent â€œwhat is worth paying attention to.â€ Forward Dynamics Core: This is the world model itself. $$\\hat{\\phi}_{t+1} = f_{forward}(\\phi(s_t), a_t; \\theta_{world})$$ Simulates physical laws, social rules, and logical causality. Prediction Head: Maps latent states back to predicted outcomes (used for computing rewards). 2.2 Curiosity In this architecture, curiosity is no longer just about â€œgetting more points,â€ but about â€œpatching the world model.â€ Mechanism: The agent actively seeks states where $f_{forward}$ prediction fails. Intrinsic Reward: $r_{intrinsic} \\propto \\Vert \\hat{\\phi}_{t+1} - \\phi_{t+1} \\Vert^2$. Philosophical Meaning: True learning only occurs when reality violates the modelâ€™s predictions (i.e., feeling â€œsurprisedâ€). This drive causes the agent to experiment like a scientist even without external tasks, to refine its internal physics model. 2.3 Memory The world model needs to predict not only $t+1$ but also $t+N$. To support long-range dependencies: We introduce Memory $\\mathcal{M}$. Memory matrix $\\mathcal{M}$ stores the â€œlong-term contextâ€ of the world model, transforming the forward model $f_{forward}$ into $s_{t+1} \\approx f(s_t, a_t, \\mathcal{M}_t)$, enabling it to handle non-Markovian environments (POMDPs). 2.4 Recursive Meta-Agent Search Controlled by meta-agent $\\Pi_\\Phi$ (Architect). Objective: Not to directly maximize task rewards, but to maximize the sub-agentâ€™s â€œworld modeling efficiencyâ€ (i.e., achieving the lowest prediction error with the fewest samples). Evolution: The meta-agent continuously rewrites the base agentâ€™s neural network architecture (e.g., number of layers, attention mechanism types) to evolve a â€œbrainâ€ that can more efficiently simulate complex physical laws. 3. Algorithm Pseudocode This pseudocode demonstrates how the relationship between all the compontents. # Algorithm: RMAS with Generative World Models def RMAS_World_Model_System(): # Meta-Agent: The Architect of Intelligence Meta_Architect = Initialize_Policy() # --- OUTER LOOP: Evolution of Cognitive Architecture --- while not Singularity_Reached: # 1. Design Phase: Generate a Brain Structure optimized for World Modeling # Topology determines the capacity of the Forward Model Brain_Topology, Theta_init = Meta_Architect.generate_design() # 2. Simulation Phase: Evaluate Intelligence in Objective Reality fitness, prediction_fidelity = Simulate_Cognition(Brain_Topology, Theta_init) # 3. Meta-Update: Survival of the \"Most Predictive\" # We favor architectures that can better predict (understand) the world Meta_Architect.update_strategy(fitness, prediction_fidelity) # 4. Curriculum: Increase World Complexity if prediction_fidelity \u003e High_Fidelity_Threshold: World.unlock_quantum_mechanics_level() # Example of complexity jump def Simulate_Cognition(Topology, Theta): # Instantiate the agent Agent = Build_Agent(Topology, Theta) # [The Core]: The Forward Model IS the World Model # It predicts the future state features given current state and action World_Model = Instantiate_Forward_Model(Topology) # [The Filter]: Inverse Model to ignore noise (LeCun's JEPA style) Feature_Encoder = Instantiate_Inverse_Model(Topology) Memory = Initialize_Memory() s_t = Environment.reset() total_reward = 0 avg_prediction_error = 0 while Agent.is_alive(): # A. Perception \u0026 Context Retrieval context = Memory.read(s_t) # B. Imagination/Planning (Optional step for Model-Based RL) # Agent can use World_Model to simulate 5 steps into the future before acting # imagined_future = World_Model.rollout(s_t, context, candidate_actions) # action = choose_best(imagined_future) # For Model-Free + Curiosity (Simpler version): action = Agent.policy(s_t, context) # C. Interaction s_next, r_ext = Environment.step(action) # D. World Model Validation (The \"Understanding\" Step) # 1. Encode Reality: Get latent features of s_t and s_next phi_t = Feature_Encoder(s_t) phi_next = Feature_Encoder(s_next) # 2. Predict Reality: What did the World Model think would happen? phi_next_pred = World_Model.forward(phi_t, action, context) # 3. Measure Surprise (Prediction Error) # Low Error = Understanding; High Error = Ignorance (or Hallucination) surprise = MSE_Loss(phi_next_pred, phi_next) # E. Intrinsic Motivation Calculation # The agent gets a dopamine hit for being \"surprised\" (learning opportunity) # BUT the long-term goal is to minimize this surprise (mastery) r_int = Calculate_Curiosity(surprise) # F. Update Synapses (Learning) # 1. Improve Policy (to get more reward) Agent.update_policy(r_ext + Lambda * r_int) # 2. Improve World Model (to better understand physics) # This is Self-Supervised Learning: The world provides the labels World_Model.update(loss=surprise) Feature_Encoder.update(s_t, s_next, action) # Update state Memory.write(s_t, action, context) s_t = s_next total_reward += r_ext avg_prediction_error += surprise.item() # Return fitness AND how well the agent understood the world return total_reward, 1.0 / (avg_prediction_error + epsilon) 4. Conclusion This proposal presents a complete path toward AGI by combining four essential components: World Models (to understand causality), Curiosity (to drive exploration), Memory (to handle long-term context), and Meta-Agent Architecture (to recursively improve learning). When placed in a rich simulated environment, an agent with these capabilities can achieve human-level learning through experience alone. However, before reaching the singularity, safety must come first. I think AI-Human Co Improve is more important. The goal is not AI that replaces humanity, but AI that learns together with us, augmenting human capability while preserving safety and shared purpose. References LeCun, Y. (2022). â€œA Path Towards Autonomous Machine Intelligence.â€ OpenReview, Version 0.9.2. https://openreview.net/forum?id=BZ5a1r-kVsf Yann LeCunâ€™s Joint-Embedding Predictive Architecture (JEPA), proposing that world models should operate in abstract representation space to avoid predicting irrelevant details. Richens, J., Abel, D., Bellot, A., \u0026 Everitt, T. (2025). â€œGeneral Agents Contain World Models.â€ arXiv preprint arXiv:2506.01622. https://arxiv.org/abs/2506.01622 Formally proves that any agent capable of generalizing to multi-step goal-directed tasks must have learned a predictive model of its environment, even if implicitly. Sutton, R. S. (2025). â€œThe Oak Architecture: A Vision of SuperIntelligence from Experience.â€ Reinforcement Learning Conference (RLC) 2025. https://www.youtube.com/watch?v=gEbbGyNkR2U Proposes the Oak architecture, a model-based RL system where all components learn continually, using the FC-STOMP progression: Feature Construction, SubTask, Option, Model, and Planning to build abstractions in state and time. ","title":"World Model, Curiosity and Meta Learning","uri":"/posts/how_to_agi/"},{"content":" Part I: Introduction This argument aims to explore whether non-biological substrates (i.e., â€œartificial substratesâ€) can theoretically completely replace biological substrates (humans), thereby realizing all human functions. Before developing a formal proof, we must first clarify two opposing physical/philosophical paradigms regarding the â€œnature of consciousness and intelligence,â€ which will determine the axiomatic foundation of this argument.\n1.1 The Turing Machine Paradigm This paradigm supports the Computational Theory of Mind.\nCore Assumption: The brain is essentially an extremely complex information processing system. Biological neurons are logic gates, synaptic connections are state storage, and consciousness is algorithmic software running on wetware. Inference: According to the Church-Turing Thesis, any computable process can be simulated by a Universal Turing Machine. Support for this Argument: If the brain is a Turing machine, then Substrate Independence holds. Silicon-based chips can perfectly replace carbon-based neurons as long as they can execute the same logical operations. 1.2 The Microtubule Quantum Paradigm This paradigm, proposed by Roger Penrose and others, represents the non-computable view under physicalism.\nCore Assumption: The brain is not merely a computer; microtubules inside neurons utilize quantum coherence and wave function collapse (Orch-OR) to generate consciousness. Inference: Human thinking contains GÃ¶delian â€œnon-algorithmicâ€ components that classical Turing machines cannot simulate, such as insights or intuitions arising from quantum collapse. Challenge: If this paradigm is true, purely classical computation cannot reproduce human intelligence. 1.3 Transition to Argument To advance this argument, we need not completely disprove the microtubule quantum effect; we only need to introduce the more general Church-Turing-Deutsch Principle:\nâ€œAny finite physical process can be perfectly simulated by a universal quantum computer.â€\nTherefore, this argument proceeds from the following position: Whether the brain is a classical neural network or a quantum microtubule system, it is ultimately a physical system. As long as artificial substrates (whether silicon-based chips or future quantum processors) can simulate this physical process, replacement becomes possible.\nPart II: Formal Argumentation System 2.1 Definitions Let $H$ be the set of human cognitive and physical functions. Let $N_{bio}$ be the set of biological neurons in a human brain, where $|N_{bio}| \\approx 86 \\times 10^9$. Let $N_{art}$ be the set of artificial computational units (e.g., silicon neurons or quantum bits). Let $S$ be the functional state of the global system (the brain/mind). Let $P$ be the set of physical laws governing the interaction of matter. 2.2 Axioms Axiom A1 (Physical Closure): All functions of the brain (including consciousness) are entirely determined by its physical structure and physical state evolution; there is no non-physical â€œsoulâ€ intervention. Axiom A2 (Local Replaceability): If a physical unit $uâ€™$ is equivalent to unit $u$ in terms of input-output and state transitions, then at the system level, $uâ€™$ can replace $u$ without changing the overall system function. $$\\forall u \\in N_{bio}, \\exists uâ€™ \\in N_{art} : Behavior(u) \\equiv Behavior(uâ€™)$$\n2.3 Deduction Step 1: Micro-Isomorphism Based on the development of engineering physics, we construct artificial neurons $n_{art}^i$. If brain operation follows classical physics, we use analog circuits or digital algorithms to reproduce the membrane potential equations of $n_{bio}^i$ . If brain operation follows quantum physics, we use quantum logic gates to reproduce the quantum state evolution of $n_{bio}^i$. Proposition 1: There exists a technological means $T$ such that a single biological neuron can be perfectly simulated by an artificial unit.\n$$P_1: n_{art}^i \\xrightarrow{T} n_{bio}^i$$\nStep 2: Inductive Reconstruction We use mathematical induction to prove the replaceability of the entire neural network.\nBase Case: Let brain $B_0$ be a fully biological brain. Replacing 1 neuron yields $B_1$. By Proposition 1 and Axiom A2, $Function(B_1) = Function(B_0)$.\nInductive Hypothesis: Assume that after replacing $k$ neurons, the hybrid brain $B_k$ still maintains functional integrity, i.e., $Function(B_k) = Function(B_0)$.\nInductive Step: Consider the $(k+1)$-th neuron. Since the interactions between neurons are local (Local Interactions) and follow physical laws $P$, in the environment of $B_k$, when the $(k+1)$-th biological neuron is replaced by an artificial neuron, its signal transmission to neighboring nodes remains unchanged.\nConclusion: When $k$ approaches the total number of brain neurons $N$, the fully artificial brain $B_{art}$ is functionally strictly equivalent to the biological brain $B_{bio}$.\n$$\\lim_{k \\to N} B_k = B_{art} \\implies B_{art} \\equiv B_{bio}$$\nStep 3: Engineering Completeness of Embodiment The brain is merely a controller; the realization of function $H$ depends on actuators (the body). Let the kinematic characteristics of the human body be the set $K_{human}$ (degrees of freedom, torque, perceptual precision). Physical laws allow the construction of a mechanical system $M_{robot}$. Since engineering materials (such as carbon fiber, hydraulic drives, piezoelectric ceramics) typically surpass biological materials (muscles, bones) in strength, speed, and precision:\n$$\\exists M_{robot} : K_{robot} \\supseteq K_{human}$$\nStep 4: Universal Functionality Combining Step 2 (fully artificial brain) and Step 3 (superhuman mechanical body). For any task $task \\in H$ that humans can complete:\nThe brain $B_{art}$ can generate the planning and control signals required to complete that task (derived from $B_{art} \\equiv B_{bio}$). The body $M_{robot}$ can execute these signals and produce physical effects (derived from $K_{robot} \\supseteq K_{human}$). Part III: Conclusion In summary, although the Microtubule Quantum Paradigm poses challenges to current AI based on classical computers, grounded in the more general physicalism and the Church-Turing-Deutsch Principle, as long as the universe is physically closed, we will inevitably be able to construct artificial substrates that are microscopically isomorphic and macroscopically equivalent.\nThrough rigorous recursion via mathematical induction, we have logically proven that: Artificial substrates can not only simulate humans but also possess theoretical completeness in replacing humans to execute any physical and cognitive tasks.\nReferences Turing, A. M. (1936). â€œOn Computable Numbers, with an Application to the Entscheidungsproblem.â€ Proceedings of the London Mathematical Society, 2(42), 230-265. https://doi.org/10.1112/plms/s2-42.1.230\nFoundation of the Church-Turing Thesis: any computable process can be simulated by a Universal Turing Machine.\nGÃ¶del, K. (1931). â€œÃœber formal unentscheidbare SÃ¤tze der Principia Mathematica und verwandter Systeme I.â€ Monatshefte fÃ¼r Mathematik und Physik, 38, 173-198. https://doi.org/10.1007/BF01700692\nIncompleteness theorems establishing the existence of â€œnon-algorithmicâ€ components in formal systems.\nPenrose, R. (1989). The Emperorâ€™s New Mind: Concerning Computers, Minds, and the Laws of Physics. Oxford University Press.\nArgues for the non-computable view of consciousness based on quantum mechanics and GÃ¶delian arguments.\nDeutsch, D. (1985). â€œQuantum Theory, the Church-Turing Principle and the Universal Quantum Computer.â€ Proceedings of the Royal Society of London A, 400(1818), 97-117. https://doi.org/10.1098/rspa.1985.0070\nEstablishes the Church-Turing-Deutsch Principle: any finite physical process can be perfectly simulated by a universal quantum computer.\n","title":"Can Machines Replace Humans? A Formal Proof","uri":"/posts/human_machine_proof/"},{"content":"æœ¬æ–‡æ•´ç†äº†ä¸€äº›æˆ‘å¬è¿‡æˆ–å¬å®Œéƒ¨åˆ†å†…å®¹çš„ï¼Œå€¼å¾—åˆ†äº«çš„æ–‡å²å“²è‰ºç±»éŸ³è§†é¢‘èµ„æºã€‚\nä¸ºç¡®ä¿èµ„æºçš„ä¸¥è°¨æ€§ä¸å¯é æ€§ï¼Œæœ¬æ–‡ä¸»è¦æ”¶å½•å¤§å­¦æ•™æˆæˆ–åœ¨ç›¸å…³é¢†åŸŸæœ‰ä¸€å®šå£°èª‰äººç‰©çš„è¯¾ç¨‹ä¸è®²åº§ï¼Œæ ¹æ®æˆ‘çš„å­¦ä¹ è¿‡ç¨‹ï¼Œæœ¬æ–‡å°†ä¸æ–­æ›´æ–°ã€‚\næˆ‘å°†è¿™äº›èµ„æºåˆ†æˆä¸¤ä¸ª Levelï¼ŒLevel 1 æŒ‡æ— éœ€é¢„å¤‡çŸ¥è¯†ï¼Œé€‚åˆåˆå­¦è€…ï¼ŒLevel 2 æŒ‡éœ€å…·å¤‡ä¸€å®šåŸºç¡€çŸ¥è¯†ï¼Œæˆ–å·²å­¦ä¹ è¿‡Level 1ä¸­ç›¸å…³å†…å®¹ã€‚\nç­‰çº§ åç§° ç§ç±» æ¥æº å¤‡æ³¨ Level1 é€»è¾‘å­¦-åå—å¸ˆèŒƒå¤§å­¦ é™ˆæ™“å¹³ æ•™æˆ å“²å­¦ b ç«™ ç†å·¥ç§‘çš„åŸºçŸ³ Level1 çˆ±æƒ…å¿ƒç†å­¦- æ­¦æ±‰ç†å·¥å¤§å­¦(å›½å®¶ç²¾å“è¯¾) b ç«™ Level1 å©šå§»ä¸çˆ±æƒ…â€”åä¸œå¸ˆèŒƒå¤§å­¦æ´ªäºšéæ•™æˆ b ç«™ çˆ±æƒ…éœ€è¦æ°¸è¿œç»´æŠ¤ Level1 è†å¬éŸ³ä¹-è€¶é²å¤§å­¦ è‰ºæœ¯ b ç«™ å¤å…¸éŸ³ä¹å…¥é—¨ Level1 èµ„æœ¬è®º-å¤æ—¦ç‹å¾·å³° å“²å­¦ b ç«™ Level1 å›ç»-å¤æ—¦ç‹å¾·å³° å“²å­¦ b ç«™ Level1 ä¼ ä¹ å½•-å¤æ—¦ç‹å¾·å³° å“²å­¦ b ç«™ Level1 å¿ƒç»-å¤æ—¦ç‹å¾·å³° å“²å­¦ b ç«™ Level1 å¤§å­¦-å¤æ—¦ç‹å¾·å³° å“²å­¦ b ç«™ Level1 ç‹é˜³æ˜å¿ƒå­¦åŠå…¶ç°ä»£æ„ä¹‰-å¤æ—¦ç‹å¾·å³° å“²å­¦ b ç«™ Level1 é©¬å…‹æ€ä¸»ä¹‰å“²å­¦å²-å¤æ—¦å´æ™“æ˜ å“²å­¦ b ç«™ Level1 é“å¾·ç»-ç‹å¾·å³° å“²å­¦ bç«™ Level1 å…­ç¥–å›ç»-å¶æ›¼ å“²å­¦ å–œé©¬æ‹‰é›… Level1 æ˜“ä¸­å¤©è¯´ç¦… å“²å­¦ å–œé©¬æ‹‰é›… Level1 ä¸­è¥¿æ€æƒ³å¿…ä¿®è¯¾-ç‹å¾·å³° å“²å­¦ youtube/å–œé©¬æ‹‰é›… ä¸­è¥¿æ€æƒ³æ¦‚è§ˆ Level1 å±€éƒ¨-é™ˆä¸¹é’ è‰ºæœ¯ youtube çœŸå®æ–‡äºº Level1 ä¸­å›½ç°ä»£æ–‡å­¦-è®¸å­ä¸œ æ–‡å­¦ youtube æ–‡å­¦å¯è’™ Level1 åŒ—å¤§é’±ç†ç¾¤æ•™æˆè®²é²è¿… æ–‡å­¦ b ç«™ ä¸­å›½é€šé²è¿… Level1 æ˜“ä¸­å¤© ã€Šå…ˆç§¦è¯¸å­ç™¾å®¶äº‰é¸£ã€‹ å“²å­¦ youtube æ‰“å¼€äº†æˆ‘å¯¹ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–æ¢ç´¢ä¹‹é—¨ Level1 åº„å­å†…ç¯‡â€”â€”å‚…ä½©è£ å“²å­¦ b ç«™ ç»ˆäºèƒ½å¬æ‡‚åº„å­å•¦ Level2 ä¸­å›½å“²å­¦å²-æ¨ç«‹å å“²å­¦ b ç«™ ã€Šè€å­ä¸å­”å­ã€‹å…¬å¼€è¯¾è®²å¾—æå¥½ Level1 ä¸­åäººæ°‘å…±å’Œå›½å²-é«˜å å†å² b ç«™ ç‹¬ç«‹å­¦è€… Level1 é‡è¯»ä¸­åäººæ°‘å…±å’Œå›½å² å†å² youtube æ¸¯ç§‘å¤§å„å®¶äº‘é›† éå¸¸æ„Ÿè°¢äº’è”ç½‘ä»¥åŠèµ„æºçš„ä¸Šä¼ è€…ï¼Œæ­£æ˜¯å› ä¸ºä»–ä»¬ï¼Œè®©æˆ‘å¾—ä»¥æ±²å–äººç±»æ™ºæ…§çš„ç²¾åï¼Œé€æ¸æˆé•¿ä¸ºä¸€ä¸ªæ›´å¥å…¨çš„äººã€‚\n","title":"A Humanities Resource Collection","uri":"/posts/humanities_resource_collection/"},{"content":" ä¸–ç•Œèµ äºˆæˆ‘è™«é¸£ ä¹Ÿèµ äºˆæˆ‘é›·éœ†\nèµ æˆ‘å¼¯å¼¯ä¸€æšæœˆ ä¹Ÿèµ äºˆæˆ‘æ™šæ˜Ÿ\nèµ æˆ‘ä¸€åœºç—… åˆæ…¢æ…¢ç—Šæ„ˆæ‘‡é£é“ƒ\nèµ æˆ‘ä¸€åœºç©º åˆæ¸æ¸å¡«æ»¡çœŸæ„Ÿæƒ…\n2025 å¹´æ˜¥æ™šï¼Œç¢°å·§é‡è§è²å§æ—¶éš”ä¸ƒå¹´ç™»æ˜¥æ™šçŒ®å”±æ–°æ­ŒğŸ‘ï¼Œæ‰€ä»¥ 2024 å¹´çš„å¹´åº¦æ€»ç»“ä¾¿ä»¥è¿™é¦–æ­Œä¸ºé¢˜å§ã€‚\nåœ¨ç§‘ç ”æ–¹é¢ï¼Œå¯¹{LLM-Agent}æœ‰äº†æ¯”è¾ƒæ·±å…¥çš„äº†è§£ï¼Œå¹¶åšäº†ä¸€äº›æ¢ç´¢æ€§æœ‰ä»·å€¼çš„å·¥ä½œã€‚åœ¨é¡¹ç›®æ–¹é¢ï¼Œå’Œ cc å¸ˆå…„æ¥å…¥äº†ä¸€ä¸ªä¼ä¸šé¡¹ç›®ï¼Œå¹¶ç”¨{Agent æ–¹æ¡ˆ}å®ç°äº†æ ¸å¿ƒæŠ€æœ¯ï¼Œè¶Šæ¥è¶Šå¯¹è‡ªå·±æ‰€é€‰æ‹©çš„è·¯å……æ»¡ä¿¡å¿ƒã€‚\nç”±äºä¿å¯†åå®šï¼Œæˆ‘åªèƒ½æœ€ç²—ç²’åº¦åœ°æè¿°åœ¨ç§‘ç ”é¡¹ç›®æ–¹é¢çš„æƒ…å†µã€‚\n24 å¹´çš„ 5 æœˆï¼ŒæŠ¥åå‚åŠ äº† valse ä¼šè®®ã€‚æˆ‘è®¤ä¸ºåœ¨valseä¸­å¾ˆæœ‰ç”¨çš„æ˜¯posterå’Œå­¦ç”Ÿè®ºå›ä¸¤ä¸ªæ´»åŠ¨ï¼Œå‰è€…å¯ä»¥å’Œè®ºæ–‡ä½œè€…é¢å¯¹é¢äº¤æµï¼Œåè€…èƒ½å¤Ÿå’Œå¾ˆå¤šç§‘ç ”å­¦ç”Ÿæ–°æ˜Ÿäº¤æµå¹¶å¬å–ä»–ä»¬åšç ”ç©¶çš„ç»éªŒã€‚\næ­¤å¤–ï¼Œåˆ†äº«åœ¨workshopä¸­å¬åˆ°çš„ä¸€ä¸ªæœ‰æ„æ€çš„è§‚ç‚¹ï¼Œå³ç›®å‰æˆ‘ä»¬æ‰€å¤„åœ¨â€œçº ç¼ æ—¶ä»£â€ï¼Œå³è‰ºæœ¯ã€ç§‘å­¦ã€å·¥ç¨‹ã€è®¾è®¡å››ä¸ªé¢†åŸŸæ˜¯ç›¸äº’è½¬åŒ–çš„ã€‚æˆ‘çš„ç†è§£æ˜¯ï¼šè‰ºæœ¯å¸¦æ¥æƒ³è±¡åŠ›ï¼Œå¯è¿ªç§‘å­¦å»è§£é‡Šé¢„æµ‹ä¸–ç•Œã€‚å·¥ç¨‹è´Ÿè´£å°†ç§‘å­¦åº”ç”¨åˆ°ç°å®ä¸–ç•Œä¸­ã€‚è€Œè®¾è®¡å¸ˆå°†å·¥ç¨‹æŠ€æœ¯åŒ…è£…æˆè®¾è®¡å“æ”¾å…¥ç°å®ä¸–ç•Œä¸­ï¼Œæé«˜å¤§ä¼—ä½¿ç”¨ä½“éªŒã€‚è€Œè‰ºæœ¯åˆä»è®¾è®¡å“ä¸­æ±²å–çµæ„Ÿã€‚\nå¯¹valseæœ€åä¸€å¤©çš„workshopå¹¶ä¸æ˜¯å¾ˆæ„Ÿå…´è¶£ï¼Œäºæ˜¯ä¾¿æˆå…¬è´¹æ—…æ¸¸äº†ğŸ˜‚\næŠ›å¼€ç§‘ç ”é¡¹ç›®ä»¥å¤–ï¼Œæˆ‘è¿˜ä¸Šå®Œäº†4é—¨è¯¾ï¼Œåˆ†åˆ«æ˜¯å¦å¤§å•æ±Ÿæ»¨è€å¸ˆå¼€è®¾çš„ã€Šæœ€ä¼˜åŒ–ç†è®ºä¸å·¥ç¨‹åº”ç”¨ã€‹ã€ä¸­ç§‘æµ©åšå¼€è®¾çš„ã€ŠåŸºäºè”åˆå›½æŠ¥å‘Šçš„å…¨çƒå¯æŒç»­å‘å±•æŠ¥å‘Šã€‹\u0026ã€Šå›½é™…ç»„ç»‡èŒå‘˜å‘å±•ï¼šç†è®ºä¸å®åŠ¡ã€‹ã€ä»¥åŠå²­å¤§è®¸å­ä¸œè€å¸ˆå¼€è®¾çš„ã€Šä¸­å›½ç°ä»£æ–‡å­¦ã€‹ï¼Œå3é—¨è¯¾åŸºæœ¬æ˜¯æˆ‘åœ¨è¿åŠ¨æˆ–è€…åˆä¼‘å‰å¬å®Œçš„ã€‚\nã€Šæœ€ä¼˜åŒ–ç†è®ºä¸å·¥ç¨‹åº”ç”¨ã€‹å±äºæ—å¬ï¼Œ3æœˆä»½å¼€å­¦ï¼Œå¿ƒé‡Œç—’ç—’æƒ³æ‰¾å‡ é—¨è¯¾æ¥ä¸Šä¸Šï¼Œä¸ç„¶æ¥çº¿ä¸‹è¯»ç ”æ²¡ä»€ä¹ˆæ„ä¹‰å‘€ğŸ¤”ï¼Œå¦ä¸€æ–¹é¢ä¹Ÿæ˜¯åˆ©ç”¨å¥½å­¦æ ¡çš„èµ„æºå’¯ã€‚äºæ˜¯æˆ‘ç»è¿‡å‡ ç•ªçº¿ä¸Šçº¿ä¸‹çš„è°ƒç ”æµ‹è¯„ï¼Œæœ€ç»ˆå†³å®šæ—å¬ä¸€é—¨ã€Šæœ€ä¼˜åŒ–ç†è®ºä¸å·¥ç¨‹åº”ç”¨ã€‹ã€‚\nä¸ªäººè®¤ä¸ºè¿™é—¨è¯¾è¿˜æ˜¯å€¼å¾—å¬çš„ï¼Œè™½ç„¶å¯¹æˆ‘æ¥è¯´ä¼˜åŒ–åœ¨ç›®å‰çš„ç§‘ç ”å·¥ä½œä¸­å°šæœªç”¨åˆ°ï¼Œä½†æ˜¯ç”¨ä¼˜åŒ–å»å»ºæ¨¡ç”Ÿæ´»ä¸­å¤§å°ä¹‹äº‹çš„æ€æƒ³æ˜¯éå¸¸å€¼å¾—å¸æ”¶åº”ç”¨çš„ã€‚\nè€Œå…³äºè”åˆå›½çš„é‚£ä¸¤é—¨è¯¾ï¼Œä¸»è¦æ˜¯è§‰å¾—å‡ºå›½å»è”åˆå›½å·¥ä½œä¹Ÿæ˜¯æœªæ¥ä¸€ç§å¯èƒ½ï¼Œå¹¶ä¸”è¿™ä¸¤é—¨å±äºçº¿ä¸Šå…è´¹æˆè¯¾ï¼Œæ°å·§æ—¶é—´éƒ½å¯ä»¥å®‰æ’åˆ°å‘¨å¤©ï¼Œä¸å½±å“å¹³æ—¥çš„ç§‘ç ”å·¥ä½œï¼Œä¾¿æŠ¥åäº†ã€‚\næ•´ä½“å¬ä¸‹æ¥æ”¶è·è¿˜æ˜¯å¾ˆå¤§çš„ï¼Œä¸€æ–¹é¢å¯¹è”åˆå›½çš„æœºåˆ¶æœ‰äº†ä¸€ä¸ªå¤§è‡´çš„äº†è§£ï¼Œè®©æˆ‘æš‚æ—¶æ‘’å¼ƒäº†å»æœªæ¥å»è”åˆå›½å°±ä¸šçš„é€‰æ‹©ï¼Œå¦ä¸€æ–¹é¢è¿˜æé«˜äº†è‹±è¯­å¬å†™èƒ½åŠ›ğŸ˜Šã€‚\nè€Œé€‰æ‹©å¬è®¸è€å¸ˆçš„ã€Šä¸­å›½ç°ä»£æ–‡å­¦ã€‹å®Œå…¨æ˜¯å‡ºäºå¯¹æ–‡å­¦çš„å…´è¶£ï¼Œè¿™é—¨è¯¾è®²å¾—å¾ˆå¥½ï¼ä¸ä»…ä¸ºæˆ‘æ™®åŠäº†ä¸€äº›æ–‡å­¦å¸¸è¯†ï¼Œé€‰è¯»åˆ†æäº†å¾ˆå¤šä½œå®¶åç¯‡ï¼Œè€Œä¸”æˆ‘è¿˜äº†è§£äº†ä¸€äº›ä½œå®¶ç”Ÿå¹³ã€‚\næˆ‘å¬ç¬¬ä¸€èŠ‚è¯¾ï¼Œå°±è¢«è®¸è€å¸ˆè®²è¯¾ç”ŸåŠ¨æ‰€æ‰“åŠ¨äº†ï¼Œå½“æ—¶å¿ƒé‡Œè§‰å¾—â€œå“‡ï¼Œè¿™ä¸ªæ•™æˆå¥½æœ‰å¤§å¸ˆè®²æ¼”çš„é£èŒƒï¼è¿™é—¨è¯¾æˆ‘ä¸€å®šè¦åšæŒå¬å®Œï¼â€\nè¯´åˆ°è®¸å­ä¸œè€å¸ˆï¼Œé‚£ä¸å¾—ä¸æåˆ°é™ˆä¸¹é’è€å¸ˆï¼Œè¿™å­¦æœŸæˆ‘åŸºæœ¬ä¸Šå¬å®Œäº†ç½‘ç»œä¸Šèƒ½æ‰¾åˆ°çš„æ¯”è¾ƒæœ‰åçš„æ‰€æœ‰è®²æ¼”è§†é¢‘ï¼Œæˆ‘è®¤ä¸ºé™ˆå¾ˆæœ‰é­…åŠ›ï¼Œæ•¢è®²çœŸè¯ï¼Œä½†åˆå¾ˆäº²å’Œï¼Œåƒé‚£ç§ååœ¨å…¬å›­é•¿å‡³ä¸Šèƒ½å’Œä½ èŠä¸€ä¸‹åˆçš„è€å¤´ã€‚æ­¤å¤–ï¼Œä»–å…³äºä¸€äº›é—®é¢˜çš„çœ‹æ³•éå¸¸å…·æœ‰æ´å¯ŸåŠ›ï¼Œè®©æˆ‘æƒ³èµ·é²è¿…å…ˆç”Ÿã€‚\nä»Šå¹´åœ¨å¬éŸ³ä¹æ–¹é¢ï¼Œç”±äºç½‘æ˜“äº‘éŸ³ä¹å……æ»¡ç€å„ç§å¹¿å‘Šï¼Œæˆ‘ä¸€æ°”ä¹‹ä¸‹æŠŠtaåˆ äº†ï¼Œè½¬ç”¨apple musicï¼Œå¤§éƒ¨åˆ†æ•´å¹´çš„å¬æ­Œæ•°æ®éƒ½ä¸¢å¤±äº†ï¼Œæˆ‘åªèƒ½ç®€è¦æ€»ç»“ã€‚\n2024ä¾ç„¶å–œæ¬¢å¬å¤å…¸ï¼Œåœ¨å®éªŒå®¤å·¥ä½œæ—¶ï¼Œç™½å¤©å¬Glenn Gouldçš„Bachä½œå“ï¼Œæ™šä¸Šå¬Glenn Gouldçš„Beethovenä½œå“ï¼Œå°¤å…¶æ˜¯ä¸“è¾‘ã€ŠBeethoven: Piano Sonatas Nos. 8, 14 \u0026 23 - Gould Remasteredã€‹ã€‚\n24å¹´å»å¬äº†ä¸€æ¬¡æ ¡å†…äº¤å“å›¢çš„éŸ³ä¹ä¼šï¼Œè¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡çº¿ä¸‹å»å¬å¤å…¸éŸ³ä¹ä¼šï¼Œéå¸¸äº«å—æ•´ä¸ªè†å¬è¿‡ç¨‹ã€‚æš‘å‡è¿˜åŸ¹å…»äº†å¼¹é’¢ç´è¿™ä¸€çˆ±å¥½ï¼Œåœ¨å­¦æ ¡å·¥ä½œæ—¶ï¼Œæˆ‘æ¯å¤©ä¼šåœ¨å›ºå®šæ—¶é—´å†…å¼¹åŠå°æ—¶ï¼Œæœ‰æ—¶å€™å¦‚æœæ€è€ƒé—®é¢˜é™·å…¥æ­»èƒ¡åŒã€æˆ–è€…æ•ˆç‡ä½ä¸‹æ—¶ï¼Œä¹Ÿä¼šè·‘å»å®éªŒå®¤æ—è¾¹çš„å…¬å…±é’¢ç´å¼¹ä¸€å°ä¼šå„¿ã€‚\nè¯»å®Œæˆ–è€…å¬å®Œ5æœ¬ä¹¦ï¼Œåˆ†åˆ«æ˜¯ã€Šå¹³é¢å›½ : å¤šç»´ç©ºé—´ä¼ å¥‡å¾€äº‹ã€‹ã€ã€Šè®ºè¯­è¯‘æ³¨ã€‹ã€ã€Šé»‘å®¢ä¸ç”»å®¶ã€‹ã€ã€Šç‹é˜³æ˜å®¶ä¹¦ : ç‹é˜³æ˜å®¶ä¹¦å®¶è®­å®¶è§„å…¨é›†ã€‹ã€ã€Šå²è’‚å¤«Â·ä¹”å¸ƒæ–¯ä¼ ï¼ˆä¿®è®¢ç‰ˆï¼‰ã€‹ï¼Œå¯¹ä¹¦ç±çš„è¯„ä»·è¯¦è§doubanä¸»é¡µã€‚\nä»Šå¹´å¯¹æˆ‘å½±å“æœ€å¤§çš„ä¹¦ä¸ºã€Šå²è’‚å¤«Â·ä¹”å¸ƒæ–¯ä¼ ã€‹ï¼Œè¯»å®Œæ­¤ä¹¦è®©æˆ‘æ˜ç¡®äº†äººç”Ÿç›®æ ‡å³ï¼šæ´»ç€å°±æ˜¯åˆ©ç”¨è‡ªå·±çš„ä¸“é•¿æ”¹å˜ä¸–ç•Œï¼\nä¸Šè¿°æåˆ°çš„ä¹¦ç±éƒ½æ˜¯åœ¨24å¹´8æœˆä»½ä¹‹å‰è¯»å®Œçš„ï¼Œä¾ç„¶æ˜¯åˆ©ç”¨åœ¨é›¶ç¢æ—¶é—´ï¼Œä½†æ˜¯éšç€åæ¥ç§‘ç ”å·¥ä½œå¼ºåº¦ä¸Šå‡ï¼Œæˆ‘ä¸å¾—ä¸å‹ç¼©é›¶ç¢æ—¶é—´ï¼Œè¦ä¹ˆç”¨æ¥æ”¾ç©ºæ€è€ƒç§‘ç ”ä¸­çš„é—®é¢˜ï¼Œè¦ä¹ˆæ˜¯åŠ å¿«èµ°è·¯çš„é€Ÿåº¦ğŸ’¦ã€‚\nå…¶å®è‡ªå·±è¯»ä¹¦ä»¥æ¥ä¸€ç›´æœ‰ä¸ªâ€œåâ€ä¹ æƒ¯ï¼Œå³ä¸€æœ¬ä¹¦è¿˜æ²¡çœ‹å®Œå°±ä¼šå»çœ‹å¦å¤–ä¸€æœ¬ä¹¦ï¼Œå¾ªç¯å¾€å¤å¯¼è‡´å¥½å‡ æœ¬ä¹¦æ²¡æœ‰ä¸€æœ¬çœ‹å®ŒğŸ˜Ÿã€‚åæ¥æˆ‘æ„è¯†åˆ°è¿™ä¸ªé—®é¢˜ï¼Œå°±è®¾ç½®è‡ªå·±å¹¶å‘æ•°é‡ä¸º 2ã€‚\nçœ‹å®Œäº†16éƒ¨ç”µå½±ï¼Œå¯ä»¥èšç±»ä¸ºï¼šçˆ±æƒ…ï¼ˆ8ï¼‰ã€éŸ³ä¹ï¼ˆ2ï¼‰ã€çŠ¯ç½ªï¼ˆ2ï¼‰ã€å‰§æƒ…ï¼ˆ4ï¼‰å…±å››ç±»ï¼Œéƒ½æ˜¯åœ¨å¯’æš‘å‡ã€æ—…æ¸¸ä»¥åŠå‘¨å¤©æ”¾å‡æœŸé—´çœ‹çš„ã€‚\nä»Šå¹´çœ‹å®Œçš„ç”µå½±æ•°é‡ç›¸å¯¹äºå»å¹´å¤§å¹…å¢åŠ ï¼Œä¸€æ–¹é¢æ˜¯ç¡®å®æ‰¾åˆ°äº†ä¸€äº›è‡ªå·±æƒ³çœ‹çš„å½±ç‰‡ï¼Œå¦ä¸€æ–¹é¢æ¥è‡ªäºå’Œç›é…¸åŒå­¦èŠå¤©æœŸé—´ï¼Œå¥¹æåˆ°çš„å½±ç‰‡ã€‚\nä»Šå¹´å¼€å§‹å¥èº«ï¼ŒæŒ‰ç…§ä¸‰åˆ†åŒ–è®­ç»ƒçš„æ–¹æ³•ï¼Œä½“é‡çªç ´äº†60kgï¼Œç»ˆäºä»ç»†ç‹—ä¸­é™¤åğŸ‰ã€‚\né™¤äº†å¥èº«è¿™ç§æ— æ°§è¿åŠ¨ï¼Œæˆ‘ä¹Ÿä¼šåœ¨ä¸éœ€è¦å¥èº«çš„é‚£å¤©ï¼Œå»åšä¸€äº›æœ‰æ°§è¿åŠ¨ï¼Œä¾‹å¦‚ç¯®çƒå’Œæ¸¸æ³³ã€‚æœ‰æ°§è¿åŠ¨ç›¸è¾ƒäºæ— æ°§è¿åŠ¨å¾ˆèƒ½é‡Šæ”¾å‹åŠ›ï¼Œè¿åŠ¨å®Œä¸€èº«é€šé€ã€‚\næˆ‘è‡³å°‘æ¯å‘¨ä¼šå»æ¸¸æ³³ä¸€æ¬¡ï¼Œæ¸¸æ³³ç‰¹åˆ«èƒ½å¤Ÿå°†ä½ ä»ç›®å‰åšçš„äº‹æƒ…ä¸­è„±ç¦»å¼€æ¥ï¼Œè®©ä½ æ‹¥æœ‰ä¸€ç§å…¨æ–°çš„è§†è§’å»æ€è€ƒæ‰€æœ‰é—®é¢˜ï¼Œå› æ­¤æˆ‘å¾ˆå–œæ¬¢æ¸¸æ³³ã€‚\nåœ¨ç¡çœ æ–¹é¢ï¼Œä¸€èˆ¬æ˜¯æ™šä¸Š23:00-23:30å…¥ç¡ï¼Œæ—©ä¸Š6:30-7:00èµ·åºŠã€‚ç”±äºä»Šå¹´æŠŠåˆä¼‘ç»™æˆ’äº†ï¼Œå†åŠ ä¸Šé«˜å¼ºåº¦çš„å·¥ä½œï¼Œæ™šä¸Šç‰¹åˆ«å®¹æ˜“å…¥ç¡ï¼\nåœ¨æ„Ÿæƒ…æ–¹é¢ï¼Œç¬¬ä¸€æ¬¡çœŸæ­£æ„ä¹‰ä¸Šåœ°è°ˆæ‹çˆ±ğŸ˜Šï¼Œæˆ‘å’Œç›é…¸å„æ–¹é¢éƒ½å¾ˆåˆå¾—æ¥ï¼Œä¹‹æ‰€ä»¥æœ€ç»ˆé€‰æ‹©åœ¨ä¸€èµ·ã€‚ä¸€æ˜¯è®¤ä¸ºæ‹çˆ±å±äºäººç”Ÿåœ¨å˜å¾—æ²¡æœ‰æ„ä¹‰å‰ä¸€ä»¶æœ‰æ„ä¹‰çš„äº‹æƒ…ï¼ŒäºŒæ˜¯ä¸æƒ³é”™è¿‡å¯¹çš„äººã€‚\nå›é¡¾äº† 2023 å¹´åº¦æ€»ç»“å®šä¸‹çš„ç›®æ ‡ï¼Œæ²¡æœ‰åšå¥½çš„ä¸¤ç‚¹æ˜¯{1.ii# }\u0026{1.iii# }ï¼Œå‰è€…ç”±äºå¥èº«å’Œç»ƒæ›²å­ä¼šå¯¼è‡´æ‰‹æœºä½¿ç”¨æ—¶é—´ä¸Šå‡æ—¥å‡1å°æ—¶47åˆ†ï¼Œä½†è‡ªè®¤ä¸ºæ¯«æ— æ„ä¹‰çš„æ‰‹æœºä½¿ç”¨æ—¶é—´å‡ ä¹æ²¡æœ‰ã€‚åè€…æ”¹æˆç¡å‰å¬ä¹¦å•¦ã€‚\né‚£ä¹ˆ2025å¹´çš„ç›®æ ‡å¦‚ä¸‹ï¼š\nå®Œæˆä¸€é¡¹èƒ½å¤Ÿäº§ç”Ÿå®é™…åº”ç”¨ä»·å€¼çš„å·¥ä½œã€‚ å’Œç›é…¸åº¦è¿‡2025å¹´ å¯¹ç†è´¢æœ‰åŸºæœ¬è®¤è¯†ï¼Œå¹¶ç”¨äºå®è·µã€‚ ä¿æŒ{è§„å¾‹ä½œæ¯}\u0026{è¿åŠ¨é‡} æ›´å¤šåœ°ç”¨æ•°æ®è®°å½•é‡åŒ–ç”Ÿæ´»ä¸­æ‰€ç”¨æ—¶é—´ ","title":"2024 ä¸–ç•Œèµ äºˆæˆ‘çš„","uri":"/posts/2024_summary/"},{"content":"Introduction è¿™å­¦æœŸå»è¹­äº†ä¸€é—¨è¯¾ã€Šæœ€ä¼˜åŒ–ç†è®ºä¸å·¥ç¨‹åº”ç”¨ã€‹ï¼Œæˆè¯¾è€å¸ˆæ˜¯å•æ±Ÿæ»¨è€å¸ˆå’Œä»˜ç«‹ç¾¤è€å¸ˆã€‚ä¸ªäººè®¤ä¸ºæˆè¯¾è´¨é‡ä¸é”™ï¼Œæ˜¯xmuå€¼å¾—å¬çš„ç ”ç©¶ç”Ÿè¯¾ã€‚è¯¾ç¨‹é‡‡ç”¨çš„æ•™ææ˜¯Stephen Boydçš„Convex Optimizationã€‚å¬å•è€å¸ˆä¸Šè¯¾è¯´ä»–åœ¨NUSè¯»åšæ—¶ï¼Œä¼˜åŒ–è¯¾çš„è€å¸ˆæ›¾åœ¨standfordå¬è¿‡Boydäº²è‡ªæˆè¯¾ï¼ŒBolydå¸¸å¼ºè°ƒå‡ ä½•ç›´è§‚ç»“åˆæ•°å­¦æ¨å¯¼ã€‚è¿™æ ·çœ‹æ¥ï¼Œæˆ‘ä¹Ÿç®—æ˜¯Boydçš„å†ä¼ å¼Ÿå­äº†ğŸ˜ã€‚ æœ¬æ–‡ä¸»è¦æ˜¯æƒ³è°ˆä¸€ä¸‹å­¦å®Œè¿™é—¨è¯¾ï¼Œæˆ‘å¯¹æœ€ä¼˜åŒ–çš„è®¤è¯†ï¼Œè¶ç€æˆ‘è„‘æµ·é‡Œä¼˜åŒ–çš„çŸ¥è¯†è¿˜æ²¡å¿˜å…‰ï¼Œè¶çƒ­æ‰“é“æ•´ç†ä¸‹æœ‰å…³ä¼˜åŒ–çš„landscapeã€‚ps:æœ¬æ–‡çš„å†…å®¹å’Œç”¨å›¾å‡æ¥å‚è€ƒè‡ªStephen Boydçš„Convex Optimization Convex optimization problem è®°å¾—æœ€æ—©æ¥è§¦åˆ°ä¼˜åŒ–æ—¶ï¼Œæ˜¯åœ¨å¤§ä¸€çš„æš‘å‡ï¼Œå½“æ—¶æŠ¥åå‚åŠ äº†å­¦æ ¡çš„æ•°å­¦å»ºæ¨¡åŸ¹è®­ï¼Œæœ‰ç±»é¢˜ç›®ä¾¿æ˜¯å±äºè¿ç­¹ä¸ä¼˜åŒ–ã€‚å°è±¡æœ€æ·±åˆ»ä¹Ÿæ˜¯å¤´ä¸€æ¬¡é‡åˆ°çš„æ˜¯çº¿æ€§è§„åˆ’ç±»â€”â€”æŠ•èµ„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå¤§æ¦‚æ˜¯ä½ æ‰‹é‡Œæœ‰ä¸€å®šçš„æœ¬é’±ï¼Œå¸‚åœºä¸Šæä¾›äº†å¤šç§èµ„äº§ä¾›æŠ•èµ„ï¼Œåœ¨ä¸è¶…è¿‡æœ¬é’±çš„æƒ…å†µä¸‹ï¼Œå°½å¯èƒ½ä½¿å¾—ä½ çš„æ”¶ç›Šè¾¾åˆ°æœ€å¤§ã€‚ è´Ÿè´£è¿™ç±»é¢˜ç›®çš„è‘£è€å¸ˆç»å¸¸å‘æˆ‘ä»¬æåˆ°ï¼Œå¯¹äºçº¿æ€§è§„åˆ’é—®é¢˜ï¼Œä¸€èˆ¬æ¥è¯´æˆ‘ä»¬å¯ä»¥æ‰¾åˆ°æœ€ä¼˜è§£ï¼Œä½†æ˜¯å¯¹äºéçº¿æ€§è§„åˆ’é—®é¢˜ï¼Œæˆ‘ä»¬åªèƒ½é€šè¿‡é—ä¼ ç®—æ³•ã€æ¨¡æ‹Ÿé€€åŒ–ç®—æ³•ç­‰å¯å‘å¼ç®—æ³•æ‰¾åˆ°ä¸€ä¸ªå±€éƒ¨æœ€ä¼˜è§£ã€‚å› æ­¤ï¼Œå½“æ—¶æˆ‘é¢å¯¹ä¼˜åŒ–é—®é¢˜æ—¶ï¼Œä¸€èˆ¬æ˜¯å…ˆåˆ¤æ–­æ˜¯å¦æ˜¯çº¿æ€§ï¼Œå¦‚æœæ˜¯çº¿æ€§å°±çš†å¤§æ¬¢å–œï¼Œé‡åˆ°éçº¿æ€§ä¾¿åªä¼šå»å¥—ä¸€äº›å¯å‘å¼ç®—æ³•ã€‚ğŸ˜“ ä½†æ˜¯ç ”ç©¶ç”Ÿå­¦å®Œã€Šæœ€ä¼˜åŒ–ç†è®ºä¸å·¥ç¨‹åº”ç”¨ã€‹è¿™é—¨è¯¾ï¼Œåˆ·æ–°äº†æˆ‘å¯¹ä¼˜åŒ–çš„è®¤çŸ¥ã€‚Bolydçš„ä¹¦ä¸­introductionéƒ¨åˆ†å†™ç€è¿™æ ·ä¸€å¥è¯ï¼š In fact the great watershed in optimization isnâ€™t between linearity and nonlinearity, but convexity and nonconvexity. åŸæ¥ä¼˜åŒ–é—®é¢˜èƒ½å¦è¢«æˆåŠŸè§£å†³ï¼Œåœ¨äºé—®é¢˜çš„å‡¸æ€§convexityå’Œéå‡¸æ€§nonconvexityã€‚é‚£ä¹ˆä»€ä¹ˆæ˜¯convex- optimizationå‡¸ä¼˜åŒ–é—®é¢˜å‘¢ï¼Ÿ $$ \\begin{array}{lll}\\text{minimize}\u0026f_0(x)\\\\ \\text{subject to}\u0026f_i(x)\\leq0,\\quad i=1,\\ldots,m\\\\ \u0026h_i(x)=0,\\quad i=1,\\ldots,p\\end{array} \\tag{1} $$ ä¸Šé¢è¿™ä¸ªå¼å­æ˜¯ä¼˜åŒ–é—®é¢˜çš„å½¢å¼åŒ–è¡¨ç¤ºï¼Œå‘é‡$x=(x_1,â€¦,x_n)$ä¸ºä¼˜åŒ–å˜é‡ï¼Œ$f_0(x)$æ˜¯ç›®æ ‡å‡½æ•°ï¼Œä¾‹å¦‚æ”¶ç›Šå‡½æ•°ã€‚$f_i(x)$æ˜¯çº¦æŸå‡½æ•°ï¼Œä¾‹å¦‚æ¯ç§èµ„äº§é™é¢ã€æŠ•èµ„èŠ±é”€ç­‰ã€‚å½“ç›®æ ‡å‡½æ•°å’Œä¸ç­‰å¼çº¦æŸå‡½æ•°$f_0, â€¦, f_m$å‡ä¸ºå‡¸å‡½æ•°ï¼Œç­‰å¼çº¦æŸå‡½æ•°$h_i(x)=a_i^Tx-b_i$ä¸ºAffineä»¿å°„å‡½æ•°æ—¶ï¼Œè¯¥ä¼˜åŒ–é—®é¢˜ä¸ºconvexå‡¸ä¼˜åŒ–é—®é¢˜ã€‚ æˆ‘ä»¬ç§°å‡½æ•°$f_i$ä¸ºå‡¸å‡½æ•°ï¼Œå¯¹äºä»»æ„$x, y\\in\\mathbf{R}^n$ï¼Œ$0\\leq\\theta\\leq1$ ï¼Œå‡½æ•°æ»¡è¶³ $$ f_i(\\theta x+(1-\\theta)y)\\leq\\theta f_i(x)+(1-\\theta) f_i(y) \\tag{2} $$ å½“ä¸Šå¼å–ç­‰å·ï¼Œä»…è¦æ±‚$\\theta \\in\\mathbf{R}$æ—¶ï¼Œè½¬å˜ä¸ºçº¿æ€§è§„åˆ’é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯è¯´å‡¸ä¼˜åŒ–é—®é¢˜æ˜¯çº¿æ€§è§„åˆ’é—®é¢˜æ›´generalçš„ç‰ˆæœ¬ã€‚è‹¥ä¼˜åŒ–é—®é¢˜ä¸æ˜¯çº¿æ€§çš„ï¼Œåˆ™ç§°ä¹‹ä¸ºéçº¿æ€§è§„åˆ’ã€‚ ç”±äºå‡¸ä¼˜åŒ–é—®é¢˜æœ‰ä¸€å¥—æˆç†Ÿçš„ç†è®ºï¼Œå½“æˆ‘ä»¬èƒ½å¤Ÿåˆ¤æ–­è¿™ä¸ªé—®é¢˜æ˜¯convexæ—¶ï¼Œå°±èƒ½æ‰¾åˆ°æœ€ä¼˜è§£ã€‚ä½†æ˜¯è¿˜æœ‰è®¸è®¸å¤šå¤šéçº¿æ€§éå‡¸çš„é—®é¢˜ï¼Œå‡¸ä¼˜åŒ–ç†è®ºä¹Ÿèƒ½æ´¾ä¸Šç”¨åœºã€‚ä¾‹å¦‚ï¼Œåœ¨éå‡¸é—®é¢˜ä¸­ï¼Œåˆå§‹ç‚¹çš„é€‰å–å¯¹äºæœ€ç»ˆè§£çš„è´¨é‡æœ‰å¾ˆå¤§çš„å½±å“ï¼Œæˆ‘ä»¬é¦–å…ˆå¯ä»¥å°†åŸé—®é¢˜è¿‘ä¼¼ä¸ºå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œæ‰¾åˆ°ä¸€ä¸ªæ¯”è¾ƒå¥½çš„è§£ï¼Œå†å°†å…¶ä½œä¸ºç®—æ³•çš„åˆå§‹è§£ï¼Œç”¨äºæ±‚è§£åŸéå‡¸é—®é¢˜ï¼Œä»è€Œä¿è¯æˆ‘ä»¬ä¼šæœ‰ä¸€ä¸ªæ¯”è¾ƒæ»¡æ„çš„å¯è¡Œè§£ã€‚ Figure 3.1 Graph of a convex function. The chord (i.e., line segment) between any two points on the graph lies above the graph. è¿™æ ·çœ‹æ¥ï¼Œå‡¸ä¼˜åŒ–æ˜¯æˆ‘ä»¬æ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„åŸºçŸ³ã€‚è®©æˆ‘ä»¬å›´ç»•å¯¹å‡¸å‡½æ•°çš„è®¨è®ºï¼Œäº†è§£ä¸‹æ•´ä¸ªå‡¸ä¼˜åŒ–é—®é¢˜çš„æ±‚è§£è¿‡ç¨‹ã€‚åœ¨ä¸Šé¢å¯¹å‡¸å‡½æ•°çš„å®šä¹‰ä¸­å…¶å®æ˜¯ä¸ä¸¥è°¨çš„ï¼Œä»…ä»…æ˜¯å¯¹å€¼åŸŸåšäº†çº¦æŸï¼Œå‡¸å‡½æ•°è¿˜è¦æ±‚å®šä¹‰åŸŸæ˜¯å‡¸é›†convex setï¼Œå¦åˆ™å¼å­2å·¦ä¾§æ²¡æœ‰æ„ä¹‰ï¼Œä»å‡ ä½•ä¸Šæ¥è®²ï¼Œå–é›†åˆä¸­ä¸¤ç‚¹ï¼Œå¦‚æœä¸¤ç‚¹è¿æˆçš„çº¿æ®µä»åœ¨é›†åˆä¸­ï¼Œé‚£ä¹ˆè¯¥é›†åˆä¸ºconvex setã€‚i.e. if for any $x_1, x_2\\in C$ and any $\\theta$ with $0\\leq\\theta\\leq1$, we have $$ \\theta x_1+(1-\\theta)x_2\\in C. \\tag{3} $$ Figure 2.2 Some simple convex and nonconvex sets. Left. The hexagon, which includes its boundary (shown darker), is convex. Middle. The kidney shaped set is not convex, since the line segment between the two points in the set shown as dots is not contained in the set. å‡¸å‡½æ•°æœ€é‡è¦çš„æ€§è´¨è«è¿‡äºå±€éƒ¨æœ€ä¼˜$\\iff$å…¨å±€æœ€ä¼˜ï¼Œè¿™æ˜¯ç”±å…¶ä¸€é˜¶æ¡ä»¶First-order conditionså¾—åˆ°çš„ã€‚å‡è®¾å‡½æ•°$f$å¯å¾®ï¼Œ$f$æ˜¯å‡¸å‡½æ•°çš„å……è¦æ¡ä»¶ä¸º$\\operatorname{dom}f$ä¸ºå‡¸é›†ä¸”å¯¹ä»»æ„$x, y\\in\\operatorname{dom}f$ï¼Œä¸‹å¼æˆç«‹ $$ f(y)\\geq f(x)+\\nabla f(x)^T(y-x) \\tag{4} $$ å³ä¾§æ˜¯å‡½æ•°$f$åœ¨$x$å¤„çš„$\\text{Talyor}$å±•å¼€ï¼Œä¸Šå¼è¡¨æ˜ï¼Œæˆ‘ä»¬åªéœ€è¦çŸ¥é“æŸç‚¹çš„å‡½æ•°å€¼ä»¥åŠè¯¥ç‚¹çš„æ¢¯åº¦ï¼ˆå±€éƒ¨ä¿¡æ¯ï¼‰ï¼Œä¾¿èƒ½æ¨å‡ºå‡½æ•°çš„ä¸‹ç•Œï¼ˆå…¨å±€ä¿¡æ¯ï¼‰ã€‚ç‰¹åˆ«åœ°ï¼Œå½“$\\nabla f(x)=0$æ—¶ï¼Œé‚£ä¹ˆå¯¹äºæ‰€æœ‰çš„$y\\in\\operatorname{dom}f$ï¼Œæœ‰$f(y)\\geq f(x)$ï¼Œå³$x$ä¸ºå‡½æ•°$f$çš„å…¨å±€æå°ç‚¹ã€‚ Figure 3.2 If f is convex and diï¬€erentiable, then $f(x)+\\nabla f(x)^T(y-x)\\leq f(y)$ for all $x, y\\in\\operatorname{dom}f.$ å®é™…ä¸Šå‡¸å‡½æ•°æ˜¯ä¸€ç¥¨éš¾æ±‚çš„ï¼Œæˆ‘ä»¬æœ‰ä¸€äº›preserve convexityä¿å‡¸çš„è¿ç®—ï¼Œä¾‹å¦‚éè´ŸåŠ æƒæ±‚å’Œã€affineç­‰ã€‚é™¤äº†æ ¹æ®First-order,second-orderåˆ¤æ–­å‡¸å‡½æ•°å¤–ï¼Œè¿˜å¯é€šè¿‡restricting to a lineã€‚ é™äºç¯‡å¹…ï¼Œæˆ‘ä»¬ä¸å¾—ä¸ç»“æŸå¯¹å‡¸é›†å’Œå‡¸å‡½æ•°çš„è®¨è®ºï¼Œä¸è¦å¿˜äº†ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯æ±‚è§£å¼å­1ä¸­çš„ä¼˜åŒ–é—®é¢˜ï¼Œé‚£å¯¹äºå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œæ˜¯å¦å­˜åœ¨æœ€ä¼˜ç‚¹çš„åˆ¤æ–­å‘¢ï¼Ÿ ä¸‹é¢ç»™å‡ºç›®æ ‡å‡½æ•°$f_0$å¯å¾®ä¸‹çš„æœ€ä¼˜ç‚¹åˆ¤åˆ«å‡†åˆ™ï¼š $\\text{ A feasible point} \\ x\\ \\text{is optimal if and only if}$ $$ \\nabla f_0(\\boldsymbol{x})^T(\\boldsymbol{y}-\\boldsymbol{x})\\geq0\\quad\\text{ for all feasible }\\boldsymbol{y} \\tag{5} $$ Figure 4.2 Geometric interpretation of the optimality condition (4.21). The feasible set $X$ is shown shaded. Some level curves of $f_0$ are shown as dashed lines. The point $x$ is optimal: $-\\nabla f(x)$ deï¬nes a supporting hyperplane(shown as asolid line) to $X$ at $x$ ä¸Šå¼ä»å‡ ä½•è§’åº¦æ˜¯å¾ˆå¥½ç†è§£çš„ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¯è¡Œè§£ä¸­çš„æœ€ä¼˜ç‚¹ï¼Œåšä¸€æ¡åˆ‡çº¿ï¼ˆsupporting hyperplaneï¼‰ï¼Œæ’‘èµ·æ•´ä¸ªå¯è¡Œè§£feasible setï¼Œä¼šå‘ç°åœ¨å¯è¡ŒåŸŸä¸­ä»»æ„å–ä¸€ç‚¹å’Œæœ€ä¼˜ç‚¹æ„æˆçš„å‘é‡ï¼Œå’Œåˆ‡çº¿çš„æ³•çº¿ä½œå†…ç§¯$\\leq0.$ å½“å¼1ä¸­çš„å‡¸ä¼˜åŒ–é—®é¢˜å±äºæ— çº¦æŸé—®é¢˜($i.e., m=0,p=0$)æ—¶ï¼Œå¼1çš„æœ€ä¼˜ç‚¹åˆ¤åˆ«æ¡ä»¶ç®€åŒ–ä¸º: $$ \\nabla f_0(\\boldsymbol{x})=0 \\tag{6} $$ Duality $\\text{Reformulating a problem in convex form is an art, there is no systematic way}.$ å› æ­¤ï¼Œæœ‰æ—¶å½“æˆ‘ä»¬æ— èƒ½ä¸ºåŠ›ï¼Œå¯ä»¥å°è¯•æ±‚è§£åŸå§‹é—®é¢˜çš„å¯¹å¶ã€‚åœ¨è¿™é‡Œï¼Œä»‹ç»ä¸€ç§å¯ä»¥å°†åŸé—®é¢˜æ”¹å†™ä¸ºconvexå½¢å¼çš„æ–¹æ³•ï¼Œè¿™å°±æ˜¯å¤§åé¼é¼çš„Lagrange dualityã€‚å…¶å®é™¤äº†æ‹‰æ ¼æœ—æ—¥å¯¹å¶è¿˜æœ‰å…¶ä»–çš„å¯¹å¶æ–¹æ³•(i.e.Fenchel duality) Dualityçš„æœ€ç»å¦™ä¹‹å¤„åœ¨äºï¼šæ— è®ºåŸå§‹é—®é¢˜æ˜¯å¦ä¸ºå‡¸ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥æ„é€ åŸé—®é¢˜çš„å¯¹å¶å½¢å¼ä¸ºconvexã€‚æ³¨æ„ï¼Œå¯¹å¶å¹¶ä¸æ„å‘³ç€æˆ‘ä»¬ç­‰ä»·è§£å†³äº†åŸé—®é¢˜ï¼Œä½†è¿™èƒ½ä¸ºæˆ‘ä»¬å¯¹åŸé—®é¢˜è¿›è¡Œåˆ†æå¸¦æ¥å¾ˆå¤§çš„å¸®åŠ©ã€‚ Lagrange dulityçš„åŸºæœ¬æ€æƒ³æ˜¯å°†çº¦æŸå‡½æ•°åŠ æƒæ±‚å’Œä¸ç›®æ ‡å‡½æ•°ç›¸åŠ æ„é€ æ–°çš„objective functionã€‚æˆ‘ä»¬å®šä¹‰Lagrange dual funcrtion $g:\\mathbf{R}^m\\times\\mathbf{R}^p\\to\\mathbf{R}$ä¸ºLargrangeå‡½æ•°å…³äº$x$å–å¾—æœ€å°å€¼ï¼šå³å¯¹$\\lambda\\in\\mathbf{R}^{m},{\\nu}\\in\\mathbf{R}^{p}$ï¼Œæœ‰ $$ g(\\lambda,\\nu)=\\inf_{x\\in\\mathcal{D}}L(x,\\lambda,\\nu)=\\inf_{x\\in\\mathcal{D}}\\left(f_0(x)+\\sum_{i=1}^m\\lambda_if_i(x)+\\sum_{i=1}^p\\nu_ih_i(x)\\right). \\tag{7} $$ Since the dual function is the pointwise inï¬mum of a family of aï¬ƒne functions of $\\lambda,\\nu$, it is concave, even when the problem (5.1) is not convex. æˆ‘ä»¬å‡è®¾å¼å­1åŸé—®é¢˜çš„æœ€ä¼˜å€¼ä¸º$p^*=f_0(x^\\star)$ã€‚å®¹æ˜“è¯æ˜ï¼Œå¯¹äºä»»æ„$\\lambda \\succeq0 $å’Œ$\\nu$ï¼Œä¸‹å¼æˆç«‹: $$ g(\\lambda,\\nu)\\leq p^{\\star}.\\tag{8} $$ ä¹Ÿå°±æ˜¯è¯´å¯¹å¶å‡½æ•°æ„æˆäº†æœ€ä¼˜å€¼çš„ä¸‹ç•Œã€‚æˆ‘ä»¬æƒ³é€šè¿‡æœ€å¤§åŒ–$g(\\lambda,\\nu)$ï¼Œä»è€Œæ‰¾åˆ°$p^\\star$æœ€ä½³çš„ä¸‹ç•Œï¼Œè¿™å°±æ„æˆäº†dual problemã€‚Largrange dual problemå½¢å¼åŒ–å¦‚ä¸‹ï¼š $$ \\begin{array}{ll}\\text{maximize}\u0026g(\\lambda,\\nu)\\\\ \\text{subject to}\u0026\\lambda\\succeq0.\\end{array} \\tag{9} $$ æ³¨æ„åˆ°ï¼Œè¿™æ˜¯ä¸€ä¸ªå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå› ä¸ºç›®æ ‡å‡½æ•°æ˜¯concaveå¹¶ä¸”çº¦æŸä¸ºlinearã€‚æˆ‘ä»¬é€šè¿‡å¼å­9å¾—åˆ°çš„æœ€ä¼˜å€¼è®°ä¸º$d^\\star$ï¼Œæ ¹æ®å¼å­8ï¼Œæˆ‘ä»¬æœ‰ $$ d^{\\star}\\leq p^{\\star}. \\tag{10} $$ ä¸Šå¼å¯¹äºåŸé—®é¢˜convexä»ç„¶æˆç«‹ï¼Œç§°ä¸ºweek dualityå¼±å¯¹å¶æ€§ã€‚$p^{\\star} - d^{\\star}$è¢«ç§°ä¸ºduality gapæœ€ä¼˜å¯¹å¶é—´éš™ã€‚å½“å¼å­10å–ç­‰å·æ—¶ï¼Œstrong dualityå¼ºå¯¹å¶æ€§æˆç«‹ã€‚æˆ‘ä»¬è‚¯å®šå¾ˆå¸Œæœ›è¿™æ ·ç†æƒ³çš„æƒ…å†µï¼Œä½†äº‹å®ä¸Šå³ä½¿åŸé—®é¢˜æ˜¯convexï¼Œstrong duality usually(but not always)æˆç«‹ã€‚å½“åŸé—®é¢˜convexä¸”æ»¡è¶³Slaterâ€™s conditionæ—¶ï¼Œå¼ºå¯¹å¶æ€§æ‰æˆç«‹ã€‚ è°ˆåˆ°å¼ºå¯¹å¶æ€§ï¼Œå°±ä¸å¾—ä¸æä¸€ä¸‹KKTæ¡ä»¶äº†ã€‚ $$ \\begin{aligned} f_{i}(x^{\\star})\u0026 \\leq\\quad0,\\quad i=1,\\ldots,m \\\\ h_i(x^{\\star})\u0026 =\\quad0,\\quad i=1,\\ldots,p \\\\ \\lambda_{i}^{\\star}\u0026 \\geq\\quad0,\\quad i=1,\\ldots,m \\\\ \\lambda_{i}^{\\star}f_{i}(x^{\\star})\u0026=\\quad0,\\quad i=1,\\ldots,m \\\\ \\nabla f_0(x^\\star)+\\sum_{i=1}^m\\lambda_i^\\star \\nabla f_i(x^\\star)+\\sum_{i=1}^p\\nu_i^\\star\\nabla h_i(x^\\star)\u0026 =\\quad0\\\\ \\end{aligned}\\tag{11} $$ ä¸Šå¼ä¸­ï¼Œ$x^\\star$å’Œ$\\lambda^\\star,\\nu^\\star$åˆ†åˆ«ä¸ºåŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜çš„æœ€ä¼˜ç‚¹ã€‚å¯¹äºç›®æ ‡å‡½æ•°å’Œçº¦æŸå‡½æ•°å¯å¾®çš„ä»»æ„ä¼˜åŒ–é—®é¢˜ï¼Œè‹¥å¼ºå¯¹å¶æ€§æˆç«‹ï¼Œé‚£ä¹ˆä»»ä¸€å¯¹åŸé—®é¢˜æœ€ä¼˜è§£å’Œå¯¹å¶é—®é¢˜æœ€ä¼˜è§£éƒ½å¿…é¡»æ»¡è¶³KKTæ¡ä»¶ï¼ˆ11ï¼‰ã€‚åœ¨æŸäº›ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€šè¿‡è§£ææ±‚è§£KKTæ¡ä»¶ï¼Œä»è€Œå®Œæˆå¯¹æ•´ä¸ªä¼˜åŒ–é—®é¢˜çš„æ±‚è§£ã€‚ Descent methods ä½†ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªèƒ½é‡‡ç”¨è¿­ä»£ç®—æ³•å¯¹ä¼˜åŒ–é—®é¢˜ï¼ˆå¼å­1ï¼‰è¿›è¡Œæ±‚è§£ï¼Œå³è®¡ç®—ç‚¹åºåˆ—$x^{(0)}, x^{(1)},\\ldots\\in\\operatorname{dom}f$ä½¿å¾—$k\\to\\infty $æ—¶$f_0(x^{(k)})\\to p^{\\star}$ã€‚æ‰€æœ‰è¿­ä»£ç®—æ³•çš„è®¾è®¡åœ¨äºç‚¹åºåˆ—çš„ä¸åŒï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä»å½“å‰ç‚¹æ€æ ·è¿ˆå‘ä¸‹ä¸€ç‚¹ã€‚å¯¹äºDescent methodè€Œè¨€ï¼Œä¸‹å¼æˆç«‹: $$ x^{(k+1)}=x^{(k)}+t^{(k)}\\Delta x^{(k)}\\quad\\text{with }f(x^{(k+1)})","title":"æˆ‘å¯¹ä¼˜åŒ–çš„è®¤è¯†","uri":"/posts/summary_convex_optimization/"},{"content":"è¿‡å»å‡ ä¹æœ‰ä¸€å¹´çš„æ—¶é—´éƒ½åœ¨åšæ¨¡å‹å‹ç¼©ï¼Œä»å‰ªæåˆ°è’¸é¦å†åˆ°é‡åŒ–ï¼Œæœ€åç»„åˆå‹ç¼©ã€‚è™½ç„¶æ²¡åšå‡ºä»€ä¹ˆæˆæœï¼Œä½†è‡³å°‘è§‰å¾—è‡ªå·±çš„ä»£ç èƒ½åŠ›æœ‰è¾ƒå¤§æå‡ï¼Œå¯¹ç§‘ç ”ä¹Ÿæœ‰æ›´æ·±ä¸€å±‚çš„ç†è§£ã€‚\nåˆ°åæ¥åšç»„åˆå‹ç¼©çš„æ—¶å€™ï¼Œå…¶å®è®¤ä¸ºè¿™ä¸æ˜¯ç†æƒ³ä¸­çš„ç§‘ç ”æ¨¡å¼ï¼Œå½“æ—¶å¯¼å¸ˆè®©æˆ‘åšçš„å”¯ä¸€äº‹æƒ…å°±æ˜¯æ— è®ºç”¨ä»€ä¹ˆæ–¹æ³•ï¼Œå°†ç²¾åº¦åˆ·åˆ°sotaã€‚è€Œä¸æ˜¯æŠ±ç€è§£å†³å®é™…é—®é¢˜çš„å¿ƒæ€ï¼Œå»æ¢ç´¢è§£å†³é—®é¢˜ï¼Œå¦‚æœåœ¨è¿‡ç¨‹ä¸­æœ‰ç»“æœï¼Œä»¥è®ºæ–‡å½¢å¼å‘è¡¨ã€‚\nå›è¿‡å¤´å»çœ‹ï¼Œå¤§å­¦ä¸ºä¿ç ”ã€é«˜ä¸­ä¸ºé«˜è€ƒã€åˆä¸­ä¸ºä¸­è€ƒâ€¦è¿™ä¸€è·¯èµ°æ¥åŸºæœ¬ä»¥åŠŸåˆ©ä¸»ä¹‰ä¸ºå¯¼å‘ã€‚ç ”ç©¶ç”Ÿå¸Œæœ›èƒ½å¤Ÿè·³å‡ºè¿™ä¸ªå¾ªç¯ï¼Œå»åšä¸€äº›çœŸæ­£æ„Ÿå…´è¶£è€Œä¸”æœ‰æ„ä¹‰çš„äº‹æƒ…ï¼Œæ¯•ç«Ÿå¾ˆå¯èƒ½ä»¥åä¸åšå­¦ç”Ÿäº†ã€‚\nç°åœ¨ï¼Œæˆ‘ä»¬è¿›å…¥æ­£é¢˜ã€‚æˆ‘çš„ç ”ç©¶æ–¹å‘ä»æ¨¡å‹å‹ç¼©è½¬åˆ°äº†LLM Agentï¼Œä¼°è®¡æ¥ä¸‹æ¥çš„æ—¶é—´éƒ½ä¼šèŠ±åœ¨LLM Agentä¸Šã€‚æœ€è¿‘ç²¾è¯»äº†ä¸€ç¯‡è®ºæ–‡MetaGPTï¼Œæˆ‘å’Œå¸ˆå…„çš„æƒ³æ³•æ˜¯ä¼šå°†å…¶ä½œä¸ºbaselineï¼Œåœ¨å…¶ä¸Šè¿›è¡Œæ”¹è¿›è¿­ä»£ã€‚äºæ˜¯ï¼Œæˆ‘æ‰“ç®—å¼€ä¸€ä¸ªSerieè®²è§£ç ”ç©¶MetaGPTçš„ä¸€äº›æ€è€ƒã€‚\nMetaGPTæ˜¯ä¸€ä¸ªMulti-Agentçš„æ¡†æ¶ï¼Œä½ å°†éœ€æ±‚ä¼ ç»™å®ƒï¼Œç”±å¤šä¸ªagentæ¨¡æ‹Ÿæˆè½¯ä»¶å…¬å¸ï¼Œä»¥ç€‘å¸ƒå¼å¼€å‘å®Œæˆä½ çš„éœ€æ±‚ã€‚\nThe software development SOPs between MetaGPT and real-world human teams. (Image source: Fig 1 in MetaGPT 2023.)\nåœ¨è¿™é‡Œï¼Œä½ å¯èƒ½ä¼šé—®ä»€ä¹ˆæ˜¯Agent? æˆ‘å…ˆä¸å¿™ç»™å‡ºå®Œæ•´ä¸¥è°¨çš„å®šä¹‰ï¼Œåç»­æˆ‘ä¼šå†™ä¸€ç¯‡blogä¸“é—¨è®¨è®ºæˆ‘ä»¬å¯¹AgentèŒƒå¼çš„æŠ½è±¡ã€‚\næœ¬æ–‡é‡ç‚¹è®¨è®ºMetaGPTçš„ä»£ç è®¾è®¡ã€‚å› æ­¤ï¼Œä½ å¯ä»¥æš‚æ—¶å°†Agentç†è§£ä¸ºå¯¹LLMèµ‹äºˆä¸€ä¸ªè§’è‰²ï¼Œä¾‹å¦‚ä½ å¯¹LLMè¿›è¡Œpromptä¸ºYou are a profession engineer, your goal is to write beautiful codes...ï¼Œå¾—åˆ°promptåï¼ŒLLMæ‘‡èº«ä¸€å˜ï¼Œæˆä¸ºEngineer Agentã€‚\né‚£ä¹ˆï¼ŒMetaGPTæ˜¯å¦‚ä½•ç”¨ä»£ç å®ç°çš„å‘¢ï¼Ÿ\næˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹MetaGPTä¸­ç±»çš„ç»„ç»‡ï¼Œä¸‹å›¾æ˜¯æˆ‘å°†MetaGPTä¸­ä¸»è¦çš„ç±»æå‡ºæ¥ï¼Œç”»äº†ä¸€ä¸ªUMLå›¾ã€‚\nteamç±»å†³å®šæœ‰å“ªäº›Role(å³Agent)ï¼Œå®Œæˆæ€æ ·çš„é¡¹ç›®ä»¥åŠé¡¹ç›®çš„æŠ•èµ„æˆæœ¬(è°ƒLLMAPIéœ€è¦é’±)ï¼Œå¹¶è´Ÿè´£å¯åŠ¨é¡¹ç›®ã€‚ Roleç±»åˆ™è¯´æ˜ä¸€ä¸ªRoleçš„åŸºæœ¬ä¿¡æ¯ï¼Œå·¥ä½œæ¨¡å¼æ˜¯æ€æ ·çš„ï¼Œä»¥åŠèƒ½å¤Ÿåšå‡ºå“ªäº›åŠ¨ä½œã€‚ Environmentç±»åˆ™æ˜¯ä¸ºRoleä¹‹é—´ä¿¡æ¯çš„äº¤æµæä¾›ä¸€ä¸ªå¹³å°ï¼Œç±»ä¼¼äºæ²Ÿé€šçš„æ¡¥æ¢ã€‚ï¼ˆæ˜¯ä¸æ˜¯æœ‰ç‚¹ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼çš„æ„Ÿè§‰ï¼‰ Actionç±»åˆ™æ˜¯å¯¹Roleèƒ½å¤Ÿé‡‡å–åŠ¨ä½œçš„æŠ½è±¡ï¼Œä¾‹å¦‚Writecode,WritePRDï¼Œè€ŒActionNode1åˆ™æ˜¯å¯¹ä¸€ä¸ªåŠ¨ä½œçš„æ‹†è§£ï¼Œå°†å…¶åˆ†ä¸ºå¤šä¸ªèŠ‚ç‚¹ã€‚Memoryç±»è´Ÿè´£å­˜å‚¨Roleçš„å†å²ä¿¡æ¯ã€‚ å…¶ä½™çš„ç±»åˆ™æ˜¯ä¸ºå¯¹åº”çš„ç±»æä¾›ä¸€äº›ä¸Šä¸‹æ–‡å’Œé…ç½®ä¿¡æ¯ã€‚ äº†è§£å®ŒMetaGPTçš„ç»„ç»‡ï¼Œåœ¨å®é™…çš„è¿è¡Œä¸­åˆæ˜¯æ€æ ·å‘¢ï¼Ÿ\nä¸Šå›¾æ˜¯ä¸€ä¸ªä¸å¤ªä¸¥è°¨çš„æ—¶åºå›¾ï¼Œæè¿°äº†æ•´ä¸ªé¡¹ç›®çš„è¿è¡Œè¿‡ç¨‹ï¼Œå¤§æ¦‚å¯åˆ†ä¸º3ä¸ªé˜¶æ®µã€‚\næˆ‘ä»¬å°†éœ€æ±‚ideaé€šè¿‡å‘½ä»¤è¡Œä¼ ç»™ç¨‹åºã€‚ è½¯ä»¶å…¬å¸å°†ideaå‘å¸ƒåˆ°ç¯å¢ƒä¸­ï¼Œç„¶åéå†æ‰€æœ‰çš„Roleï¼Œæ¯ä¸ªRoleå°†ideaæ¶ˆæ¯æ”¾å…¥åˆ°æ¶ˆæ¯æ± ä¸­ã€‚ è½¯ä»¶å…¬å¸å¼€å§‹è¿è¡Œæ•´ä¸ªé¡¹ç›®ï¼Œå®Œæˆéœ€æ±‚ã€‚éå†æ¯ä¸ªRoleï¼ŒRoleä»æ¶ˆæ¯æ± ä¸­å¼¹å‡ºæ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå·±éœ€è¦å¤„ç†çš„æ¶ˆæ¯ï¼Œè‹¥å¦åˆ™ä¸åšä»»ä½•å¤„ç†ï¼Œå¦åˆ™ï¼Œä¸LLMäº¤äº’æ‹¿åˆ°å¤„ç†åçš„ç»“æœï¼Œå°è£…æˆæ¶ˆæ¯å‘å¸ƒåˆ°ç¯å¢ƒä¸­ã€‚ æ•´ä¸ªç¨‹åºç»ˆæ­¢çš„æ¡ä»¶æœ‰ä¸¤ä¸ªï¼Œåˆ†åˆ«æ˜¯è¶…è¿‡investmentå’Œn_roundä¸º0ã€‚n_roundçš„å€¼å†³å®šäº†ä¼šæœ‰å¤šå°‘ä¸ªRoleå¤„ç†æ¶ˆæ¯ï¼Œæ‰§è¡ŒåŠ¨ä½œã€‚åœ¨roundä¸­ï¼Œæˆ‘ä»¬ä¼šç»™æ¯ä¸ªRoleä¸€æ¬¡æ‰§è¡ŒåŠ¨ä½œçš„é€‰æ‹©æƒï¼Œè€Œç€‘å¸ƒå¼å¼€å‘çš„æ¨¡å¼å†³å®šäº†æ¯ä¸ªæ¶ˆæ¯æœ‰ä¸”åªèƒ½ç”±ä¸€ä¸ªRoleå¤„ç†ã€‚\nè€Œåœ¨å…·ä½“çš„å®ç°ä¸Šï¼Œä¸»è¦ä¾é ä¸¤ä¸ªåŒ…ï¼Œåˆ†åˆ«æ˜¯ä½¿ç”¨asyncioå®ç°å¹¶å‘å’Œåˆ©ç”¨Pydanticå®ç°å¯¹æ•°æ®çš„ç»„ç»‡å’Œå°è£…ã€‚\næœ€åï¼Œä¸ªäººè®¤ä¸ºMetaGPTé¡¹ç›®çš„ä»£ç æ˜¯å†™çš„å¾ˆæ¼‚äº®çš„ã€‚å¯¹äºæ¯”è¾ƒéš¾æ‡‚çš„åœ°æ–¹é‡‡ç”¨äº†googleé£æ ¼çš„æ³¨é‡Šæé«˜äº†å¯è¯»æ€§ï¼Œæ­¤å¤–ï¼Œä»£ç å…·æœ‰è‰¯å¥½çš„æ¨¡å—åŒ–è®¾è®¡ï¼Œå¯¹äºä¸åŒä»£ç æ–‡ä»¶çš„ç»„ç»‡å’Œå°è£…åšå¾—å¾ˆå¥½ã€‚\n# ä¸‹é¢æ˜¯ä¸€ä¸ªgoogleé£æ ¼æ³¨é‡Šçš„ä¾‹å­ def add_numbers(a, b): \"\"\" Adds two numbers and returns the result. Args: a (int): The first number. b (int): The second number. Returns: int: The sum of the two numbers. Raises: TypeError: If either `a` or `b` is not an integer. \"\"\" if not isinstance(a, int) or not isinstance(b, int): raise TypeError('Both a and b must be integers') return a + b References Hong S, Zheng X, Chen J, et al. Metagpt: Meta programming for multi-agent collaborative framework[J]. arXiv preprint arXiv:2308.00352, 2023. RFC-116-MetaGPT Roleå¯¹è±¡é—´æ¶ˆæ¯æœºåˆ¶ä¼˜åŒ–æ–¹æ¡ˆ MultiAgent 101 ","title":"The Design of MetaGPT","uri":"/posts/design_of_metagpt/"},{"content":"æœ€è¿‘åœ¨ç ”ç©¶Transformerï¼Œç»å¸¸ç¢°åˆ°KV-Cacheï¼Œæ¯æ¬¡éƒ½è¦å»æŸ¥ä¸€ä¸‹æ‰èƒ½å›æƒ³èµ·æ¥è¿™ä¸ªä¸œè¥¿ã€‚ä½†ç¨å¾®ç ”ç©¶äº†ä¸€ä¸‹ï¼Œè§‰å¾—kv-cacheä»æ•°å­¦ä¸Šæ¥è¯´æ˜¯éå¸¸æ˜¾ç„¶çš„ï¼Œåœ¨è¿™é‡Œæ€»ç»“ä¸€ä¸‹æˆ‘å¯¹kv-cacheçš„ç†è§£ã€‚ KV-Cacheæºè‡ªäºTransformerï¼Œå…¨ç§°æ˜¯Key-Value Cacheï¼Œä¹Ÿå°±æ˜¯å¯¹Keyå’ŒValueçš„ç¼“å­˜ã€‚ Transformerç›¸å¯¹äºCNNæœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯å¼•å…¥äº†Attentionè®¡ç®—ï¼Œå…¶è®¡ç®—å…¬å¼å¦‚ä¸‹: $$ \\mathrm{Attention}(Q,K,V)=\\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V \\tag{1} $$ å…¶ä¸­$Q,K,V$åˆ†åˆ«ä»£è¡¨Queryã€Keyå’ŒValueçŸ©é˜µï¼Œ$d_k$ä»£è¡¨Scaling factorï¼Œå±äºå®æ•°ã€‚æ‰€è°“KV-Cacheä¾¿æ˜¯åœ¨Attentionè®¡ç®—ä¸­ï¼Œé€šè¿‡å¯¹Keyå’ŒValueè¿›è¡Œç¼“å­˜ï¼Œä»è€Œå‡å°ä¸å¿…è¦çš„å¼€é”€ï¼Œè¿™é‡Œâ€œä¸å¿…è¦â€æŒ‡ç”±äºæˆ‘ä»¬å·²ç»ç¼“å­˜äº†éƒ¨åˆ†Keyå’ŒValueï¼Œå› æ­¤ä¸éœ€è¦å†è¿›è¡Œé‡å¤è®¡ç®—ä»¥å¾—åˆ°è¿™éƒ¨åˆ†Keyå’ŒValueï¼Œä½¿ç”¨ä¹‹å‰è®¡ç®—å¥½äº†çš„å³å¯ã€‚ é‚£ä¹ˆä¸ºä»€ä¹ˆè¯´åç»­çš„Attentionè®¡ç®—ä¸­ä¼šç”¨åˆ°ä¹‹å‰çš„Keyå’ŒValueå‘¢ï¼Ÿè¿™å°±è¦è®²ä¸€ä¸‹Transformeræ˜¯å¦‚ä½•è¿›è¡Œæ¨ç†äº†ã€‚ In the auto-regressive generation of the decoder, given an input the model predicts the next token, and then taking the combined input in the next step the next prediction is made. (Image source: https://jalammar.github.io/illustrated-gpt2/). å¦‚ä¸Šå›¾æ‰€ç¤ºGPT-2ä½¿ç”¨çš„æ˜¯Transformerçš„decoderæ¶æ„ï¼Œè¿™ç±»æ¨¡å‹åœ¨æ¨ç†æ—¶é‡‡å–çš„æ˜¯auto-regressiveè‡ªå›å½’å¼çš„é£æ ¼ï¼Œå…·ä½“çš„è¯´ï¼Œåœ¨ç¬¬$i$ä¸ªroundæ—¶ï¼Œæ¨¡å‹è¾“å‡º1ä¸ªtokenï¼Œä¾‹å¦‚ä¸Šå›¾ä¸­çš„â€œrobotâ€ã€‚ åˆ°äº†ç¬¬$i+1$ä¸ª$\\mathrm{round}$æ¨¡å‹ä¼šç»§ç»­æ¨ç†ï¼Œä½†è¿™æ—¶æ¨¡å‹çš„è¾“å…¥ä¼šå‘ç”Ÿå˜åŒ–ï¼Œå®ƒä¼šå°†ä¸Šä¸ª$\\mathrm{round}$é¢„æµ‹å¾—åˆ°çš„tokenï¼Œâ€œrobotâ€ appendåˆ°ç¬¬$i$ä¸ª$\\mathrm{round}$çš„è¾“å…¥recite ... Açš„åé¢ï¼Œä½œä¸ºç¬¬$i+1$ä¸ª$\\mathrm{round}$æ¨¡å‹è¾“å…¥ã€‚ è¿™é‡Œå¯ä»¥ç¨å¾®çœ‹ä¸‹Transformeræ¨ç†çš„æºç ï¼Œauto-regressiveçš„ä½“ç°ä¾¿æ˜¯åœ¨torch.catå‡½æ•°ã€‚ # Generate the translation word by word while decoder_input.size(1) \u003c seq_len: # build mask for target and calculate output decoder_mask = torch.triu(torch.ones((1, decoder_input.size(1), decoder_input.size(1))), diagonal=1).type(torch.int).type_as(source_mask).to(device) out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask) # project next token prob = model.project(out[:, -1]) _, next_word = torch.max(prob, dim=1) decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1) # print the translated word print(f\"{tokenizer_tgt.decode([next_word.item()])}\", end=' ') # break if we predict the end of sentence token if next_word == tokenizer_tgt.token_to_id('[EOS]'): break ä¸€å¥è¯æ€»ç»“ï¼Œauto-regressiveç±»æ¨¡å‹ä¼šå°†é¢„æµ‹çš„ç»“æœConcatenateåˆ°è¾“å…¥æœ«å°¾ä½œä¸ºæ–°çš„è¾“å…¥ï¼Œç„¶åç»§ç»­é¢„æµ‹ã€‚ äº†è§£äº†Transformeræ˜¯å¦‚ä½•æ¨ç†çš„ï¼Œæˆ‘ä»¬å†å›åˆ°Attentionçš„è®¡ç®—ã€‚ å‡è®¾ä»$\\mathrm{round_1}$å¼€å§‹æ¨¡å‹è¾“å…¥æ˜¯1ä¸ªtokenï¼Œåœ¨å…·ä½“çš„å®ç°ä¸Šï¼Œæˆ‘ä»¬ä¼šç”¨Vectorå‘é‡æ¥è¡¨ç¤º1ä¸ªtokenï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨cvä¸­ç”¨çŸ©é˜µè¡¨ç¤ºå›¾åƒé‚£æ ·ï¼Œæˆ‘ä»¬è®°è¿™ä¸ªtokenè¾“å…¥å‘é‡ä¸º$x_1$ï¼Œä¸ºäº†æ–¹ä¾¿åç»­æ•°å­¦è¡¨è¾¾ï¼Œå½“æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‘é‡æ—¶ï¼Œé»˜è®¤å®ƒä¸ºè¡Œå‘é‡ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçº¿ä»£ä¸­é»˜è®¤å‘é‡ä¸ºåˆ—å‘é‡ã€‚ è¿™é‡Œé¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œåœ¨Transformerçš„ä»£ç å®ç°ä¸Šï¼ŒAttentionæœºåˆ¶ä¸­çš„$Q_w,K_w,V_w\u2028$æ˜¯ä¸€ç»„å¯å­¦ä¹ çš„æƒé‡å‚æ•°ï¼Œç”¨nn.Linearæ¥è¡¨ç¤ºçš„çº¿æ€§å±‚ã€‚ åœ¨$\\mathrm{round_1}$æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†$x_1$åˆ†åˆ«å’Œ$Q_w,K_w,V_w\u2028$ç›¸ä¹˜å¾—åˆ° $q_1,k_1,v_1$ï¼Œç„¶åå¸¦å…¥åˆ°ç­‰å¼1ä¸­å®ŒæˆAttentionçš„è®¡ç®—ã€‚æ•´ä¸ªæ¨¡å‹forwardç»“æŸï¼Œä¼šå¾—åˆ°æ¨¡å‹è¾“å‡ºçš„1ä¸ªtokenï¼Œæˆ‘ä»¬æŠŠå®ƒè®°ä¸º$x_2$ã€‚ åœ¨$\\mathrm{round_2}$æ—¶ï¼Œæˆ‘ä»¬å°†$x_1, x_2$ç»„åˆä½œä¸ºè¾“å…¥ï¼Œå’Œ$Q_w,K_w,V_w\u2028$åšçŸ©é˜µä¹˜å¾—åˆ°$q_1, q_2$,$k_1,k_2$ä»¥åŠ$v_1 v_2\u2028$ã€‚ åœ¨$\\mathrm{round_n}$æ—¶ï¼Œæˆ‘ä»¬æ‰‹é‡Œæœ‰$x_1,x_2,â€¦x_n$ï¼Œè®°$X=\\begin{pmatrix}x_1\\\\x_2\\\\ \\vdots\\\\x_n\\end{pmatrix}$ã€‚æˆ‘ä»¬å°†$X$åˆ†åˆ«ä¸$Q_w,K_w,V_w\u2028$ç›¸ä¹˜å¾—åˆ°$Q,K,V$ æœ‰äº†$Q,K,V$ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Attentionçš„è®¡ç®—ï¼Œæ³¨æ„Attentionè®¡ç®—çš„å…³é”®åœ¨äºQKVçŸ©é˜µä¹˜ï¼Œsoftmaxå¯¹æ¯ä¸€è¡Œå…ƒç´ åšå½’ä¸€åŒ–ï¼ŒScaling factorå¯¹çŸ©é˜µä¸­æ¯ä¸ªå…ƒç´ çš„valueåšæ”¾ç¼©ï¼Œæ€»çš„æ¥è¯´softmaxå’ŒScaling factoréƒ½åªæ˜¯å¯¹çŸ©é˜µä¸­å…ƒç´ å€¼åšæ”¾ç¼©ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿½ç•¥softmaxå’ŒScaling factorå¹¶ä¸ä¼šå¯¹KV-Cacheçš„ç†è§£æœ‰å½±å“ã€‚é‚£ä¹ˆï¼ŒAttentionçš„è®¡ç®—å±•å¼€æˆå‘é‡å½¢å¼å¦‚ä¸‹ï¼š $$ \\mathrm{Attention}(Q,K,V) \\approx \\begin{pmatrix}q_1 \\\\q_2 \\\\ \\vdots\\\\q_n\\end{pmatrix}\\begin{pmatrix}k^T_1, k^T_2,\\cdots, k^T_n\\end{pmatrix}\\begin{pmatrix}v_1 \\\\v_2 \\ \\vdots\\\\v_n\\end{pmatrix}\\\\ =\\begin{pmatrix}q_1k^T_1\u0026\u0026\u0026\\\\q_2k^T_1\u0026q_2k^T_2\u0026\u0026\\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\\\q_nk^T_1\u0026q_nk^T_2\u0026\\cdots\u0026q_nk^T_n\\end{pmatrix}\\begin{pmatrix}v_1 \\\\v_2 \\\\ \\vdots\\\\v_n\\end{pmatrix}\\\\ =\\begin{pmatrix}q_1k^T_1v_1 \\\\q_2k^T_1v_1 + q_2k^T_2v_2 \\\\ \\vdots\\\\q_nk^T_1v_1 + q_nk^T_2v_2+\\cdots+q_nk^T_nv_n\\end{pmatrix} \\tag{2} $$ æ³¨æ„åœ¨ä¸Šé¢ç¬¬äºŒæ­¥æ¨å¯¼ä¸­ï¼Œ$QK^T$æ˜¯ä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µï¼Œå› ä¸ºåœ¨$\\mathrm{round_i}$æ—¶ï¼Œæˆ‘ä»¬ä»…æœ‰$q_j,k_j,v_j$å…¶ä¸­$j \\leq i$ã€‚ä»¤$A$è¡¨ç¤ºå¼å­2ä¸­çš„æœ€ç»ˆç»“æœï¼Œ$A$çš„ç¬¬$i$ä¸ªè¡Œå‘é‡$A_i=\\sum_{j}^{i}q_ik_j^Tv_j$ã€‚ çœ‹åˆ°è¿™é‡Œï¼Œä¸çŸ¥é“ä½ æœ‰æ²¡æœ‰ä¸€ç§æç„¶å¤§æ‚Ÿçš„æ„Ÿè§‰ğŸ˜‰ã€‚ç”±äºæˆ‘ä»¬åœ¨$\\mathrm{round_{j \u003c i}}$çš„è¿‡ç¨‹ä¸­ï¼Œç¼“å­˜äº†$k_j,v_j$ï¼Œé‚£ä¹ˆåœ¨$\\mathrm{round_i}$æ—¶æˆ‘ä»¬åªéœ€è¦å†è®¡ç®—ä¸€ä¸‹$k_i,v_i$ï¼Œå¤ç”¨ç¼“å­˜çš„keyå’Œvalueä¾¿èƒ½å®Œæˆæ•´ä¸ªAttentionçš„è®¡ç®—ã€‚ è¿™é‡Œå¯ä»¥å†å¤šæ‰¯ä¸€ä¸‹ï¼ŒKV-Cacheçš„å”¯ä¸€ä½œç”¨ä¾¿æ˜¯é¿å…å†—ä½™è®¡ç®—ã€‚åœ¨Transformerçš„è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¯ä¸å­˜åœ¨KV-cacheçš„ï¼Œå› ä¸ºåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªå¥å­çš„å‰n-1ä¸ªtokenå–‚ç»™æ¨¡å‹ï¼Œå°†é¢„æµ‹å¾—åˆ°çš„tokenå’Œground truthåšcross-entropyï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¯one-shoté£æ ¼è€Œä¸æ˜¯è‡ªå›å½’å¼çš„ï¼Œè®­ç»ƒä»£ç ä¸ºè¯ã€‚ for i, batch in enumerate(iterator): src = batch.src trg = batch.trg optimizer.zero_grad() output = model(src, trg[:, :-1]) output_reshape = output.contiguous().view(-1, output.shape[-1]) trg = trg[:, 1:].contiguous().view(-1) loss = criterion(output_reshape, trg) loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), clip) optimizer.step() KV-caheä»…å­˜åœ¨äºæ¨ç†é˜¶æ®µï¼Œè€Œä¸”åªå­˜åœ¨äºdecoderä¸­ã€‚ä¸‹å›¾æ˜¯Transformerç»“æ„ï¼Œåœ¨å³ä¾§decoderä¸­ï¼ŒMulti-Head Attentionæ¨¡å—çš„Keyå’ŒValueæ¥è‡ªäºEncoderçš„è¾“å‡ºï¼Œæ˜¯ä¸€æ¬¡æ€§å…¨éƒ¨ç”Ÿæˆå¥½äº†çš„ï¼Œå› æ­¤æˆ‘ä»¬é€šå¸¸æ˜¯åœ¨è®©decoderé¢„æµ‹å‰åœ¨å†…å­˜ä¸­ç¼“å­˜å¥½encoderçš„outputï¼Œä½œä¸ºKeyå’ŒValueç”¨äºcross-Attentionçš„è®¡ç®—ã€‚è€Œdecoderä¸­çš„Masked Multi-Head Attentionæ¨¡å—ä¾¿æ˜¯ä¸Šæ–‡æ‰€è®²ï¼Œåœ¨é€tokençš„ç”Ÿæˆä¸­ä¸æ–­ç¼“å­˜key-valueã€‚ The full model architecture of the transformer. (Image source: Fig 1 \u0026 2 in Vaswani, et al., 2017.) References Transformers KV Caching Explained pytorch-transformer Ashish Vaswani, et al. â€œAttention is all you need.â€ NIPS 2017. Transformer: PyTorch Implementation of â€œAttention Is All You Needâ€ ","title":"KV Cache in Transformer","uri":"/posts/kv_cache_transformer/"},{"content":" æˆ‘çŸ¥é“ é‚£äº›å¤å¤© å°±åƒé’æ˜¥ä¸€æ ·å›ä¸æ¥ ä»£æ›¿æ¢¦æƒ³çš„åªèƒ½æ˜¯å‹‰ä¸ºå…¶éš¾ ä»ä»Šå¹´å¼€å§‹ï¼Œæˆ‘æ‰“ç®—æ¯å¹´å†™ä¸€æ¬¡å¹´åº¦æ€»ç»“ï¼Œå¯¹æ˜¨å¹´è‡ªå·±çš„å­¦ä¹ ç”Ÿæ´»è¿›è¡Œæ¢³ç†æ€»ç»“ï¼Œå¸Œæœ›èƒ½å¤Ÿå¯¹æœªæ¥å¸¦æ¥ä¸€äº›å¯ç¤ºã€‚è€Œå¹´åº¦æ€»ç»“çš„æ ‡é¢˜ï¼Œå¦‚æœæ¯æ¬¡éƒ½ä»¥xxxxå¹´åº¦æ€»ç»“ä»¥é¢˜æ˜¾å¾—å¤ªæ²¡æœ‰ç‰¹è‰²ã€‚æ‰€ä»¥ï¼Œæˆ‘å†³å®šè‡ªæ‹Ÿæ ‡é¢˜ï¼Œä¸€äº›æ­Œã€è¯—è¯ã€æ–‡ç« è¨€è®ºéƒ½åœ¨è€ƒè™‘èŒƒå›´å†…ã€‚23å¹´ä¾¿ä»¥å®‹å†¬é‡çš„ã€Šå®‰æ²³æ¡¥ã€‹ä¸ºé¢˜å§ã€‚ 23å¹´ï¼Œå›è¿‡å¤´çœ‹æ¥æ˜¯ä¸€ä¸ªå°ç™½æ‘¸ç´¢ç§‘ç ”ï¼Œä¸æ–­è¯•é”™å…¥é—¨çš„ä¸€å¹´ã€‚22å¹´å› ä¸ºç–«æƒ…ï¼Œæ‰€ä»¥å­¦æ ¡12æœˆåº•æ”¾å‡äº†ã€‚æˆ‘è®°å¾—å½“æ—¶ç©¿ç€ä¸€èº«é˜²æŠ¤æœå›å®¶ï¼Œç»“æœè¿˜æ˜¯é˜³äº†\u003e_\u003cã€‚ä½†è¿˜å¥½ï¼Œæœ‰æ¯äº²åœ¨å®¶ç…§é¡¾æˆ‘ï¼Œåæ¥é€æ¸æ¢å¤äº†ï¼Œæ¯äº²è¯´æƒ³å¸¦æˆ‘å‡ºå»èµ°èµ°ï¼Œæˆ‘ä»¬ä¾¿é©±è½¦æ¥åˆ°ä¸‡æºå…«å°å±±åº¦è¿‡äº†å…ƒæ—¦ã€‚ å¯’å‡è¿™ä¸€ä¸ªå¤šæœˆçš„æ—¶é—´ï¼Œä¸»è¦è¿˜æ˜¯åœ¨åšæ¯•è®¾ï¼Œåœ¨ç©ºä½™æ—¶é—´åŸºæœ¬è¯»å®Œäº†ã€Šåˆ«é—¹äº†ï¼Œè´¹æ›¼å…ˆç”Ÿã€‹ä»¥åŠæ—å¥•å«çš„ã€Šæˆ¿æ€çªçš„åˆæ‹ä¹å›­ã€‹ã€‚æˆ‘æ˜¯æ˜¯é€šè¿‡ä¸€ä¸ªå…³äºFeynmançš„è®¿è°ˆäº†è§£åˆ°æ­¤äººçš„ï¼Œè¯¥ä¹¦é€šè¿‡è®²è¿°Richard Feynmançš„ç”Ÿå¹³ä»¥åŠä¸€äº›è¶£äº‹ï¼Œè®©æˆ‘çœ‹åˆ°äº†ä¸€ä½ç‰©ç†å­¦å®¶çš„çº¯çœŸä»¥åŠé‚£ç§å±•ç°å‡ºæ¥çš„å¯¹å‘¨å›´ç”Ÿæ´»çš„çƒ­çˆ±ä¸å¥½å¥‡ï¼è€Œæ—å¥•å«çš„ã€Šæˆ¿æ€çªçš„åˆæ‹ã€‹è¿™æœ¬ä¹¦ï¼Œæˆ‘æ˜¯åœ¨ä¸Šå­¦æ ¡çš„ã€Šä¸­å¤–åè‘—å¯¼è¯»ã€‹è¯¾å ‚ä¸Šäº†è§£åˆ°çš„ï¼Œå‘¨è€å¸ˆè¯´å»ºè®®æ¯ä½å¥³ç”Ÿéƒ½åº”è¯¥è¯»ä¸€è¯»è¿™æœ¬ä¹¦ï¼Œç„¶è€Œæˆ‘ä¹Ÿè¯»äº†ï¼Œè¯»çš„è¿‡ç¨‹ä¸­æ„Ÿåˆ°å¾ˆæ‚²ç—›ï¼Œæœ€åå†™äº†ä¹¦è¯„ã€‚ æ­¤å¤–ï¼Œæˆ‘è¿˜åœ¨é›¶ç¢æ—¶é—´å¬å®Œäº†å•ç”°èŠ³å…ˆç”Ÿçš„è¯„ä¹¦ã€Šæ›¾å›½è—©ã€‹ï¼Œè¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡å¬è¯„ä¹¦ï¼Œæ‰€ä»¥è¿˜å†™äº†å¬åæ„Ÿã€‚å…¶å®ï¼Œæœ€å¼€å§‹æ˜¯åœ¨å–œé©¬æ‹‰é›…ä¸Šå¬ã€Šæ›¾å›½è—©å®¶ä¹¦ã€‹ï¼Œä½†æˆ‘è§‰å¾—å¾—å…ˆäº†è§£ä¸€ä¸‹æ›¾å›½è—©ï¼Œå†å»å¬å®¶ä¹¦ä¼šæ¯”è¾ƒæœ‰ä½“ä¼šï¼Œäºæ˜¯ä¾¿æ‰¾æ¥äº†å•è€çš„è¯„ä¹¦å¬ã€‚é€šè¿‡å®¶ä¹¦ä»¥åŠæ›¾å›½è—©çš„ç”Ÿå¹³ï¼Œæˆ‘å­¦ä¹ åˆ°äº†å¾ˆå¤šä¸ºäººä¸ºå­¦å¤„äº‹çš„é“ç†ï¼Œä¸å¾—ä¸è¯´æ›¾å›½è—©æ˜¯è‡ªå¾‹çš„å…¸èŒƒï¼Œæ˜¯å€¼å¾—æ¯ä¸ªæ™®é€šäººå­¦ä¹ çš„ã€‚ è€Œå¯’å‡è¿™æ®µæ—¶é—´çš„ä½œæ¯ï¼Œåˆšå¼€å§‹æ—¶è¿˜æ˜¯æŒ‰ç…§ä»¥å¾€åœ¨å­¦æ ¡çš„ä¹ æƒ¯ï¼Œ23ç‚¹ç¡6:30èµ·ï¼Œä½†ç”±äºå¾—äº†æ–°å† ï¼Œåé¢å°±å˜æˆäº†æ—©ç¡ä½†7-8ç‚¹ä¹‹é—´èµ·åºŠäº†ğŸ˜…ï¼Œå†åŠ ä¸Šè¿‡å¹´èµ°äº²è®¿å‹çš„ä¸€äº›åŸå› ï¼Œæ—©èµ·è¯»ä¹¦ä¾¿æ–­æ–­ç»­ç»­çš„ï¼Œåœ¨å®¶æ—©è¯»å¦‚æœæ²¡æœ‰ç‰¹æ®ŠåŸå› ï¼Œæˆ‘ä¸€èˆ¬æ˜¯æŒ‰ç…§è‡ªå·±çš„å…´è¶£æ¥ï¼Œå…ˆè¯»åŠå°æ—¶æ¨å¸…è€å¸ˆçš„èƒŒä¸‰å¥ç»ƒä¹ è‹±è¯­å£è¯­ï¼Œå†èŠ±åŠå°æ—¶æœ—è¯»æœç”«çš„è¯—æ­Œå’Œè€å­çš„ã€Šé“å¾·ç»ã€‹ã€‚æˆ‘å¾ˆå–œæ¬¢æœç”«çš„è¯—ï¼Œæ²‰éƒé¡¿æŒ«é£æ ¼ï¼Œè±ªè¿ˆå¤§æ°”çš„æ„å¢ƒï¼Œæ·±æ²‰æµ“çƒˆçš„æ„Ÿæƒ…ï¼Œå€¼å¾—åå¤æœ—è¯µå“å‘³ åœ¨ä¸´è¿‘å¼€å­¦çš„é‚£å‡ å¤©ï¼Œæˆ‘æŠ½ç©ºå›äº†è¶Ÿç»µé˜³ï¼Œçœ‹äº†çœ‹å—å±±ä¸­å­¦ï¼Œå¹¶å’Œåˆé«˜ä¸­åŒå­¦è§äº†è§ï¼Œå››å¹´æ¥ç¬¬ä¸€æ¬¡ç›¸äº¤ï¼Œæˆ‘æ„Ÿè§‰å¤§å®¶çš„å¢ƒé‡ã€å˜åŒ–éƒ½æŒºå¤§çš„ï¼Œé€šè¿‡è¿™å‡ æ¬¡èŠå¤©ï¼Œæˆ‘ä¹Ÿå¯¹è‡ªå·±æœªæ¥çš„è§„åˆ’æ›´åŠ åšå®šäº†ï¼Œåœ¨é‡åº†çš„æ±ŸåŒ—æœºåœºå€™æœºæ—¶ï¼Œæˆ‘å†™ä¸‹äº†å¯’å‡ä»¥åŠç»µé˜³è¡Œçš„æ€»ç»“â€”â€”äºæˆ‘è€Œè¨€ï¼Œç ”ç©¶ç”Ÿè¿™ä¸‰å¹´ï¼Œæˆ‘æƒ³æ²‰æ·€ä¸‹æ¥ï¼Œè¿½æ±‚å­¦æœ¯ï¼Œçœ‹è‡ªå·±æ˜¯å¦é€‚åˆåšç§‘ç ”ã€‚ å¼€å­¦åï¼Œæ—©è¯»çš„åŠŸè¯¾æ¢æˆäº†èƒŒä¸‰å¥å’Œè®ºè¯­ï¼Œä»2æœˆä»½ä¸€ç›´åˆ°4æœˆä»½ï¼Œä¸€ç›´åœ¨å¿™æ¯•è®¾ï¼ŒæŠ½ç©ºè¯»å®Œäº†ã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ã€‹ï¼Œä¸»è¦æ˜¯æƒ³çœ‹çœ‹å¦‚ä½•deep Learning from scratchğŸ˜‹ã€‚è€Œå¯¹äºè¿™ä¸ªæ¯•è®¾ï¼Œç°åœ¨çœ‹æ¥æ„Ÿè§‰å¥½trivialï¼Œåªæ˜¯åœ¨ITPrunerä¸ŠåŠ äº†ä½ç§©åˆ†è§£ï¼Œå¦‚æœé‡æ¥ä¸€éï¼Œå¯èƒ½ä¼šæŒ‰ç…§å¯¼å¸ˆè¯´çš„ç”¨Mindsporeé‡æ–°å®ç°ä¸€éï¼Œè™½ç„¶æœ‰é£é™©ï¼Œä½†è¦è¸å‡ºèˆ’é€‚åŒºï¼ŒæŒ‘æˆ˜è‡ªå·±å¯èƒ½åšä¸åˆ°çš„äº‹æƒ…ï¼Œå¯¹èƒ½åŠ›çš„æå‡æ‰ä¼šæ›´å¤§å§ï¼å¹¶ä¸”å°±ç®—æœ€åå®ç°ä¸äº†ï¼Œæ¯•è®¾ä¹Ÿä¸ä¼šå¡çš„ï¼Œå½“æ—¶è‡ªå·±å¤ªæ±‚ç¨³äº†T_Tã€‚ä½†æ•´ä¸ªæ¯•è®¾è¿˜æ˜¯æœ‰æ”¶è·çš„ï¼Œä»æœ€å¼€å§‹çš„æ–‡çŒ®è°ƒç ”æ‰¾å¯æ”¹è¿›çš„ç‚¹ï¼Œåšå®éªŒï¼Œåˆ°æœ€ç»ˆå®Œæˆæ¯•ä¸šè®ºæ–‡ï¼Œå¯èƒ½è¿™ä¹Ÿç®—æ˜¯ä¸€ç§ç§‘ç ”è®­ç»ƒå§ï¼Ÿ åˆ°5æœˆä»½åˆç­”è¾©å®Œï¼Œæ¯•è®¾çš„äº‹æƒ…ä¾¿æš‚æ—¶å‘Šä¸€æ®µè½äº†ã€‚å½“æ—¶æ­£ç¢°ä¸Šå­¦é™¢çš„å…šæ”¯éƒ¨ç»„ç»‡å»å˜‰å…´è°ƒç ”ï¼Œäºæ˜¯æˆ‘ä¹ŸæŠ¥åå»äº†ã€‚å¤§å­¦å››å¹´åŸºæœ¬ä¸€ç›´å¾…åœ¨å­¦æ ¡ï¼Œå¦‚æœå†ä¸å‡ºå»çœ‹çœ‹æ„Ÿè§‰å¾ˆå¯æƒœå˜‰å…´ï¼Œç‰¹åˆ«æ˜¯æœˆæ²³å¤é•‡ï¼Œç»™æˆ‘ä¸€ç§æ±Ÿå—æ°´ä¹¡çš„æ€¡äººï¼Œå½“ä½ è¸å…¥è¿™é‡Œï¼Œå¥¹å°±åƒæ˜¯ä¸€ä½äº­äº­ç‰ç«‹çš„ä½³äººï¼Œåœ¨æŸ³çµ®æ˜¥é£çš„ä¼´éšä¸‹ï¼Œå‘ä½ å¾å¾èµ°æ¥ã€‚ æƒ³è±¡ä¸€ä¸‹ï¼Œåœ¨é™¢å­é‡Œæ³¡ä¸Šä¸€å£¶èŒ¶ï¼Œå…»å…»èŠ±ï¼Œå’Œè€å‹è°ˆå¤©è¯´åœ°ä¸€ä¸ªä¸‹åˆï¼Œæ˜¯å¤šä¹ˆæƒ¬æ„ã€‚ ä»ç­”è¾©å®Œåˆ°6æœˆä»½åˆè¿™æ®µæ—¶é—´ï¼Œæˆ‘æ¯å¤©ä¸»è¦æ˜¯åœ¨å¿™ç§‘ç ”ä»¥åŠæ”¹æ¯•è®¾æ–‡æ¡£ï¼Œå½“æ—¶å¯¼å¸ˆæƒ³è®©æˆ‘ç»§ç»­åšåšæ–‡å­¦é•¿å¼ºåŒ–å­¦ä¹ å‰ªæçš„å®éªŒï¼Œäºæ˜¯ä¾¿æ‰¾äº†å¾ˆå¤šèµ„æ–™å»äº†è§£è¿™æ–¹é¢çš„ä¸œè¥¿ã€‚å½“æ—¶è¿˜å…»æˆäº†ä¸€ä¸ªä¹ æƒ¯ï¼Œåˆä¼‘ç»“æŸï¼Œæˆ‘ä¼šå…ˆèŠ±åŠå°æ—¶å…ˆå­¦å­¦è‡ªå·±æ„Ÿå…´è¶£çš„ä¸œè¥¿ï¼Œç„¶åå¼€å§‹å·¥ä½œï¼Œè¿™ä¸ªä¹ æƒ¯ä¸€ç›´æŒç»­äº†æ•´ä¸ªæš‘å‡ã€‚ç”¨è¿™æ¯å¤©åŠå°æ—¶çš„æ—¶é—´ï¼Œæˆ‘çœ‹å®Œäº†Crash Course Computer Scienceï¼Œä¹Ÿç®—æ˜¯å¯¹æ•´ä¸ªcomputer scienceæœ‰äº†ä¸€ä¸ªæµ…å±‚çš„å…¨é¢çš„äº†è§£ã€‚ åœ¨6æœˆä»½çš„ç¬¬ä¸€ä¸ªå‘¨æœ«å’Œå¥½å‹å»çœ‹äº†æ•°å­—è‰ºæœ¯ä¸è«æ¢µå±•ã€‚ç¬¬äºŒå¤©ï¼Œæˆ‘åªèº«ä¸€äººååŠ¨è½¦å»ä½™å§šæ‹œè®¿ç‹é˜³æ˜æ•…å±…ï¼Œå› ä¸ºä¸­å›½ä¼ ç»Ÿæ–‡åŒ–å¯¹è‡ªå·±çš„å½±å“æŒºå¤§çš„ï¼Œè€Œç‹é˜³æ˜ä½œä¸ºå¿ƒå­¦çš„å¼€åˆ›è€…ï¼Œä¸‰ä¸æœ½çš„åœ£äººï¼Œæ‰€ä»¥æˆ‘è§‰å¾—å¾ˆæœ‰å¿…è¦å»æ‹œè®¿ä¸€ä¸‹ã€‚ å½“æ—¶æœ‰å¾ˆå¤šæ…•åè€Œæ¥çš„æ¸¸å®¢æ¥æ‹œè®¿ï¼Œè¿˜æœ‰ä¸€äº›é˜³æ˜å¿ƒå­¦çš„å­¦ä¹ ç­æ¥æ•…å±…å‚è§‚å­¦ä¹ ï¼Œæˆ‘æ„Ÿå—åˆ°äº†ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–çš„å¤å…´ï¼Œç»½æ”¾æ–°çš„ç”Ÿæœºï¼Œå‘æŒ¥ç€å¥¹çš„æ—¶ä»£ä»·å€¼ï¼Œäºå›½äºæ°‘è¿™æ˜¯å¾ˆå¥½çš„äº‹æƒ…ã€‚ åˆ°6æœˆ8å·ï¼Œå¯¼å¸ˆè·Ÿè¯´æˆ‘å…ˆä¸åšå¼ºåŒ–å­¦ä¹ äº†ï¼Œè®©æˆ‘åšæ¥ç€åšåšæ–‡å­¦é•¿iccvè¢«æ‹’çš„çŸ¥è¯†è’¸é¦è®ºæ–‡ï¼Œäºæ˜¯æˆ‘ä¾¿å¼€å§‹çœ‹çŸ¥è¯†è’¸é¦è¿™æ–¹é¢çš„ä¸œè¥¿ã€‚ä¸€ç›´åˆ°7æœˆä»½ï¼ŒæœŸé—´ç»å†äº†æ¯•ä¸šå…¸ç¤¼ï¼Œè¿˜å’Œå¤§å­¦çš„å‡ ä¸ªå¥½æœ‹å‹å»è¥¿æ¹–é™„è¿‘ç©äº†ä¸€å¤©ä¹Ÿç®—æ˜¯æ¯•ä¸šæ—…è¡Œï¼Ÿ åœ¨6æœˆåº•ï¼Œæˆ‘æŠ¥åå‚åŠ äº†ä¸Šæµ·çš„Amazonäº‘ç§‘æŠ€ä¸­å›½å³°ä¼šï¼Œä¸»è¦æ˜¯æƒ³å»çœ‹çœ‹ä¼ä¸šç©¶ç«Ÿæ˜¯åœ¨åšäº›ä»€ä¹ˆï¼Œå¬äº†å‡ åœºæŠ¥å‘Šä¸‹æ¥ã€‚æœ‰ä¸¤ä¸ªæ„Ÿå—ä¸€æ˜¯å¤§æ¨¡å‹AIGCçœŸæ˜¯éå¸¸ç«ï¼Œä¼šåœºæŒ¤æ»¡äº†äººï¼Œè€Œåƒé‡å­è®¡ç®—ä¸€äº›è¿˜æœªå¤§è§„æ¨¡å®é™…åº”ç”¨çš„åªæœ‰å¯¥å¯¥æ•°äººï¼ŒäºŒæ˜¯ç°åœ¨çš„ç¨‹åºå‘˜å­¦ä¹ å·¥ä½œæ–¹å¼éœ€è¦è½¬å˜ï¼Œä¼šæ›´åŠ æ³¨é‡æ€ç»´çš„ç‹¬åˆ›æ€§ã€‚ åœ¨7æœˆåˆï¼Œæˆ‘å»å‚åŠ äº†ç«‹å¿ƒè¥ã€‚ç«‹å¿ƒè¥ç»“æŸåï¼Œæˆ‘å¼€å§‹åš2030é¡¹ç›®ï¼Œ7æœˆä¸­æ—¬å›å®¶å¾…äº†åŠä¸ªæœˆï¼Œ8æœˆåˆä¾¿æ¥MACå®éªŒå®¤äº†ã€‚æ¥å¦å¤§ä»¥åï¼Œæˆ‘çš„ä¸»è¦ç²¾åŠ›ä»ç„¶æ˜¯æ”¾åœ¨2030ä¸Šï¼Œæˆ‘ä»¬å‡ ä¸ªç ”ä¸€çš„ï¼Œä¸»è¦æ˜¯åšä¸€äº›SFTæ•°æ®é›†å¤„ç†ï¼Œpeftå¾®è°ƒç­‰å·¥ä½œã€‚ åˆ°9æœˆä»½å¼€å­¦è¿™æ®µæ—¶é—´ï¼Œæˆ‘æ¯å¤©æ—©ä¸Š6ç‚¹åŠèµ·åºŠï¼Œè¯»1hè‹±è¯­ï¼Œä¸»è¦æ˜¯ç»ƒä¹ å£è¯­å’ŒèƒŒGREå•è¯ï¼Œè®°å¾—åˆšæ¥è¿™è¾¹å¯¹å¦å¤§çš„ç¯å¢ƒä¸å¤ªç†Ÿæ‚‰ï¼Œè‹¦äºæ‰¾ä¸åˆ°é€‚åˆæ—©è¯»çš„åœ°æ–¹ï¼Œä¼šå·å·æºœåˆ°ç”Ÿå‘½ç§‘å­¦å­¦é™¢é‡Œå»ğŸ˜‚ã€‚ä½†è¿˜å¥½ï¼Œåæ¥æˆ‘å‘ç°é£Ÿå ‚äºŒæ¥¼å¾ˆé€‚åˆæ—©è¯»ï¼Œè¯»å®Œä¹¦ä¹‹åä¾¿æ­å®éªŒå®¤ç­è½¦å»è½¯ä»¶å›­å¼€å§‹å·¥ä½œã€‚ é‚£æ®µæ—¶é—´çš„åˆè¯¾åŠå°æ—¶ï¼Œæˆ‘å¼€å§‹åœ¨Courseraä¸Šå­¦learning-how-to-learnï¼Œä¸»è¦æ˜¯æƒ³å¼„æ¸…æ¥šå¦‚ä½•ç§‘å­¦æœ‰æ•ˆåœ°å­¦ä¹ ï¼Œæ¯•ç«Ÿä»å°åˆ°å¤§å­¦äº†è¿™ä¹ˆä¹ ï¼Œå¥½åƒè¿˜æ²¡è®¤çœŸæ€è€ƒè¿‡ä»€ä¹ˆæ‰æ˜¯å­¦ä¹ ï¼Œå¦‚ä½•å­¦ä¹ ï¼Ÿåœ¨é›¶ç¢æ—¶é—´æˆ–è€…æ˜¯æ‘¸é±¼çš„æ—¶å€™ï¼Œæˆ‘ä¼šå»å­¦The Missing Semester of Your CS Educationä»¥åŠçœ‹çœ‹intermediate-pythonï¼Œå‰è€…å› ä¸ºæˆ‘å‘ç°è‡ªå·±è¿˜æ˜¯ç¼ºå°‘å¾ˆå¤šcsé€šç”¨çš„æŠ€èƒ½ï¼Œè€Œåè€…æˆ‘æƒ³å†™å‡ºä¼˜é›…çš„é«˜è´¨é‡çš„pythonä»£ç ï¼Œæ¯•ç«Ÿå¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨ä½¿ç”¨pythonã€‚åœ¨æ¯å‘¨å…­å‘¨å¤©ï¼Œæ²¡æœ‰2030çš„ä»»åŠ¡æ—¶ï¼Œæˆ‘åœ¨å­¦standford CS229ä»¥åŠmit18.100Aï¼Œä¸€æ–¹é¢æ˜¯æƒ³ç»™è‡ªå·±è¡¥è¡¥åŸºç¡€ï¼Œå¦ä¸€æ–¹é¢å¯¹è¿™äº›ä¹Ÿæœ‰å¾ˆå¤§çš„passionã€‚ 9æœˆä»½å¼€å­¦ï¼Œæˆ‘ç«é€‰äº†ç­çº§å­¦å§”ï¼Œä¸»è¦æ˜¯æƒ³ä¸¾åŠç±»ä¼¼è¯»ä¹¦ä¼šçš„æ´»åŠ¨ï¼Œä»¥è®¨è®ºç­çš„å½¢å¼å°†ä¸€ç¾¤çƒ­çˆ±æŠ€æœ¯ã€ç§‘ç ”çš„äººèšé›†åœ¨ä¸€èµ·ï¼Œå…±åŒè¯»ä¸€éƒ¨ä¹¦æˆ–è€…æ˜¯è®ºæ–‡æ¢è®¨ã€‚å› ä¸ºè§‰å¾—ä¸€ä¸ªäººå­¦ä¹ å¾ˆå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œè€Œä¸€ä¸ªå›¢ä½“èƒ½å¤Ÿæ‰©å¤§æœç´¢èŒƒå›´ï¼Œè·³å‡ºå±€éƒ¨æœ€ä¼˜ã€‚ è€Œ9æœˆä»½è¿™ä¸€ä¸ªæœˆçš„æ—¶é—´é‡Œï¼Œæˆ‘é™¤äº†ä¸Šè¯¾ï¼Œå‰©ä¸‹çš„å¤§éƒ¨åˆ†æ—¶é—´è¿˜æ˜¯åœ¨åš2030ï¼Œæ ¹æ®flagevalä¸Šçš„å„ç±»æŒ‡æ ‡ï¼Œæ”¶é›†æ•°æ®é›†ï¼Œåšpeftå¾®è°ƒï¼Œå°è¯•æå‡llamaæ¨¡å‹çš„æ€§èƒ½ã€‚å¯¹äºå¦å¤§çš„ç ”ç©¶ç”Ÿæ•™å­¦è´¨é‡ï¼ŒçœŸæ˜¯ä¸€è¨€éš¾å°½ï¼Œç»å¤§éƒ¨åˆ†è¯¾éƒ½åƒæ˜¯æ‘†è®¾ï¼Œè€å¸ˆè®²è€å¸ˆçš„ï¼Œå­¦ç”Ÿåšè‡ªå·±çš„ã€‚è€Œå¯¹äºæˆ‘æ¥è¯´ï¼Œå¦‚æœè€å¸ˆè®²å¾—å¥½ï¼Œè¯¾å¬çš„æœ‰æ”¶è·æˆ‘ä¾¿ä¼šå¬ï¼Œä½†å¤§éƒ¨åˆ†æ—¶é—´æˆ‘ä¹Ÿæ˜¯åœ¨åšè‡ªå·±çš„äº‹æƒ…ï¼Œä¸çŸ¥é“å…¶ä»–topé«˜æ ¡çš„ç ”ç©¶ç”Ÿæ•™å­¦æ˜¯æ€æ ·çš„ï¼ŒçœŸæ˜¯å¾ˆå‘å¾€æœ‰å¤§å¸ˆçš„å­¦æ ¡ï¼ åˆ°äº†10æœˆä»½ï¼Œåšæ–‡å¸ˆå…„å®ä¹ å›æ¥ï¼Œæˆ‘å¼€å§‹ç»§ç»­åšä¸¢äº†2ä¸ªå¤šæœˆçš„çŸ¥è¯†è’¸é¦ã€‚ä¸»è¦æ˜¯éœ€è¦é‡æ–°è®¾è®¡è’¸é¦ç®—æ³•ï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œå¸ˆå…„è¿™ç¯‡iccvä¹‹æ‰€ä»¥è¢«æ‹’ï¼Œæ˜¯å› ä¸ºå®¡ç¨¿äººdisså®éªŒæ•ˆæœè¿˜å·®ç‚¹ï¼Œè™½ç„¶å…·æœ‰åˆ›æ–°æ€§å’Œå¯è§£é‡Šæ€§å¾ˆå¼ºã€‚ åˆ°10æœˆä¸­æ—¬çš„æ—¶å€™ï¼Œæˆ‘å»å‚åŠ äº†PRCV2023ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ç¬¬ä¸€æ¬¡å‚åŠ å­¦æœ¯ä¼šè®®ï¼Œæˆ‘æœ€å—ç›Šçš„æ˜¯ã€Šé«˜è´¨é‡è®ºæ–‡å†™ä½œä¸å‘è¡¨è®ºå›ã€‹ï¼Œè¯·äº†å¾ˆå¤šæœ‰åçš„æ•™æˆè°ˆç§‘ç ”ä¸è®ºæ–‡å†™ä½œå¿ƒå¾—ã€‚å…¶ä¸­å°è±¡æœ€æ·±çš„æ˜¯æµ™æ±Ÿå¤§å­¦æçºæ•™æˆè¯´â€œç§‘ç ”æ˜¯ä¸€ä¸ªå…¨é“¾æ¡ä¼˜åŒ–çš„è¿‡ç¨‹â€ï¼Œè¿˜æœ‰å¤æ—¦å¤§å­¦å¼ å†›å¹³æ•™æˆã€Šé«˜è´¨é‡è¯»ç ”ã€‹ï¼Œæˆ‘åˆ©ç”¨é›¶ç¢æ—¶é—´å°†è¿™æœ¬ä¹¦è¯»å®Œäº†ï¼Œå…¶ä¸­å¯¹æˆ‘å¸®åŠ©æœ€å¤§æ˜¯ä¹¦ä¸­è¯´â€åŸºç¡€åº”è¯¥ä¼˜å…ˆå®šä¹‰åœ¨å¯¹å…·ä½“ç ”ç©¶é—®é¢˜çš„å‰æ²¿æŒæ¡ä¸Šï¼Œä»¥ç‚¹å¸¦é¢åœ°å­¦ä¹ ã€‚â€œ æ­¤å¤–ï¼Œå¾å®—æœ¬é™¢å£«é¢˜ä¸ºã€Šå˜ä¸ä¸å˜ï¼šæœ‰å…³å¤§æ¨¡å‹çš„ä¸€äº›æ•°ç†åŸºç¡€é—®é¢˜ã€‹è®©æˆ‘æ„è¯†åˆ°æˆ‘ä»¬æ­£å¤„äºå¤§æ¨¡å‹æ—¶ä»£ï¼Œè€Œä»¥å‰çš„æ•°å­¦ç†è®ºåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šå¹¶ä¸å®Œå…¨é€‚ç”¨ï¼Œéœ€è¦å»ºç«‹ä¸€å¥—å…¨æ–°çš„æ•°å­¦ç†è®ºæ¥åšå¤§æ¨¡å‹çš„åŸºç¡€ç ”ç©¶ã€‚ ä»10æœˆä»½åˆ°11æœˆ19æ—¥CVPRæˆªæ­¢è¿™æ®µæ—¶é—´ï¼Œæˆ‘ç»å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨åšè’¸é¦å®éªŒï¼Œå°è¯•äº†å¾ˆå¤šæƒ³æ³•ï¼Œä½†æœ€åå¹¶æ²¡æœ‰è¾¾åˆ°ç†æƒ³çš„é¢„æœŸğŸ˜‚ï¼Œå¸ˆå…„è¯´è®¾è®¡æ–°çš„è’¸é¦ç®—æ³•å’ŒåŸè®ºæ–‡å…¶å®æ˜¯ç‹¬ç«‹çš„ç ”ç©¶è¯¾é¢˜äº†ï¼Œå› ä¸ºä½ çŸ¥é“ä¸€ä¸ªä¸œè¥¿æ˜¯ä»€ä¹ˆå’ŒçŸ¥é“å¦‚ä½•è®©å®ƒå˜å¾—æ›´å¥½æ˜¯ä¸¤ç äº‹ã€‚æˆ‘æ„Ÿè§‰æ•´ä¸ªå®éªŒçš„è¿‡ç¨‹ï¼Œæœ‰ç‚¹åƒæŠ½å¥–ç¢°è¿æ°”ï¼Œå°è¯•çš„å¾ˆå¤šæƒ³æ³•éƒ½æ²¡æœ‰æ ¹æ®ï¼Œæˆ‘è®¤ä¸ºæœ‰å¾ˆå¤§éƒ¨åˆ†åŸå› åœ¨äºè‡ªå·±è¯»è®ºæ–‡å¤ªå°‘äº†ï¼Œå¯¹è’¸é¦çš„ç†è§£å¾—è¿˜ä¸å¤Ÿæ·±å…¥ï¼Œåœ¨è®¾è®¡æ—¶å¯ç”¨çš„æ­¦å™¨å¹¶ä¸å¤šã€‚ æŠ•å®Œcvpråˆ°12æœˆä¸­æ—¬è¿™ä¸€ä¸ªå¤šæœˆï¼Œæˆ‘ä¸»è¦æ˜¯åœ¨ç»§ç»­åšå¯¼å¸ˆä¹‹å‰ä¸€ç¯‡æ··åˆå‹ç¼©çš„è®ºæ–‡ï¼Œåœ¨ä¸Šé¢åŠ å„ç§CNNçš„KDç®—æ³•ï¼ŒéªŒè¯å®éªŒæ•ˆæœã€‚æœ€å¼€å§‹åšçš„æ—¶å€™ï¼Œè·‘1ä¸ªepochéœ€è¦èŠ±2ä¸ªå¤šå°æ—¶ğŸ˜“ã€‚å°è¯•äº†å„ç§åŠ é€Ÿçš„tricksï¼Œä»æ•°æ®åŠ è½½åˆ°æ•°æ®å¢å¼ºï¼Œç»“æœå‘ç°æå‡å¹¶ä¸æ˜æ˜¾ï¼Œåªå¿«äº†0.5hï¼Œç»“æœåæ¥æ‰æ–­å®šæ˜¯æœºå™¨çš„é—®é¢˜ï¼ŒåŒä¸€ä»½ä»£ç ï¼Œç›¸åŒçš„é…ç½®ï¼Œä¼Ÿä¸­åœ¨å¦å¤–çš„æœºå™¨ä¸Šè·‘åªéœ€è¦å‡ åˆ†é’Ÿ/eopchã€‚ æ­¤å¤–ï¼Œæˆ‘å’Œå’ä¸œç»„é˜Ÿåšè®¡ç®—æœºè¯­è¨€å­¦çš„è¯¾è®¾ï¼Œè€Œå’ä¸œæ‰“ç®—ç”¨ä»–æŠ•IJCAIçš„è®ºæ–‡æ‹¿å»å½“è¯¾è®¾ï¼Œäºæ˜¯æˆ‘å¸®ç€ç”¨open3då®ç°äº†è®ºæ–‡ä¸­3D bounding boxçš„å¯è§†åŒ–ï¼Œæœ¬æƒ³æ‰¾ä¸ªç°æˆçš„ç›´æ¥ç”¨å› ä¸ºæ„Ÿè§‰è¿™ä¸ªå¯è§†åŒ–æŒºæ™®éçš„ï¼Œç»“æœæ‰¾éå…¨ç½‘éƒ½æ²¡æœ‰ï¼Œæ‰€ä»¥åªå¥½è‡ªå·±å†™ï¼Œåšäº†å¾ˆä¹…æœ€åéƒ½æ‰“ç®—ç”¨PPTç”»äº†ğŸ˜‚ï¼Œä½†ç»ˆäºè¿˜æ˜¯ç”¨ä»£ç å®ç°äº†ï¼Œæ‰“ç®—åé¢æ•´ç†ä¸‹å¼€æºåˆ°githubä¸Šã€‚ 23å¹´æœˆåº•æœ€åä¸€å‘¨æ—¶é—´åˆ™ä¸»è¦æ˜¯åœ¨è¡¥ä¹‹å‰æ¬ ä¸‹çš„è¯¾å ‚ä½œä¸šå’Œå‡†å¤‡æœŸæœ«å¤ä¹ äº†ã€‚æœ‰ä¸€é—¨çŸ©é˜µè®ºçš„è€ƒè¯•ï¼Œæˆ‘æ²¡æƒ³åˆ°è€å¸ˆä¼šè€ƒä½œä¸šä¸­æ²¡æœ‰æ¶‰åŠåˆ°çš„çŸ¥è¯†ç‚¹ï¼Œäºæ˜¯100åˆ†çš„é¢˜ç›®æˆ‘åªåšäº†60å¤šåˆ†ï¼Œæ²¡åšå‡ºæ¥çš„éƒ½æ˜¯æˆ‘å¤ä¹ æ²¡çœ‹çš„ï¼Œè™½ç„¶å¹³æ—¶ä¹Ÿå­¦äº†ï¼Œä½†æ—¶é—´ä¸€ä¹…å°±å¿˜äº†ã€‚å½“æ—¶è€ƒå®Œåï¼Œçªç„¶å¯¹è¿™ç§è€ƒè¯•æœ‰äº›åæ„Ÿäº†ï¼Œæ¯•ç«Ÿå‡­ç€å¯¹æ•°å­¦å…´è¶£ï¼Œè‡ªå·±å¹³å¸¸åœ¨çŸ©é˜µè®ºä¸Šä¹ŸèŠ±äº†ä¸å°‘æ—¶é—´ã€‚è€Œä¸”ç»å†äº†ä»å¤§å­¦è¿½æ±‚é«˜ç»©ç‚¹ï¼Œåˆ°ç ”ç©¶ç”Ÿä»¥è¿½æ±‚ç†è§£çŸ¥è¯†æœ¬è´¨ä¸ºä¸»çš„è½¬å˜ã€‚æˆ‘è®¤ä¸ºå¦‚æœä½ æœ‰æ¯”è¾ƒå¼ºçš„è€ƒè¯•çªå‡»èƒ½åŠ›ï¼Œåœ¨çŸ­æ—¶é—´å†…æŠŠå†…å®¹è®°ä½ç„¶ååº”ç”¨ï¼Œä¹Ÿèƒ½å¤Ÿè€ƒå¾ˆå¥½çš„åˆ†æ•°ï¼Œè€Œä¸”å®ƒæ— æ³•è¯„ä¼°ä½ æ˜¯æ ¹æ®ç†è§£å†™å‡ºæ¥çš„è¿˜æ˜¯èƒŒå‡ºæ¥çš„ã€‚æˆ‘æ›´æƒ³ä»æ•°å­¦ä¸­è·å–æ€æƒ³ï¼Œå¦‚ä½•è§£å†³é—®é¢˜çš„æ€ç»´ï¼Œè€Œä¸æ˜¯ä»…ä»…æŠŠæ•°å­¦å½“ä½œä¸€ç§å·¥å…·å§ã€‚ ä»¥ä¸Šæ¢³ç†äº†23å¹´ä»¥æ¥çš„ä¸»è¦äº‹ä»¶ï¼Œè‡ªå·±åœ¨ç§‘ç ”çš„é“è·¯ä¸Šæ‘¸çˆ¬æ»šæ‰“ï¼Œèµ°çš„æ¯”è¾ƒæ…¢ï¼Œä½†ä¹Ÿæ¯”è¾ƒæ²‰ç¨³ï¼Œæ€»ä¹‹å¯¹æˆ‘æ¥è¯´ï¼Œåšä»€ä¹ˆäº‹æƒ…æ— è®ºç»“æœå°½åŠ›è€Œä¸ºå³å¯ã€‚æœ€åï¼Œå†ç”¨æ•°æ®æ€»ç»“ä¸‹23å¹´ã€‚ 23å¹´ä½œæ¯å¤§æ¦‚ä¸ºï¼Œæ—©è¯»1hï¼Œ9ç‚¹åˆ°å®éªŒå®¤å·¥ä½œåˆ°12ç‚¹ï¼Œå»å›¾ä¹¦é¦†åˆä¼‘åŠå°æ—¶å14ç‚¹åˆ°å®éªŒå®¤å·¥ä½œåˆ°17:30ï¼Œæ™šä¸Š19:00å·¥ä½œåˆ°22ç‚¹ã€‚æ—¥å¤ä¸€æ—¥ï¼Œå¦‚æœå½“å¤©ä¼šå»è¿åŠ¨ï¼Œ17:00ä¾¿ä¼šä¸‹ç­ã€‚é™¤äº†1hæ—©è¯»å¤–ï¼Œæˆ‘æ™šä¸Šå–œæ¬¢å»æ€æºé¤å…åƒé¥­ï¼Œåœ¨å›æ¥å®éªŒå®¤çš„è·¯ä¸Šï¼Œå¬ç€ã€Šèµ°éç¾å›½ã€‹çš„å½•éŸ³ï¼Œç»ƒä¹ å£è¯­ï¼Œæˆ‘å‘ç°è¿™æ˜¯ä¸ªå¾ˆå¥½çš„æ–¹æ³•ï¼Œå› ä¸ºå›æ¥æœ‰æ®µè·¯ä¸ŠåŸºæœ¬æ²¡æœ‰äººğŸ˜‚ã€‚ åœ¨ç”Ÿæ´»æ–¹é¢ï¼Œæ‰‹æœºæ—¶é—´ä½¿ç”¨æ—¶é—´æ—¥å‡1h31minï¼Œ23å¹´æ€»è®¡502h20minã€‚ç¡çœ æ—¥å‡æ—¶é—´ä¸º7å°æ—¶44minï¼Œä¸€èˆ¬æ˜¯23ç‚¹-23ç‚¹åŠå…¥ç¡ï¼Œæ—©ä¸Š6ç‚¹åŠ-7ç‚¹èµ·ã€‚å¥åº·æ–¹é¢ï¼Œå¹²çœ¼ç—‡è¿˜æ²¡æœ‰å®Œå…¨å¥½ï¼Œä½†æŒ‰ç…§ç•ªèŒ„é’Ÿçš„é—´éš”å­¦ä¹ é—®é¢˜ä¸å¤§ã€‚è¿åŠ¨ä¸»è¦æ˜¯æ¸¸æ³³å’Œè·‘æ­¥å¥èº«ï¼Œä¸€èˆ¬æ˜¯éš”å¤©è¿›è¡Œä¸€æ¬¡1hè¿åŠ¨ï¼Œæ¯•ä¸šåæ‰“ç¯®çƒå¾ˆå°‘äº†ï¼Œä¸»è¦æ˜¯æ‰¾ä¸åˆ°çƒå‹å‘€~ 23å¹´å…±å®Œæ•´è¯»å®Œ/å¬å®Œäº†8æœ¬ä¹¦ï¼Œåˆ†åˆ«æ˜¯ã€Šé«˜è´¨é‡è¯»ç ”ã€‹ã€ã€Šåˆ«é—¹äº†ï¼Œè´¹æ›¼å…ˆç”Ÿã€‹ã€ã€Šæ›¾å›½è—©å®¶ä¹¦ã€‹ã€ã€Šå¤§å­¦ä¸­åº¸ã€‹ã€ã€Šå›¾è§£å¿ƒç»ã€‹ã€ã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ã€‹ã€ã€Šæˆ¿æ€çªçš„åˆæ‹ä¹å›­ã€‹ã€ã€Šæ‰¾å‡ºæœ€åˆçš„ä½ ã€‹ï¼Œç„¶åè¿˜æœ‰ä¸€äº›åŸºæœ¬è¯»å®Œä»¥åŠä¸“ä¸šè¯¾ç”¨åˆ°è¯»äº†å¤§éƒ¨åˆ†çš„ä¹¦å°±ä¸åœ¨æ­¤ä¸€ä¸€èµ˜è¿°å•¦ï¼Œè¯¦è§è±†ç“£ã€‚ åœ¨è§‚å½±æ–¹é¢ï¼Œ23å¹´çœ‹äº†4éƒ¨ç”µå½±ï¼Œåœ¨å¯’å‡çœ‹äº†ã€Šé¥®é£Ÿç”·å¥³ã€‹ã€ã€ŠèŠ±æ ·å¹´åã€‹ã€ã€Šè½æ°´ç‹—ã€‹ï¼Œåœ¨æ¥å¦å¤§çš„é£æœºä¸Šçœ‹å®Œäº†ã€Šè€äººä¸æªã€‹ã€‚æˆ‘è¿˜æ˜¯å–œæ¬¢çœ‹ä»¥å‰ç»å…¸çš„ç”µå½±ï¼Œå‡ ä¹ä¸å»ç”µå½±é™¢ã€‚ åœ¨äººæ–‡è‰ºæœ¯æ–¹é¢ï¼Œæˆ‘å–œæ¬¢åˆ©ç”¨é›¶ç¢æ—¶é—´ï¼Œä¾‹å¦‚åç­è½¦ã€èµ°è·¯çš„æ—¶é—´å¬ä¸€äº›è®²åº§ï¼Œæ–‡å²å“²è¿™äº›ä¸œè¥¿å äº†æˆ‘ç²¾ç¥ä¸–ç•Œä¸­çš„å¾ˆå¤§éƒ¨åˆ†ï¼Œå¦‚æœæ²¡æœ‰è¿™äº›æ„Ÿè§‰è‡ªå·±å°±åƒä¸ªè¡Œå°¸æ ·çš„å·¥å…·äººã€‚åŸºæœ¬å¬å®Œäº†ç‹å¾·å³°æ•™æˆçš„ã€Šå¤§å­¦ã€‹ã€ã€Šé“å¾·ç»ã€‹ã€ã€Šä¸­è¥¿æ€æƒ³å¿…ä¿®è¯¾ã€‹ã€é«˜åæ•™æˆçš„ã€Šä¸­åäººæ°‘å…±å’Œå›½å²ã€‹ã€é¦™æ¸¯ç§‘æŠ€å¤§å­¦æ–‡åŒ–ç ”ç©¶ä¸­å¿ƒç³»åˆ—è®²åº§ã€Šé‡è¯»ä¸­åäººæ°‘å…±å’Œå›½å²ã€‹ï¼Œä¸€æ–¹é¢æ˜¯å‡ºäºå¯¹ä¸­è¥¿æ–¹å“²å­¦çš„å…´è¶£ï¼Œå¦ä¸€æ–¹é¢æƒ³å…¨é¢å®¢è§‚åœ°äº†è§£è‡ªå·±æ‰€ç”Ÿæ´»å›½å®¶çš„å†å²ã€‚å±•è§ˆé™¤äº†ä¸Šé¢æåˆ°çš„æ•°å­—è‰ºæœ¯å’Œè«å¥ˆï¼Œä»Šå¹´åªçœ‹äº†æ ¡å†…çš„ä¸€ä¸ªæ‘„å½±å±•ã€‚ åœ¨éŸ³ä¹æ–¹é¢ï¼Œå¬å¾—æœ€å¤šçš„è¿˜æ˜¯å¤å…¸ï¼Œæœ€å–œæ¬¢å¬è‚–é‚¦ä»¥åŠå·´èµ«ï¼Œä¸‹é¢æ­æ™“å¹´åº¦æ­Œæ‰‹å’Œæ­Œæ›²ï¼ æ€»çš„æ¥è¯´ï¼Œä»Šå¹´æœ€å¤§çš„äº‹æƒ…è¿˜æ˜¯è¯»ç ”å§ï¼Œäº¤åˆ°äº†å¾ˆå¤šå‰å®³çš„æœ‹å‹ï¼Œæˆ‘ä¹Ÿé€æ¸é€‚åº”è¯»ç ”çš„ç”Ÿæ´»ã€‚è‡ªå·±è¿˜æ˜¯æ¯”è¾ƒå–œæ¬¢ç›®å‰çš„çŠ¶æ€ï¼Œåšæœ‰æ„ä¹‰ã€æœ‰ä»·å€¼çš„äº‹æƒ…ã€‚ 24å¹´å¸Œæœ›è‡ªå·±èƒ½åšåˆ°ä»¥ä¸‹ï¼š ç”Ÿæ´» ä¿æŒæ—©ç¡æ—©èµ·çš„ä¹ æƒ¯ï¼ŒåšæŒå¥åº·ç¬¬ä¸€ä½ã€‚ æ‰‹æœºä½¿ç”¨æ—¶é—´é™ä½ï¼Œæ§åˆ¶åœ¨1hå†… å……åˆ†åˆ©ç”¨å¥½é›¶ç¢æ—¶é—´è¯»ä¹¦ï¼Œå¹¶åœ¨æ™šä¸Šç¡å‰èƒ½å¤Ÿäº‰å–çœ‹ä¸€ä¼šå„¿ä¹¦ ç§‘ç ” è½¬å˜ç§‘ç ”å­¦ä¹ çš„æ–¹å¼ï¼Œé™ä½çœ‹ä¹¦å’Œçœ‹è¯¾çš„æ¯”ä¾‹ï¼Œå°†ä¸»è¦çš„æ—¶é—´ç”¨åœ¨è¯»è®ºæ–‡åšå®éªŒä¸Šï¼Œå¸Œæœ›èƒ½åšå‡ºè‡ªå·±çš„ä¸œè¥¿ã€‚ ","title":"2023 å®‰æ²³æ¡¥","uri":"/posts/2023_summary/"},{"content":"è¿™å­¦æœŸé€‰äº†ä¸€é—¨çŸ©é˜µè®ºçš„è¯¾ï¼Œå…¶ä¸­æœ‰ä¸ªä½œä¸šæ˜¯å°ç»„ç»„é˜Ÿç§‘æ™®ä¸€äº›çŸ©é˜µè®ºçš„ç›¸å…³åº”ç”¨ã€‚æˆ‘ä»¬ç»„é€‰äº†Harris Corner detectionä½œä¸ºæŠ¥å‘Šé¢˜ç›®ï¼Œæˆ‘è´Ÿè´£ä»£ç å®ç°éƒ¨åˆ†ï¼ŒèŠ±æ—¶é—´æ•´ç†äº†ä¸‹è¿™æ–¹é¢çš„ä¸œè¥¿ï¼Œæ„Ÿè§‰è§’ç‚¹æ£€æµ‹è¿˜æ˜¯è›®æœ‰æ„æ€çš„ï¼Œä¸»è¦æ˜¯æ²¡æƒ³åˆ°çŸ©é˜µè®ºåœ¨cvå¤„ç†ä¸­è¿˜å¯ä»¥è¿™ä¹ˆç”¨ã€‚T_T å¯¹äºç°åº¦å›¾ä¸ŠæŸç‚¹ï¼Œå¦‚æœè¯¥ç‚¹åœ¨è¿›è¡Œå¾®å°ç§»åŠ¨åç°åº¦å˜åŒ–å¾ˆå¤§ï¼Œè¿™æ„å‘³ç€è¯¥ç‚¹çš„äº®åº¦æˆ–é¢œè‰²æ·±æµ…å˜åŒ–æ˜¾è‘—ã€‚è¿™ç§æ˜¾è‘—çš„ç°åº¦å˜åŒ–é€šå¸¸å‘ç”Ÿåœ¨å›¾åƒä¸­çš„è§’ç‚¹cornerã€‚ â€œç°åº¦â€æ˜¯æŒ‡å›¾åƒä¸­æ¯ä¸ªåƒç´ ç‚¹çš„äº®åº¦æˆ–é¢œè‰²æ·±æµ…ã€‚åœ¨æ•°å­—å›¾åƒå¤„ç†ä¸­ï¼Œç°åº¦å›¾æ˜¯ä¸€ç§ç‰¹æ®Šçš„å›¾åƒï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ ä»…åŒ…å«ç°åº¦ä¿¡æ¯ï¼Œè€Œä¸åŒ…å«é¢œè‰²ä¿¡æ¯ã€‚ç°åº¦å€¼é€šå¸¸æ˜¯ä»0ï¼ˆçº¯é»‘ï¼‰åˆ°255ï¼ˆçº¯ç™½ï¼‰çš„æ•´æ•°ï¼Œè¡¨ç¤ºä¸åŒçš„äº®åº¦çº§åˆ«ã€‚åœ¨ä»£ç ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å°†RGBä¸‰é€šé“çš„åƒç´ å€¼å–å¹³å‡ï¼Œæœ€åå¾—åˆ°çš„å•é€šé“å›¾åƒä¾¿ä¸ºç°åº¦å›¾ã€‚ æ³¨æ„ï¼Œä¸Šé¢æ‰€è¯´çš„â€œå¾®å°çš„ç§»åŠ¨â€æ˜¯æŒ‡åœ¨æŸä¸ªåŒºåŸŸå†…æ²¿ä»»æ„æ–¹å‘ç§»åŠ¨å‡ä¼šå¼•èµ·ç°åº¦å˜åŒ–ã€‚ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼Œåœ¨1åŒºåŸŸæƒ³è±¡æœ‰ä¸ªæ»‘åŠ¨çª—å£ä»ä¸‹å¾€ä¸Šï¼Œç§»åŠ¨è¶Šè¿‡çº¢çº¿ï¼Œè¿™æ—¶ä¹Ÿä¼šå¼•èµ·ç°åº¦å˜åŒ–ï¼Œé‚£ä¹ˆæ˜¯å¦èƒ½åˆ¤æ–­å®ƒå°±æ˜¯è§’ç‚¹å‘¢ï¼Ÿç­”æ¡ˆæ˜¯å¦å®šçš„ã€‚ å› ä¸ºï¼Œæ»‘åŠ¨çª—å£åœ¨çº¢æ¡†1çš„ä½ç½®å·¦å³ç§»åŠ¨ï¼Œå¹¶ä¸ä¼šå¼•èµ·ç°åº¦å˜åŒ–ã€‚ä½†è¿™æ—¶å¦‚æœæˆ‘ä»¬è€ƒè™‘2åŒºåŸŸè¿™ä¸ªäº¤ç‚¹ï¼Œå¯ä»¥å‘ç°æ— è®ºæ˜¯ä¸Šä¸‹æˆ–è€…å·¦å³ç§»åŠ¨å‡ä¼šå¼•èµ·ç°åº¦çš„å˜åŒ–ï¼Œæˆ–è€…æ˜¯æ²¿2çº¢æ¡†çš„å¯¹è§’çº¿ç­‰å„ä¸ªæ–¹å‘å‡ä¼šå¼•èµ·è¾ƒå¤§çš„ç°åº¦å˜åŒ–ï¼Œå› æ­¤æˆ‘ä»¬èƒ½å¤Ÿåˆ¤æ–­äº¤ç‚¹å¤„ä¸ºè§’ç‚¹ã€‚ æ€»çš„æ¥è¯´ï¼Œè§’ç‚¹æ£€æµ‹ä»è§’ç‚¹çš„å®šä¹‰å…¥æ‰‹ï¼Œcornerçš„å®šä¹‰ä¸ºï¼šåœ¨è¯¥ç‚¹é‚»åŸŸçš„å„ä¸ªæ–¹å‘ä¸Šç§»åŠ¨å‡ä¼šå¼•èµ·è¾ƒå¤§çš„ç°åº¦å€¼å˜åŒ–çš„ç‚¹ã€‚ ç²—ç³™åœ°ä»‹ç»å®Œäº†è§’ç‚¹æ£€æµ‹çš„åŸå§‹æ€æƒ³ï¼Œé‚£å¦‚ä½•å¯¹å…¶è¿›è¡Œæ•°å­¦ä¸Šçš„å½¢å¼åŒ–å‘¢ï¼Ÿä»åˆ¤æ–­çš„æ–¹æ³•æè¿°ä¸­ï¼Œæˆ‘æåˆ°äº†å¯ä»¥ä½¿ç”¨çª—å£æ»‘åŠ¨å‰åç°åº¦å€¼çš„å˜åŒ–ä½œä¸ºåˆ¤æ–­è§’ç‚¹çš„å‡†åˆ™ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªè¡¨ç¤ºçª—å£å†…ç°åº¦å€¼å˜åŒ–çš„å·®å€¼å‡½æ•°Error function$E(u,v)$å¦‚ä¸‹ $$ E(u,v)=\\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2 \\tag{1} $$ å…¶ä¸­$w(x,y)$è¡¨ç¤ºçª—å£å‡½æ•°ï¼Œå¯¹è¯¥ç‚¹çš„æ¯ä¸ªåƒç´ ç‚¹å‡èµ‹äºˆæƒå€¼ï¼Œä¸€èˆ¬å–çŸ©å½¢çª—å£æˆ–è€…é«˜æ–¯çª—å£ï¼Œå‰è€…å¯¹çª—å£å†…çš„å€¼å–1ï¼Œåè€…æŒ‰ç…§é«˜æ–¯åˆ†å¸ƒå–å€¼ã€‚$I(x+u,y+v)$è¡¨ç¤ºçª—å£æ²¿uå’Œvå¹³ç§»åçš„è¯¥ç‚¹çš„ç°åº¦å€¼ï¼Œ$I(x,y)$è¡¨ç¤ºå¹³ç§»å‰è¯¥ç‚¹çš„ç°åº¦å€¼ã€‚æ±‚å’Œç¬¦å·è¡¨ç¤ºå¯¹çª—å£å†…çš„æ‰€æœ‰åƒç´ ç‚¹è®¡ç®—ç°åº¦å€¼çš„å˜åŒ–ã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å‡½æ•°$E(u,v)$è¿›è¡Œä¸€äº›åŒ–ç®€ï¼Œé¦–å…ˆå°†$I(x+u,y+v)$åœ¨ç‚¹$(x,y)$å¤„è¿›è¡Œä¸€é˜¶Taylorå±•å¼€ï¼Œå¾—åˆ°ä¸‹å¼ï¼š $$ E(u,v) \\approx \\sum_{x,y}w(x,y)[I(x,y)+I_xu+I_yv-I(x,y)]^2 \\tag{2} $$ å…¶ä¸­$I_x,I_y$åˆ†åˆ«è¡¨ç¤ºåœ¨ç‚¹$(x,y)$å¤„çš„æ²¿$x$å’Œ$y$æ–¹å‘çš„ä¸€é˜¶åå¯¼ã€‚äºæ˜¯ï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥æ¶ˆæ‰$I(x,y)$ï¼Œå°†å¹³æ–¹æ‹¿è¿›å»åå¾—åˆ°$I(x,y)$çš„äºŒæ¬¡å‹ï¼Œé‚£ä¹ˆï¼Œå¾ˆè‡ªç„¶åœ°æˆ‘ä»¬ä¼šæƒ³åˆ°æŠŠè¿™ä¸ªäºŒæ¬¡å‹å†™æˆçŸ©é˜µçš„å½¢å¼ï¼Œæœ€ç»ˆçš„åŒ–ç®€ç»“æœå¦‚ä¸‹ï¼š $$ E(u,v) \\approx [u\\quad v]M\\begin{bmatrix}u\\\\v\\end{bmatrix} \\tag{3} $$ å…¶ä¸­çŸ©é˜µ$M$ä¹Ÿè¢«ç§°ä¸ºç»“æ„å¼ é‡structure tensor $$ M=\\sum_{x,y}w(x,y)\\begin{bmatrix}I_xI_x\u0026I_xI_y \\\\ I_xI_y\u0026I_yI_y\\end{bmatrix} \\tag{4} $$ å¯ä»¥å‘ç°å·®å€¼å‡½æ•°çš„å¤§å°ä¸»è¦å–å†³äº$M$çš„å¤§å°ï¼Œä¾‹å¦‚ï¼Œå¯¹äºå¼€å¤´ä¾‹å­ä¸­çš„1,2åŒºåŸŸæ¥è¯´ï¼Œåœ¨æ»‘åŠ¨çª—å£ç§»åŠ¨ç›¸åŒçš„è·ç¦»å³$u,v$ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œèƒ½æ£€æµ‹åˆ°åŒºåŸŸ2ä¸­åŒ…å«è§’ç‚¹çš„åŸå› ä¸ºæ˜¯$M$è¾ƒå¤§ã€‚ é‚£ä¹ˆå¦‚ä½•æ¥åº¦é‡$M$å¯¹$E$çš„è´¡çŒ®ï¼Œä»è€Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨è§’ç‚¹å‘¢ï¼ŸHarris å‘Šè¯‰æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å¼å­æ¥åˆ¤æ–­æŸä¸ªåŒºåŸŸå†…æ˜¯å¦å­˜åœ¨corner $$ \\begin{aligned}R=\\det(M)-k\\operatorname{tr}(M)^2.\\end{aligned} \\tag{5} $$ ç”±äº$\\det(M)=\\lambda_{1}\\lambda_{2}$å¹¶ä¸”$\\operatorname{tr}(M) = \\lambda_{1} + \\lambda_{2}$ï¼Œå…¶ä¸­$\\lambda_{1}\\lambda_{2}$åˆ†åˆ«æ˜¯çŸ©é˜µ$M$çš„ç‰¹å¾å€¼ï¼Œäºæ˜¯ä¸Šå¼å¯ä»¥è¿›ä¸€æ­¥å±•å¼€ä¸ºï¼š $$ R=\\lambda_1\\lambda_2-k\\left(\\lambda_1+\\lambda_2\\right)^2. \\tag{6} $$ å…¶ä¸­$k$æ˜¯å¸¸æ•°ï¼Œä¸€èˆ¬å–åˆ°$[0.04,0.06]$ä¹‹é—´ The so-called Harris Corner Detector was introduced by Chris Harris and Mike Stephens in 1988 in the paper â€œA Combined Corner and Edge Detectorâ€. å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ç»“æ„å¼ é‡çš„ç‰¹å¾å€¼å¤§å°æ¥åˆ¤æ–­æ˜¯å¦åŒ…å«cornerï¼Œä¸‹å›¾éå¸¸å½¢è±¡åœ°è¯´æ˜äº†è¿™ä¸€ç‚¹ï¼š å½“$\\lambda_1\\approx\\lambda_2$ï¼Œä¸”éƒ½æ¯”è¾ƒå¤§æ—¶$R$ä¼šæ¯”è¾ƒå¤§ï¼Œè¿™æ—¶å¯åˆ¤æ–­å­˜åœ¨cornerï¼›å½“$\\lambda_1 \\gg \\lambda_2$ï¼Œ$R \u003c 0$ï¼Œå­˜åœ¨edgeï¼›å½“äºŒè€…éƒ½æ¯”è¾ƒå°æ—¶ï¼Œ$|R|$è¾ƒå¾ˆå°ï¼Œä¸å­˜åœ¨edgeæˆ–è€…cornerã€‚ å…¶å®ï¼Œæ ¹æ®$\\lambda_1\\lambda_2$çš„å¤§å°æ¥åˆ¤æ–­å·®å€¼å‡½æ•° $E$ çš„å¤§å°ï¼Œä»è€Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨cornerè¿˜å¯ä»¥ä»ä¸‹é¢è¿™ç•ªæ¨å¯¼ä¸­ä¹Ÿå¯ç†è§£ã€‚ ç”±äº$M$æ˜¯ä¸€ä¸ªå®å¯¹ç§°çŸ©é˜µï¼Œå±äºæ­£è§„çŸ©é˜µï¼Œå› æ­¤$M$é…‰ç›¸ä¼¼äºå¯¹è§’çŸ©é˜µï¼Œä¸”ç›¸ä¼¼å˜æ¢çŸ©é˜µ$P$ä¸ºæ­£äº¤çŸ©é˜µã€‚ æˆ‘ä»¬å°†$M$ç›¸ä¼¼å¯¹è§’åŒ–åå¸¦å…¥ç­‰å¼3åï¼Œå¯ä»¥å¾—åˆ°å¦‚ä¸‹å¼å­ $$ E(u,v)=[u, v]P[\\begin{matrix}\\lambda_{1}\u00260\\\\0\u0026\\lambda_{2}\\end{matrix}]P^{T}[u,v]^T \\tag{7} $$ å…¶ä¸­$\\lambda_{1},\\lambda_{2}$åˆ†åˆ«ä¸º$M$çš„ç‰¹å¾å€¼ã€‚ç”±äº$P$ä¸ºæ­£äº¤çŸ©é˜µï¼Œå½“å®ƒä¸å‘é‡ç›¸ä¹˜ï¼Œç›¸å¯¹äºå¯¹è¯¥å‘é‡è¿›è¡Œæ—‹è½¬æˆ–è€…åå°„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æŠŠä¸Šå¼å†™æˆå¦‚ä¸‹å½¢å¼ï¼š $$ E(u,v)=[u', v'][\\begin{matrix}\\lambda_{1}\u00260\\\\0\u0026\\lambda_{2}\\end{matrix}][u',v']^T \\\\ =\\frac{(u^{\\prime})^{2}}{\\frac{1}{\\lambda_{1}}}+\\frac{(v^{\\prime})^{2}}{\\frac{1}{\\lambda_{2}}} \\tag{8} $$ ä»å‡ ä½•ä¸Šï¼Œ$E(u,v)$å¯ä»¥çœ‹ä½œå¯¹ç›´è§’åæ ‡ç³»è¿›è¡Œæ—‹è½¬åçš„ä¸€ä¸ªä¸­å¿ƒä»åœ¨åŸç‚¹çš„æ¤­åœ†ï¼Œå¦‚ä¸‹å›¾ã€‚ æ˜¾ç„¶ï¼Œæ ¹æ®å¼å­8ï¼Œæˆ‘ä»¬ä¾¿èƒ½å¾ˆæ¸…æ™°åœ°ç†è§£å¦‚ä½•é€šè¿‡$\\lambda_1\\lambda_2$çš„å¤§å°æ¥åˆ¤æ–­æ˜¯å¦å­˜åœ¨corneräº†ã€‚ å®ç°ä»£ç ç½‘ç»œä¸Šæœ‰å¾ˆå¤šï¼Œåœ¨æ­¤ç»™ä¸ªpseudo-codeåšå‚è€ƒ def harris_corner_detection(image, k, window_size, threshold, border): # 1. Convert to grayscale gray_image = convert_to_grayscale(image) # 2. Compute gradients in x and y directions img_gx = compute_gradient_x(gray_image) img_gy = compute_gradient_y(gray_image) # 3. Compute products of gradients sq_img_gx = img_gx * img_gx sq_img_gy = img_gy * img_gy img_gx_gy = img_gx * img_gy # 4. Apply Gaussian smoothing sq_img_gx = gaussian_smooth(sq_img_gx, window_size) sq_img_gy = gaussian_smooth(sq_img_gy, window_size) img_gx_gy = gaussian_smooth(img_gx_gy, window_size) # 5. Compute corner response for each pixel corner_response = compute_corner_response(sq_img_gx, sq_img_gy, img_gx_gy, k) # 6. Apply thresholding and non-maximum suppression corners = threshold_and_non_maximum_suppression(corner_response, threshold, window_size) # 7. Mark corners on the original image marked_image = mark_corners(image, corners, border) return marked_image Reference Harris Corner Detection Explained Robert Collins, CSE486, Penn State 16-385 Computer Vision (Kris Kitani), Carnegie Mellon University harris corner detection(è§’ç‚¹æ£€æµ‹) A COMBINED CORNER AND EDGE DETECTOR ","title":"An Application in Matrix Theory:Harris Corner Detection","uri":"/posts/harris_corner_detection/"},{"content":"ä»Šå¤©ä¸Š80æœåŠ¡å™¨è·‘mdistillerçš„ä»£ç æ—¶ï¼Œæ„å¤–å‘ç°torchã€numpyéƒ½ä¸èƒ½ç”¨äº†T_T å¯¼å…¥torchã€numpyåº“æ—¶å‡ºç°å¦‚ä¸‹æŠ¥é”™æƒ…å†µ sh: 0: getcwd() failed: No such file or directory Intel MKL FATAL ERROR: Cannot load /home/jyg/anaconda3/envs/mdisPy37/lib/python3.7/site-packa ges/torch/lib/../../../../libmkl_core.so. Intel MKL FATAL ERROR: Cannot load /home/jyg/anaconda3/envs/mdisPy37/lib/python3.7/site-packa ges/mkl/../../../libmkl_rt.so.1. æˆ‘ä»¬å…ˆçœ‹çœ‹æŠ¥é”™ä¿¡æ¯ï¼Œè¿™ä¸ªæŠ¥é”™æ¥è‡ªInter MKLã€‚Inter MKLå…¨ç§°æ˜¯The Intel Math Kernel Libraryï¼Œå®ƒæ˜¯ä¸€ä¸ªä¸»è¦æ˜¯ç”¨äºç§‘å­¦è®¡ç®—çš„å…±äº«åº“ï¼Œæä¾›äº†å¾ˆå¤šä¸æ•°å­¦ä¼˜åŒ–ç¨‹åºï¼Œä¾‹å¦‚å‘é‡çŸ©é˜µæ“ä½œä»€ä¹ˆçš„ã€‚ æŠ¥é”™ä¿¡æ¯è¯´æ˜æˆ‘ä»¬åœ¨å¯¼å…¥torchæˆ–numpyåº“æ—¶ï¼Œæ— æ³•è½½å…¥libmkl_core.so.å’Œlibmkl_rt.so.1. è¿™ä¸¤ä¸ªæ–‡ä»¶ä»¥soç»“å°¾ï¼Œå±äºå…±äº«åº“æ–‡ä»¶ã€‚ åœ¨Linuxç³»ç»Ÿä¸Šä¸€èˆ¬ä»¥.soæ–‡ä»¶æ‰©å±•å(shared object), åœ¨MacOSä¸Šä»¥.dylibä¸ºæ–‡ä»¶æ‰©å±•å, åœ¨Windowsä¸Šä»¥.dll (dynamic link library)ä¸ºæ–‡ä»¶æ‰©å±•åã€‚ å…±äº«åº“çš„å‡ºç°çš„ä¸€ä¸ªé‡è¦åŸå› æ˜¯é˜²æ­¢é‡å¤é€ è½®å­ï¼Œå®ƒå…è®¸å¤šä¸ªç¨‹åºä½¿ç”¨åŒä¸€ä»½ä»£ç ã€‚ è¿™æ ·ç¨‹åºé‡Œé¢ä¾¿ä¸éœ€è¦é‡å¤å†™ç›¸åŒçš„ä»£ç ï¼Œåªéœ€è¦è®©ç¨‹åºæŒ‡å‘å…±äº«åº“å³å¯ï¼Œæé«˜äº†ç¨‹åºçš„å¯å¤ç”¨æ€§ï¼Œä¹Ÿè®©ç¨‹åºå˜å¾—æ›´modularäº†ã€‚ ä»æŠ¥é”™ä¿¡æ¯æ¥çœ‹ï¼Œå®ƒè¯´æˆ‘ä»¬æ— æ³•è½½å…¥æŸä¸ªæ–‡ä»¶ã€‚é¦–å…ˆæƒ³åˆ°çš„æ˜¯å…ˆç¡®å®šè¿™ä¸ªæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè¿™é‡Œä»¥libmkl_rt.so.1.æ¥è¿›è¡Œåˆ†æã€‚ ä»æˆ‘çš„æœºå™¨ä¸Šè¿è¡Œç»“æœæ¥çœ‹ï¼Œlibmkl_rt.so.1.ç¡®å®å­˜åœ¨ã€‚ é‚£ä¹ˆå¦‚ä½•è®©numpyæˆ–è€…torchåº“èƒ½å¤Ÿæ­£ç¡®çš„æ‰¾åˆ°Inter MKLå…±äº«åº“å¹¶è½½å…¥å®ƒéœ€è¦çš„å…±äº«æ–‡ä»¶å‘¢ï¼Ÿ è¿™å°±ä¸å¾—ä¸è¯´ä¸€ä¸‹LD_LIBRARY_PATHç¯å¢ƒå˜é‡äº†ã€‚ LD_LIBRARY_PATHæ˜¯Linuxç³»ç»Ÿä¸Šä¸€ä¸ªä¸åŠ¨æ€é“¾æ¥æœ‰å…³çš„ç¯å¢ƒå˜é‡ã€‚å¦‚æœå°†å„ä¸ªç¨‹åºæƒ³è±¡æˆå¤§å°ä¸ä¸€çš„æ‹¼å›¾ï¼Œé‚£ä¹ˆé“¾æ¥çš„è¿‡ç¨‹å°±æ˜¯å°†è¿™äº›æ‚ä¹±çš„æ‹¼å›¾æ­£ç¡®åœ°æ‹¼åˆèµ·æ¥ã€‚ å½“æŸä¸ªåº“æˆ–è€…ç¨‹åºéœ€è¦ç”¨åˆ°å…¶ä»–çš„å…±äº«åº“æ—¶ï¼Œåœ¨æœç´¢æ ‡å‡†åº“ç›®å½•ï¼Œä¾‹å¦‚/libæˆ–è€…/usr/libä¹‹å‰ï¼Œæ“ä½œç³»ç»Ÿä¼šé¦–å…ˆä»ç”±LD_LIBRARY_PATHæŒ‡å®šè·¯å¾„ä¸‹è¿›è¡Œæœç´¢ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦å°†è·¯å¾„/home/jyg/anaconda3/envs/mdisPy37/libæ·»åŠ åˆ°LD_LIBRARY_PATHå³å¯ï¼Œå³æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ export LD_LIBRARY_PATH=/home/jyg/anaconda3/envs/mdisPy37/l ib:$LD_LIBRARY_PATH ç°åœ¨ä¾¿èƒ½æ­£å¸¸å¯¼å…¥numpyæˆ–è€…torchåº“äº† ä¸è¦å¿˜äº†ï¼Œæˆ‘ä»¬ç°åœ¨åªæ˜¯åœ¨å½“å‰sessionä¸­ä¸´æ—¶è®¾ç½®äº†LD_LIBRARY_PATHçš„å€¼ï¼Œå¦‚æœå½“å‰ä¼šè¯ç»“æŸäº†ï¼Œé‡æ–°å¼€ä¸€ä¸ªä¼šè¯æ—¶è¿˜éœ€è¦é‡æ–°exportã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ°¸ä¹…æ”¹å˜LD_LIBRARY_PATHçš„å€¼ echo \"export LD_LIBRARY_PATH=/home/jyg/anaconda3/envs/mdisPy37/lib:$LD_LIBRARY_PATH\" \u003e\u003e ~/.bashrc source ~/.bashrc å†™åˆ°è¿™é‡Œï¼Œä½œè€…æƒ³åˆ°ï¼Œæ—¢ç„¶å½“æŸä¸ªç¨‹åºéœ€è¦ç”¨åˆ°å…¶ä»–å…±äº«åº“æ—¶ï¼ŒLinuxæ“ä½œç³»ç»Ÿä¼šé¦–å…ˆä»ç”±LD_LIBRARY_PATHæŒ‡å®šè·¯å¾„ä¸‹è¿›è¡Œæœç´¢ï¼Œé‚£æˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†æœ¬æ¬¡æŠ¥é”™çš„è§£å†³æ–¹æ³•è¿›è¡Œæ¨å¹¿ï¼Œå¦‚æœå…±äº«åº“æ–‡ä»¶abc.soæ— æ³•æ­£å¸¸åŠ è½½ï¼Œä¸”è¯¥å…±äº«æ–‡ä»¶å­˜åœ¨ï¼Œå…¶æ‰€åœ¨ç›®å½•ä¸º/path/ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¾¿å¯ä»¥å°è¯•ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œè§£å†³ï¼š export LD_LIBRARY_PATH=/path/:$LD_LIBRARY_PATH ","title":"æŠ¥é”™Cannot load *.soå¯èƒ½é€šç”¨çš„è§£å†³æ–¹æ³•","uri":"/posts/solution_cannot_load_so/"},{"content":"\næ¢…è´»ç¦å…ˆç”Ÿæœ‰å¥åè¨€ï¼šâ€œæ‰€è°“å¤§å­¦ä¹‹å¤§ï¼Œéæœ‰å¤§æ¥¼ä¹‹è°“ä¹Ÿï¼Œä¹ƒæœ‰å¤§å¸ˆä¹‹è°“ä¹Ÿã€‚â€å®é™…ä¸Šï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰å¯¹â€œå¤§å¸ˆâ€åšå‡ºä¸€ä¸ªç»Ÿä¸€æ ‡å‡†çš„å®šä¹‰ï¼Œäººäººå¿ƒä¸­éƒ½æœ‰è‡ªå·±çš„å¤§å¸ˆã€‚ä½†æˆ‘è®¤ä¸ºå¤§å¸ˆè®²è¯¾è‡³å°‘ä¼šç»™äººä»¥å¯å‘å’Œæ·±æ€ã€‚\nç ”ä¸€å¼€å­¦ï¼Œå¦é—¨å¤§å­¦ä¿¡æ¯å­¦é™¢å‰é™¢é•¿å‘¨æ˜Œä¹æ•™æˆä¸ºæˆ‘ä»¬åšäº†é¢˜ä¸ºã€Šä¿¡æ¯å­¦ç§‘çš„å¤§å­¦ä¹‹é“ã€‹çš„è®²åº§ï¼Œå›ç­”äº†æˆ‘æœ€è¿‘æ€è€ƒçš„ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚é¢å¯¹ChatGPTç­‰ä¿¡æ¯æŠ€æœ¯çš„å†²å‡»ï¼Œä»€ä¹ˆæ‰æ˜¯æ•™è‚²ä¸­æœ€é‡è¦çš„ï¼Ÿè‡³å°‘ä»æŸç§ç¨‹åº¦ä¸ŠçŸ¥è¯†å·²ç»ä¸é‡è¦äº†ã€‚æ•™è‚²çš„ç›®çš„æ˜¯ä½¿äººæˆæ‰ï¼Œé‚£ä¹ˆæœªæ¥äººæ‰éœ€è¦å…·å¤‡å“ªäº›ç‰¹è´¨å‘¢ï¼Ÿ\nå¬å®Œæ•´ä¸ªè®²åº§ï¼Œæˆ‘å¯¹ä¸Šè¿°é—®é¢˜æœ‰äº†ä¸€äº›ç­”æ¡ˆï¼Œå¯¹è®²åº§çš„å¤§è‡´å†…å®¹ä»¥åŠæˆ‘çš„æ€è€ƒè®°å½•å¦‚ä¸‹ã€‚\né¦–å…ˆï¼Œå‘¨è€å¸ˆå…ˆæå‡ºäº†ä¿¡æ¯å­¦ç§‘çš„ä¸‰ç‚¹åŸ¹å…»ç›®æ ‡ã€‚\nä¸€ä¸äºŒæ˜¯å¯¹å­¦é—®ä¸Šçš„è¦æ±‚ï¼Œå³æˆ‘ä»¬ä¸ä»…éœ€è¦äº†è§£æœ¬å­¦ç§‘çš„åŸºæœ¬çŸ¥è¯†å’Œå‰æ²¿ï¼Œè¿˜èƒ½å¤Ÿæ‹“å®½è‡ªå·±çš„çŸ¥è¯†é¢ï¼Œäº†è§£äº¤å‰å­¦ç§‘çš„å†…å®¹ï¼Œä¸ç„¶å­¦é—®å®¹æ˜“æ­»æ°´ä¸€æ½­ã€‚3æ˜¯å¯¹ç ”ç©¶è€…é“å¾·ä¿®å…»ä¸Šçš„è¦æ±‚ï¼Œä¸€æµçš„å­¦è€…å¿—å­˜é«˜è¿œï¼Œåšæœ‰ä»·å€¼ã€æœ‰å½±å“åŠ›çš„ç ”ç©¶ï¼Œè€Œä¸æ˜¯ä¸ºäº†å‘è®ºæ–‡è€Œä¸€å‘³çŒæ°´ã€‚\nè¯´åˆ°è¿™ï¼Œæµ™æ±Ÿå¤§å­¦æ ¡é•¿ç«ºå¯æ¡¢çš„ä¸€æ®µè¯æˆ‘ä¹Ÿå¾ˆèµåŒï¼Œåœ¨ä»Šå¤©çœ‹æ¥ä¹Ÿé¢‡æœ‰ä»·å€¼ã€‚\næˆ‘ä»¬å—é«˜ç­‰æ•™è‚²çš„äººï¼Œå¿…é¡»æœ‰æ˜è¾¨æ˜¯éã€é™è§‚å¾—å¤±ã€ç¼œå¯†æ€è™‘ã€ä¸è‚¯ç›²ä»çš„ä¹ æƒ¯ï¼Œç„¶ååœ¨å­¦æ—¶æ–¹ä¸è‡´å®³å·±ç´¯äººï¼Œå‡ºè€Œç«‹èº«å¤„ä¸–æ–¹èƒ½ä¸è´Ÿæ‰€å­¦ã€‚å¤§å­¦æ‰€æ–½çš„æ•™è‚²ï¼Œæœ¬æ¥ä¸æ˜¯ä¾›ç»™ä¼ æˆç°æˆçš„æ™ºè¯†ï¼Œè€Œé‡åœ¨å¼€è¾ŸåŸºæœ¬çš„é€”å¾„ï¼Œæç¤ºè·å¾—çŸ¥è¯†çš„æ–¹æ³•ï¼Œå¹¶ä¸”åŸ¹å…»å­¦ç”Ÿç ”ç©¶æ‰¹åˆ¤å’Œåçœçš„ç²¾ç¥ï¼Œä»¥æœŸå­¦è€…æœ‰è‡ªåŠ¨æ±‚æ™ºå’Œä¸æ–­ç ”ç©¶çš„èƒ½åŠ›ã€‚\nâ€”â€”å›½ç«‹æµ™æ±Ÿå¤§å­¦æ ¡é•¿ç«ºå¯æ¡¢ 1936å¹´4æœˆ25æ—¥\nè°ˆåˆ°äº¤å‰æ—¶ï¼Œå‘¨è€å¸ˆè¯´ç†å·¥ç§‘å’Œæ–‡ç§‘çš„è€å¸ˆä»¬äº’ç›¸çœ‹ä¸èµ·ï¼Œä»¥è‡³äºè€æ­»ä¸ç›¸å¾€æ¥ã€‚æˆ‘çªç„¶æƒ³èµ·æ¥é«˜ä¸­æ•°å­¦è€å¸ˆä¸¾çš„ä¸€ä¸ªä¾‹å­ï¼Œè¯´ä¸€å¯¹æƒ…ä¾£å»çœ‹æµ·ï¼Œå­¦æ–‡çš„å¥³ç”Ÿä¼šæ„Ÿå¹æµ·é¢çš„å¹¿é˜”ï¼Œæµ·é£çš„æ¸©æŸ”ï¼Œè€Œå­¦ç†å·¥çš„ç”·ç”Ÿå¿ƒé‡Œåªä¼šæƒ³è¿™æœ‰ä»€ä¹ˆæµªæ¼«ï¼Œä¸å°±æ˜¯æ°´ã€é£å˜›ğŸ˜‚ã€‚è¿™æ ·çœ‹æ¥ï¼Œè€å¸ˆä»¬äº’ç›¸çœ‹ä¸èµ·çš„åŸå› å¤§æ¦‚æ˜¯ä¸åŒå­¦ç§‘çœ‹å¾…ä¸–ç•Œçš„æ–¹æ³•ä¸åŒã€‚é‚£ä¹ˆåœ¨æ–‡ç†ä¹‹å¤–æ˜¯å¦å­˜åœ¨ç¬¬ä¸‰ç§æ–‡åŒ–ï¼Œèƒ½å¤Ÿæ²Ÿé€šæ–‡ç†å‘¢ï¼Ÿå¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œè€å¸ˆå‘æˆ‘ä»¬æ¨èäº†ä¸€æœ¬ä¹¦ã€Šç¬¬ä¸‰ç§æ–‡åŒ–ã€‹ã€‚\nè€Œä¿¡æ¯æŠ€æœ¯å¯¹ç¤¾ä¼šçš„å†²å‡»å’Œå˜é©ï¼Œå‘¨è€å¸ˆæ€»ç»“ä¸ºä»¥ä¸‹ä¸‰ç‚¹\nå¯¹äºç¬¬ä¸€ç‚¹ï¼Œç°ä»£ç¤¾ä¼šä¸­å¸¸å¸¸å‡ºç°çˆ¶æ¯ä¸å„¿å¥³å¯¹ç°¿å…¬å ‚ï¼Œç™¾åˆ†ä¹‹ä¸ƒåäº”çš„äººå¤„äºå¿ƒç†äºšå¥åº·ã€‚è€Œè¿™äº›é—®é¢˜çš„è§£å†³éƒ½æœ‰èµ–äºå»ºç«‹å…¨æ–°çš„é“å¾·ä»·å€¼ä½“ç³»ã€‚è€Œå¯¹äºç¬¬ä¸‰ç‚¹åˆ™ä½“ç°åœ¨äº’è”ç½‘ã€é«˜é“é£æœºçš„å‡ºç°ä½¿äººä¸äººä¹‹é—´å˜å¾—å¾ˆçŸ­å¾ˆçŸ­ã€‚\né‚£ä¹ˆäººç±»èŒä¸šåˆ†å¸ƒæ˜¯ä»€ä¹ˆæ ·çš„å‘¢ï¼Ÿ\nå¯¹äºä»ä¸šè€…çš„ç»„æˆï¼Œå‘¨è€å¸ˆå€Ÿé‰´äº†å›½å®¶çš„ä½œç”¨â€”21ä¸–çºªçš„èµ„æœ¬ä¸»ä¹‰å‰æ™¯ä¸€ä¹¦ä¸­çš„è§‚ç‚¹ï¼Œè¯¥ä¹¦æ˜¯ä½œè€…40å¹´å‰å¯¹æœªæ¥ç”Ÿæ´»çš„é¢„è§ï¼Œåœ¨æ­¤çœ‹æ¥éå¸¸å…·æœ‰å‰ç»æ€§ã€‚\næŒ‰ç…§ç¾å›½å­¦è€…ç½—ä¼¯ç‰¹â€¢ èµ–å…‹çš„è§‚ç‚¹ï¼Œä»¥çŸ¥è¯†ç»æµä¸ºä¸»å¯¼çš„ç¤¾ä¼šï¼Œé™¤äº†å…¬å…±äº‹ä¸šçš„ä»ä¸šè€…ä¹‹å¤–ï¼Œç¤¾ä¼šèŒä¸šäººå‘˜ä¸»è¦åˆ†ä¸ºå¦‚ä¸‹ä¸‰ç±»ï¼šä¼ ç»Ÿç”Ÿäº§äººå‘˜ã€ç›´æ¥æœåŠ¡äººå‘˜ä»¥åŠç¬¦å·åˆ†æäººå‘˜ï¼ˆçŸ¥è¯†åˆ›æ–°äººå‘˜ï¼‰ã€‚\nè€Œå¯¹äºæœªæ¥èŒä¸šçš„å˜åŒ–å’Œè½®æ›¿ï¼Œå‘¨è€å¸ˆå‘æˆ‘ä»¬æ¨èäº†å¦ä¸€æœ¬ä¹¦ã€Šç™¾å²äººç”Ÿã€‹ï¼Œè¿™æœ¬ä¹¦ä¸­äº¤ä»£äº†ä¸€ä¸ªåŸºæœ¬äº‹å®ï¼š21ä¸–çºªåˆå‡ºç”Ÿçš„äººæœ‰ä¸€åŠçš„æ¦‚ç‡æ´»åˆ°100å²ï¼Œè¿™æ ·çœ‹æ¥ï¼Œè¿‡å»çš„å—æ•™è‚²â€”å·¥ä½œâ€”é€€ä¼‘ä¸‰é˜¶æ®µäººç”Ÿæ¨¡å¼å·²ä¸å†é€‚ç”¨ï¼Œç»ˆèº«å­¦ä¹ å°†æˆä¸ºå¸¸æ€ã€‚æ­¤å¤–ï¼Œè®¸å¤šèŒä¸šä¼ ç»ŸèŒä¸šå°†æ¶ˆå¤±ã€‚\nã€Šç™¾å²äººç”Ÿã€‹ä½œè€…æŒ‡å‡ºï¼šâ€œ æ¥ä¸‹æ¥çš„å‡ åå¹´ä¸­ï¼Œéšç€ä¸€äº›ä¼ ç»ŸèŒä¸šçš„æ¶ˆå¤±å’Œæ–°å‹èŒä¸šçš„å‡ºç°ï¼ŒåŠ³åŠ¨åŠ›å¸‚åœºå°†å‡ºç°å¤§å¹…å˜åŠ¨ã€‚ã€‚ã€‚ã€‚å±•æœ›æœªæ¥ï¼Œéšç€åå°å¤„ç†ã€é”€å”®ç§Ÿå¸‚åœºè¥é”€ã€åŠå…¬å®¤ç®¡ç†å’Œè¡Œæ”¿ç­‰å„ç§å·¥ä½œè¢«æœºå™¨äººå’Œäººå·¥æ™ºèƒ½å³å–ä»£ï¼Œ è¿™ç§å˜åŠ¨å°†æŒç»­ä¸‹å»ã€‚â€\nå†™åˆ°è¿™é‡Œï¼Œè¯»è€…æƒ³å¿…èƒ½å¤ŸçŒœåˆ°å‘¨è€å¸ˆçš„è®²åº§é£æ ¼ï¼Œå³ä»–ä¼šå°†è‡ªå·±çœ‹è¿‡çš„ä¹¦åˆ—å‡ºæ¥ï¼Œç»“åˆç€ä¹¦é‡Œçš„è§‚ç‚¹å»è®²ä»–çš„è§‚ç‚¹ï¼Œè¿™æ ·å¬å®Œä»–çš„è®²åº§ï¼Œä½ ä¼šå‘ç°è¦è¯»çš„ä¹¦å¯å¤ªå¤šäº†ğŸ˜­ã€‚\nä»€ä¹ˆæ˜¯æœºå™¨éš¾ä»¥å–ä»£çš„èŒä¸šå‘¢ï¼Ÿåœ¨å›ç­”è¿™ä¸ªé—®é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆçœ‹çœ‹ä»€ä¹ˆæ˜¯æœºå™¨æ‰€æ²¡æœ‰çš„å§ï¼Œå‘¨è€å¸ˆè®¤ä¸ºæƒ…æ„Ÿã€è‡ªæˆ‘æ„è¯†ã€ä»¥åŠåˆ›é€ åˆ›æ–°èƒ½åŠ›æ˜¯æœºå™¨ç›®å‰æœ€ç¼ºä¹çš„ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨è¿™ä¸‰æ–¹é¢çš„é¢†åŸŸä¸Šï¼Œæˆ‘ä»¬æ˜¯èƒœè¿‡æœºå™¨çš„ï¼Œæ—¢ç„¶å¦‚æ­¤ï¼Œè¿™ä¸‰æ–¹é¢çš„èƒ½åŠ›ä¾¿éœ€è¦ç€é‡åŸ¹å…»æå‡äº†ã€‚\nã€Šç™¾å²äººç”Ÿã€‹ä½œè€…æŒ‡å‡ºï¼šâ€œæŠ€æœ¯å‘å±•åèƒ½å¤Ÿå¹¸å­˜çš„å·¥ä½œæœ‰ä¸¤ç±»ï¼šä¸€ç±»æ˜¯äººç±»æ‹¥æœ‰ç»å¯¹ä¼˜åŠ¿çš„å·¥ä½œï¼Œä¸€ç±»æ˜¯äººç±»å…·æœ‰ç›¸å¯¹ä¼˜åŠ¿çš„å·¥ä½œã€‚\næˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹å¦‚ä½•åŸ¹å…»åˆ›æ–°èƒ½åŠ›å§ï¼Œå‘¨è€å¸ˆä»¥ä¸­å›½çš„äº”è¡Œä¸ºå–»ï¼Œç»™å‡ºäº†è‡ªå·±çš„çœ‹æ³•ã€‚\nåˆ›æ–°èƒ½åŠ›çš„åŸ¹å…»æœ‰èµ–äºæŠ½è±¡æ€ç»´ã€è‰ºæœ¯å®¡ç¾ã€ç³»ç»Ÿç»¼åˆã€ç§‘å­¦å®éªŒä»¥åŠå›¢é˜Ÿæ²Ÿé€šäº”ç»´æå‡ã€‚\næŠ½è±¡æ€ç»´è¦æ±‚æˆ‘ä»¬å…·æœ‰ä¸€å®šçš„ç†è§£èƒ½åŠ›ï¼Œæ¯”å¦‚æˆ‘ä»¬åœ¨è®¾è®¡æ•°æ®åº“æ—¶ï¼ŒåŸºäºå¯¹å®¢æˆ·éœ€æ±‚çš„ç†è§£ï¼Œé€šè¿‡æ„å»ºE-Rå›¾è¿›è¡Œå»ºæ¨¡ã€‚å› ä¸ºæˆ‘ä»¬èƒ½å¤Ÿç†è§£ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¯¹ç°å®ç”Ÿæ´»ä¸­çš„äº‹ç‰©äº§ç”Ÿå…±æƒ…ã€‚è€Œå¯¹äºä¸€é¡¹å¤æ‚çš„å·¥ä½œè€Œè¨€ï¼Œå¾€å¾€æ˜¯éœ€è¦ç”±ä¸€ä¸ªå›¢é˜Ÿå…±åŒå®Œæˆï¼Œä¾¿éœ€è¦æé«˜å›¢é˜Ÿæ²Ÿé€šèƒ½åŠ›ã€‚\nè€Œåœ¨åšå®éªŒï¼Œäº§ç”Ÿæ–°çš„çŸ¥è¯†çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å¤§èƒ†åœ°å‡è®¾ã€å°å¿ƒåœ°æ±‚è¯ï¼ŒåŸ¹å…»ç§‘å­¦ç²¾ç¥ï¼Œæé«˜ç§‘å­¦å®éªŒçš„èƒ½åŠ›ã€‚ä¹Ÿæ­£å› ä¸ºæˆ‘ä»¬èƒ½å¤Ÿç†è§£ï¼Œæ‰€ä»¥å¯ä»¥æ„Ÿå—ã€‚è‰ºæœ¯å®¶æ˜¯æœ€å…·æœ‰creativityçš„èŒä¸šï¼Œæˆ‘ä»¬éœ€è¦æé«˜è‰ºæœ¯å®¡ç¾ï¼Œäº§ä»è€Œç”Ÿæ›´å¤šæ–°çš„æƒ³æ³•ã€‚é™¤äº†è¿™å››ç»´èƒ½åŠ›å¤–ï¼Œç³»ç»Ÿç»¼åˆèƒ½åŠ›ä¹Ÿå¾ˆé‡è¦ï¼Œæ¯”å¦‚ï¼Œè½¯ä»¶ç³»ç»Ÿæ¶æ„å¸ˆæ‹¿åˆ°çš„æŠ¥é…¬è¿œè¿œé«˜äºåªä¼šå¼€å‘çš„ç å†œã€‚\næƒ…æ„Ÿå’Œè‡ªæˆ‘æ„è¯†å…¶å®éƒ½å¯ä»¥å½’ç»“åˆ°ä¿®å…»èƒ½åŠ›çš„åŸ¹å…»ã€‚å­”é—¨å¿ƒæ³•ã€Šä¸­åº¸ã€‹ä¸­æœ‰ä¸€æ®µè¯æ˜¯è¿™æ ·çš„ã€‚\nå–œæ€’å“€ä¹ä¹‹æœªå‘ï¼Œè°“ä¹‹ä¸­ï¼›å‘è€Œçš†ä¸­èŠ‚ï¼Œè°“ä¹‹å’Œã€‚ä¸­ä¹Ÿè€…ï¼Œå¤©ä¸‹ä¹‹å¤§æœ¬ä¹Ÿï¼›å’Œä¹Ÿè€…ï¼Œå¤©ä¸‹ä¹‹è¾¾é“ä¹Ÿã€‚è‡´ä¸­å’Œï¼Œå¤©åœ°ä½ç„‰ï¼Œä¸‡ç‰©è‚²ç„‰ã€‚\nä¹Ÿå°±æ˜¯è¯´äººçš„æƒ…æ„Ÿéœ€è¦è¾¾åˆ°â€œçš†ä¸­èŠ‚â€ï¼Œå¤©åœ°ä¸‡ç‰©æ‰èƒ½é•¿ä¹…ã€‚ä½†äººå¾€å¾€æ˜¯çˆ±ä¹‹æ¬²å…¶ç”Ÿï¼Œæ¨ä¹‹æ¬²å…¶æ­»ï¼Œè€Œè¿™éœ€è¦é€šè¿‡æé«˜ä¿®å…»èƒ½åŠ›æ¥æ”¹å–„ã€‚\nå½“äººæœ‰äº†è‡ªæˆ‘æ„è¯†æ—¶ï¼Œå¾€å¾€ä¼šç€ç›¸ï¼Œæ‰§ç€äºè‡ªå·±è¿™ä¸ªå°æˆ‘ä¸­ï¼Œä»¥åŠæƒ³ç€é€šè¿‡è‡ªå·±çš„åŠ›é‡èƒ½å¤Ÿå¾æœè‡ªç„¶ã€‚ä½†ç°ä»£äººè¯¸å¤šçš„å¿ƒç†å¥åº·é—®é¢˜ï¼Œä¾‹å¦‚ç„¦è™‘ã€æŠ‘éƒåŸºæœ¬éƒ½æ˜¯å› ä¸ºæ— æ³•æ‘†è„±å°æˆ‘ï¼Œæ–°å† ç–«æƒ…ã€çªå‘çš„æ´ªæ¶ç¾å®³æ›´æ˜¯æ˜¾ç¤ºäº†äººç±»çš„æ¸ºå°ã€‚æ‰€ä»¥ï¼Œä½›å®¶æ•™æˆ‘ä»¬å»æˆ‘æ‰§ã€‚ä¸‹é¢è¿™é¦–è¯—å¾ˆèƒ½å¤Ÿè¯´æ˜æ‰§ç€äºå°æˆ‘ä¹‹äººçš„çŠ¶æ€ã€‚\næ€¥æ€¥å¿™å¿™è‹¦è¿½æ±‚ï¼Œå¯’å¯’æš–æš–åº¦æ˜¥ç§‹ã€‚\næœæœæš®æš®è¥å®¶è®¡ï¼Œæ˜§æ˜§æ˜æ˜ä¸ºå·±è°‹ã€‚\næ˜¯æ˜¯ééä½•æ—¥äº†ï¼Œçƒ¦çƒ¦æ¼æ¼å‡ æ—¶ä¼‘ã€‚\næ˜æ˜ç™½ç™½ä¸€æ¡è·¯ï¼Œä¸‡ä¸‡åƒåƒä¸è‚¯ä¿®ã€‚\nâ€”ã€Šé†’ä¸–è¯—ã€‹æ˜.ç½—æ´ªå…ˆ\næ€»ç»“æ¥è¯´ï¼Œä¿®å…»èƒ½åŠ›çš„åŸ¹å…»ä½“ç°åœ¨äººèƒ½å¤Ÿå¤„ç†å¥½ä¸è‡ªå·±çš„å…³ç³»ã€ä¸ä»–äººçš„å…³ç³»ã€ä¸è‡ªç„¶ä¸‡ç‰©çš„å…³ç³»ã€‚\nä¸Šé¢è®²äº†æˆ‘å¯¹ä¿®å…»èƒ½åŠ›åŸ¹å…»é‡è¦æ€§çš„è®¤è¯†ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å‘¨è€å¸ˆä¸ºä»€ä¹ˆä¼šé‡è§†ä¿®å…»èƒ½åŠ›çš„åŸ¹å…»ã€‚\nå¦‚ä½•åŸ¹å…»ä¿®å…»èƒ½åŠ›å‘¢ï¼Ÿå¯¹äºä¸­å›½äººæ¥è¯´ï¼Œæˆ‘ä»¬åº”è¯¥è¯»å®‰èº«ç«‹å‘½ä¹‹ä¹¦ã€‚ä¾‹å¦‚ã€Šå¤§å­¦ã€‹ã€ã€Šä¸­åº¸ã€‹ã€ã€Šè®ºè¯­ã€‹ç­‰ã€‚æ­£å¦‚è±¡å±±å…ˆç”Ÿæ‰€è¯´ï¼šâ€å­¦é“ä»¥åœ£è´¤ä¸ºå¸ˆï¼Œåœ£è´¤é—ä¹¦ï¼Œä¸‡ä¸–æ ‡çš„ä¹Ÿã€‚â€œ\nä½†è¦æ³¨æ„çš„æ˜¯ï¼Œä¿®å…»èƒ½åŠ›çš„åŸ¹å…»ä¸ä»…éœ€è¦å…ˆä»ä¹¦æœ¬ä¸Šè·å¾—çŸ¥è¯†ï¼Œè¿˜éœ€è¦åœ¨å®é™…ç”Ÿæ´»ä¸­è¿›è¡Œå®è·µä½“ä¼šã€‚åœ¨æ­¤ï¼Œå‘¨è€å¸ˆå°†ã€Šå¤§å­¦ã€‹ä¸­çš„å…«æ¡ç›®è¿›ä¸€æ­¥æ‰©å±•ï¼Œæå‡ºäº†ä¿®ä»æ™ºå¿ƒçš„ä¸‰ä¸ªæ­¥éª¤ï¼Œå³çŸ¥é“ã€è¾¾é“ã€è¡Œé“ã€‚\nåœ¨ä¿®å…»èƒ½åŠ›çš„åŸ¹å…»ä¸Šï¼Œå‘¨è€å¸ˆç€é‡è®²äº†å„’å®¶ç»å…¸ï¼Œè¿™ç¡®å®æ˜¯å¿…ä¸å¯å°‘çš„åŸºç¡€ã€‚æˆ‘ä¸ªäººè®¤ä¸ºé“å®¶ã€ä½›å®¶çš„ä¹¦ä¹Ÿæ˜¯å€¼å¾—ä¸€è¯»çš„ï¼Œå¯¹äºåŸ¹å…»ä¿®å…»èƒ½åŠ›ä¹Ÿæ˜¯æœ‰è£¨ç›Šçš„ï¼Œå„’å®¶ä¸å¦å¤–ä¸¤å®¶çš„ä½œç”¨ç±»ä¼¼äºæ“ä½œç³»ç»Ÿä¸åº”ç”¨è½¯ä»¶çš„å…³ç³»ã€‚è€Œè¿™ä¸‰å®¶çš„ä½œç”¨ï¼Œå¤æ—¦å¤§å­¦ç‹å¾·å³°æ•™æˆæ€»ç»“å¾—å¾ˆç²¾è¾Ÿã€‚\nå„’å®¶æ•™æˆ‘ä»¬â€œæ‹¿å¾—èµ·â€ï¼Œé“å®¶æ•™æˆ‘ä»¬â€œæ”¾å¾—ä¸‹â€ï¼Œä½›å®¶æ•™æˆ‘ä»¬â€œæƒ³å¾—å¼€â€ã€‚â€”â€”ç‹å¾·å³°\nå…³äºè®²åº§çš„è®¨è®ºåˆ°æ­¤ä¸ºæ­¢ã€‚è®²åº§åï¼Œæˆ‘åŠ äº†å‘¨è€å¸ˆçš„å¾®ä¿¡ï¼Œè¡¨ç¤ºæˆ‘å¬å®Œè®²åº§åéå¸¸æ„Ÿå¹ä¸æ”¶è·ã€‚é€šè¿‡è€å¸ˆçš„å¾®ä¿¡ï¼Œå‘ç°å‘¨è€å¸ˆè¿˜ä¼šå¼¹å¤ç´ï¼ŒçœŸæ˜¯ä¸€ä½æœ‰è¶£çš„äººã€‚ğŸ˜„\nåæ¥ï¼Œæˆ‘è¿˜å»å‚åŠ äº†è€å¸ˆå¼€è®¾çš„ä¹æ˜“è¯»ä¹¦ä¼šï¼Œæ´»åŠ¨è‡´åŠ›äºåŒ–å¯¼æ°‘ä¼—çš„å¥åº·å¹¸ç¦ç”Ÿæ´»ã€æå‡æ°‘ä¼—çš„ä¼˜è‰¯å¿ƒç†å“è´¨ï¼Œå…¶å®—æ—¨æ˜¯ï¼šâ€œè¯»åœ£è´¤ä¹¦ã€æ˜ç§‘å­¦ç†ã€ä¿®ä»æ™ºå¿ƒâ€ã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œè¿™æ˜¯ä¸€ä»¶å¾ˆæœ‰æ„ä¹‰çš„äº‹æƒ…ï¼Œå› ä¸ºæˆ‘æ„Ÿè§‰å¤§å­¦æ•™æˆä¸å­¦æœ¯ç ”ç©¶å…¶å®æ˜¯ç¦»æ™®é€šå¤§ä¼—å¾ˆé¥è¿œçš„ä¸œè¥¿ã€‚ä½†å½“ä»–é€€ä¼‘ï¼Œä¸å†ä»¥å­¦æœ¯ä¸ºä¸­å¿ƒäº†ï¼Œè€ŒæŠ•å…¥åˆ°å¸®åŠ©æ°‘ä¼—ä¸­ï¼Œä¹Ÿä½•å°ä¸æ˜¯ä¸€ä»¶å¥½äº‹å‘¢ï¼Ÿæˆ‘æƒ³è¿™ä¹Ÿæ˜¯å‘¨è€å¸ˆå¾®ä¿¡ä¸ªæ€§ç­¾åï¼šâ€œä¸ºæ°‘æ’­æ’’æºæ‚Œæƒ…â€çš„å«ä¹‰å§ã€‚ğŸ¤”\n","title":"ä¿¡æ¯å­¦ç§‘çš„å¤§å­¦ä¹‹é“","uri":"/posts/higher_education_of_computer_science/"},{"content":"I have been developing 2030 project almost more than one month. I primarily focus on analysing and cleaning data. Recently, Iâ€™ve delved into some advanced work about LLM. Specifically, I use LoRA to fine-tune Chinese-Llama-2-7b. In the beginning, five postgraduates were working on similar tasks as mine on different dataset. Sometimes, serval Ph.D students also use the same server. However, we only have 8 NVIDIA A800 on the server for fine-tuning LLM. It is quite annoying to see available GPUs slip away simply because we were slightly slow in executing commands. Therefore, efficiently securing enough GPUs under limited resources becomes crucial. In summary, my goal is to design a Python program that can help me grab available GPUs and once I acquire $n$ GPUs, then start running the real program. Before delving into the solution, Iâ€™d like to share something else. Creating a program to grab GPUs aligns with the first of the Three Virtues of a Programmer â€” Laziness. This is because automated GPU allocation saves me more time and energy compared to do it manually. Moreover, automation enhances efficiency and accuracy. The process of automating tasks is also a great way to hone my programming skills. Now, letâ€™s delve into the source codes and briefly discuss the main idea. To grab GPUs, we first need to gather the information about GPUs. For this, I leverage the Python libaray subprocess to execute the nvidia-smi command, which provides details about GPU status. The get_gpu_mem function retrieves the memory of a specified GPU while get_free_gpus returns available GPUs as a list. def get_gpu_mem(gpu_id): gpu_query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']) gpu_memory = [int(x) for x in gpu_query.decode('utf-8').split('\\n')[:-1]] return gpu_memory[gpu_id] def get_free_gpus()-\u003elist: gpu_query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']) gpu_memory = [int(x) for x in gpu_query.decode('utf-8').split('\\n')[:-1]] free_gpus = [i for i, mem in enumerate(gpu_memory) if mem \u003c 100] return free_gpus So, how to occupy available GPUs ? I employ Pythonâ€™s multiprocessing library to achieve this. If there are $n$ avaible GPUs, $n$ subprocesses will their own GPU. In the main process for-loop, the update rate of the occupy_num variable lags far behind the actual code execution. As a result, the occupy_all_gpus function spawns numerous subprocesses. In fact, the total number of subprocesses exceeds $n$ . However, thanks to the Lock mechanism, only $n$ subprocesses get to occupy GPUs and grab GPUs orderly. To occupy a GPU essentially means claiming its memory. In the occupy_gpu function, I generate a high-dimensional torch tensor on the designated GPU and then make the subprocess enter a sleep state. def occupy_gpu(gpu_id:int, n, occupy_num, ocpy_gpus, lock, a_dim=100000): with lock: if get_gpu_mem(gpu_id) \u003c 100 and occupy_num.value \u003c n: import torch a = torch.ones((a_dim,a_dim)).cuda(gpu_id) ocpy_gpus[occupy_num.value]= gpu_id occupy_num.value += 1 print(f\"Occupying GPU {gpu_id}, Total Occupied: {occupy_num.value}\") while True: time.sleep(10) def occupy_all_gpus(n:int, occupy_num, ocpy_gpus, interval=10): print(\"Launching process to occupy GPU ...\") lock = Lock() processes = [] #List to store the processes while occupy_num.value \u003c n: free_gpus = get_free_gpus() will_occupy_num = min(n, max(0,len(free_gpus))) for i in range(will_occupy_num): if occupy_num.value \u003c n: p = Process(target=occupy_gpu, args=(free_gpus[i], n, occupy_num, ocpy_gpus, lock)) p.start() processes.append(p) time.sleep(interval) # enough time to occupy gpus and update nvidia-smi return processes, ocpy_gpus With that, I conclude the introduction to the mechanism of occupying GPUs ends. Once weâ€™ve occupy $n$ GPUs, it`s time to run our real program. However, before that, we need to terminate all the subprocesses. def run_my_program(n, desired_script, processes, ocpy_gpus, occupy_num): for p in processes: p.terminate() ocpy_gpus_list = list(ocpy_gpus[:occupy_num.value]) cuda_visible_devices = \",\".join(map(str, ocpy_gpus_list)) os.environ['CUDA_VISIBLE_DEVICES'] = cuda_visible_devices subprocess.run([desired_script, str(n)]) In a nutshell, the core of my solution is employing Python multiprocessing to occupy GPUs memory. The source code is available for download here. I developed it using Python 3.11. You can run the script by executing the following command. python grab_gpu.py --n 3 --otime 30 --spath ./train.sh I finish the whole work from programming to polish this blog by the help of chatGPT. The capabilities of this tool have profoundly transformed my academic and personal life. The more I engage with it, the more I feel canâ€™t live without it. This evokes mixed feelings. While Iâ€™m elated witnessing the moumental strides AI is making to better our lives, the sheer potency of AI instills a lingering apprehension that one day, AI might spiral out of our control.ğŸ¤” The emergence of tools like chatGPT prompts reflection on topics such as the essence of human learning and the evolving nature of a programmerâ€™s role. Recently, Iâ€™ve been reading The Art of Unix Programming.\" Inspired by its title, Iâ€™ve chosen to name my blog The Art of GPU Occupation.ğŸ˜ Hope this blog can help you and if you have any questions or insights, I welcome a hearty discussion! ğŸ˜† ","title":"The Art of GPU Occupation","uri":"/posts/the_art_of_gpu_occupation/"},{"content":"æˆ‘äº2023å¹´7æœˆ5æ—¥-7æœˆ9æ—¥åœ¨æ­å·æ¡åºå¿—å¿ƒä¹¦é™¢å‚åŠ ä¸ºæœŸ5å¤©çš„é’å¹´ç«‹å¿ƒè¥ï¼Œæœ‰äº›æ„Ÿæƒ³ï¼Œé‚æˆæ­¤æ–‡ã€‚ æˆ‘æ˜¯åœ¨å¤§ä¸‰ä¸Šçš„å¹¸ç¦å­¦è¯¾ä¸ŠçŸ¥é“å¿—å¿ƒä¹¦é™¢çš„ï¼Œå½“æ—¶è¯¾å ‚çš„å®è·µä½œä¸šé€‰é¡¹ä¹‹ä¸€æ˜¯æ¥å¿—å¿ƒå½“å¿—æ„¿è€…ã€‚ä½†ç”±äºç–«æƒ…ä»¥åŠä¸ªäººæ—¶é—´å†²çªç­‰ç¼˜æ•…ï¼Œæˆ‘ç›´åˆ°2023å¹´æš‘æœŸæ‰å‚ä¸äº†æ­¤æ¬¡æ´»åŠ¨ã€‚ è€Œå‚åŠ è¯¥æ´»åŠ¨çš„åŸå› åœ¨äºæˆ‘æƒ³æ¥ä½“éªŒå½“ä»£æ˜¯å¦‚ä½•å¼˜æ‰¬ä¼ ç»Ÿæ–‡åŒ–çš„ã€‚æˆ‘æœ¬èº«æ˜¯å¯¹ä¼ ç»Ÿæ–‡åŒ–æ˜¯æ¯”è¾ƒæ„Ÿå…´è¶£çš„ï¼Œåœ¨å¹³æ—¥ç¹å¿™çš„ç§‘ç ”ä»»åŠ¡ä¸­ï¼Œæˆ‘æ€»ä¼šè§ç¼æ’é’ˆåœ°å¬ä¸€äº›ç›¸å…³çš„è®²åº§ã€‚é‚£ä¹ˆç°å®ä¸­çš„ä¼ ç»Ÿæ–‡åŒ–åå®¶è®²è¯¾åˆæ˜¯å¦‚ä½•çš„å‘¢ï¼Ÿç±»ä¼¼ä¹¦é™¢èˆ¬çš„æ´»åŠ¨åˆä¼šç»™å¸¦æ¥äº›ä¸ä¸€æ ·çš„ä½“ä¼šå‘¢ï¼Ÿè¿™äº›é—®é¢˜æˆ‘éƒ½æŒºå¥½å¥‡çš„ï¼Œå¸Œæœ›èƒ½ä»è¿™æ¬¡æ´»åŠ¨ä¸­æ‰¾åˆ°ä¸€äº›ç­”æ¡ˆã€‚ 7.5ä¸Šåˆï¼Œåœ¨æ™¨è¯»ã€æ—©é¤ä¹‹åï¼Œæˆ‘ä»¬æ¥åˆ°æ•™å®¤ä¸¾è¡Œäº†é‡Šèœç¤¼ï¼Œå‘å…ˆå¸ˆå­”å­è¡Œå¥ ç¥­ä¹‹ç¤¼ï¼Œä»¥è¡¨ç¤ºå…¥å­¦ã€‚ ä¸¾è¡Œå®Œé‡Šèœç¤¼ä¹‹åï¼Œä¸­å¤®ç¤¾ä¼šä¸»ä¹‰å­¦é™¢å‰¯æ•™æˆæå‹‡åˆšè€å¸ˆä½œäº†é¢˜ä¸ºã€Šä¼ ç»Ÿæ–‡åŒ–å­¦ä¹ äº¤æµã€‹çš„åˆ†äº«ã€‚ æè€å¸ˆé¦–å…ˆå›é¡¾äº†è‡ªå·±å­¦ä¹ ä¼ ç»Ÿæ–‡åŒ–çš„ç›¸å…³ç»å†ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæè€å¸ˆå°±åƒä¸€ä½ä¹…è¿çš„è€å‹ï¼Œç»†æ•°ç€å­¦ä¹ å„’å®¶æ€æƒ³çš„å†ç¨‹ï¼Œå‘ä½ å¨“å¨“é“æ¥ã€‚ æè€å¸ˆæåˆ°è‡ªå·±ä»¥å‰å»æ–°ç–†æ”¯æ•™æ—¶ï¼Œå‘å­©å­ä»¬æ•™æˆã€Šä¸‰å­—ç»ã€‹ã€ã€Šåƒå­—æ–‡ã€‹ç­‰å„’å®¶ç»å…¸ï¼Œå¶ä¸€æ—©ï¼Œå¿½é—»æ“åœºä¸Šå­©å­ä»¬è‡ªå‘æœ—è¯µç»å…¸ä¹‹å£°ï¼Œä¸ç¦æ½¸ç„¶æ³ªä¸‹ã€‚åˆå¦‚åœ¨åšå£«è®ºæ–‡çš„é€‰é¢˜ä¸Šæ°èµ¢æ‰§æ‹—çš„åŒ—å¤§æŸè€æ•™æˆï¼Œä½œæ˜¥ç§‹å…¬ç¾Šå­¦è®ºæ–‡ã€‚07å¹´å»ç»™å¹²éƒ¨è®²å„’å®¶ç»å…¸è¯¾æ—¶ï¼Œè¯¾æ²¡ä¸Šåˆ°ä¸€åŠä¾¿ä»¥â€œä¼ æ’­å°å»ºç³Ÿç²•â€çš„ç†ç”±è¢«èµ¶å‡ºæ¥ã€‚åœ¨ä»–å™è¿°çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ„Ÿå—åˆ°æè€å¸ˆå¯¹ç»å…¸çš„å–œçˆ±ä¸å½“æ—¶æ±‚å­¦å’Œä¸ºå­¦çš„è‰°è¾›ã€‚ è€å¸ˆå¯¹å„’å­¦æ˜¯æ¯”è¾ƒæ¨å´‡çš„ï¼Œä»–è®¤ä¸ºå„’é‡Šé“ä¸‰å®¶å…¶å®æ˜¯ä¸å¯¹ç­‰ï¼Œå„’å®¶æ˜¯å¦å¤–ä¸¤å®¶çš„åŸºç¡€ï¼Œå°±åƒå„’å®¶æ‰®æ¼”äº†æ“ä½œç³»ç»Ÿçš„è§’è‰²ï¼Œå…¶ä»–å­¦è¯´åªæ˜¯æ“ä½œç³»ç»Ÿä¸Šçš„åº”ç”¨ç¨‹åºã€‚ æ¥ç€ï¼Œæè€å¸ˆè®²è§£äº†é©¬å…‹æ€ä¸»ä¹‰ï¼Œè§£é‡Šäº†ä¸ºä»€ä¹ˆåªæœ‰é©¬å…‹æ€ä¸»ä¹‰èƒ½è§£å†³ä¸­å›½äººâ€œä¸€ç›˜æ•£æ²™â€çš„é—®é¢˜ï¼Œè¯¦ç»†åœ°è®ºè¿°äº†é©¬å…‹æ€ä¸»ä¹‰å…¶å®æ˜¯å’Œä¸­åä¼ ç»Ÿæ–‡åŒ–æ˜¯ç›¸é€šçš„ï¼Œæ¯”å¦‚é©¬å…‹æ€è®¤ä¸ºâ€œäººæ˜¯ä¸€åˆ‡ç¤¾ä¼šå…³ç³»çš„æ€»å’Œâ€ä¸å„’å®¶çš„â€œä¸‰çº²äº”å¸¸â€æ˜¯ç›¸è”ç³»çš„ã€‚ æœ€åï¼Œæè€å¸ˆæŠ½ä¸å‰¥èŒ§åœ°åˆ†æäº†ä¹ ä¸»å¸­åœ¨6.2æ–‡åŒ–ä¼ æ‰¿å‘å±•åº§è°ˆä¼šä¸Šçš„è®²è¯ï¼Œåœ¨çœ‹ä¼¼æ™®é€šçš„å®˜æ–¹è¯è¯­ä¸­é¥±å«æ·±å±‚é€»è¾‘å’Œå«ä¹‰ï¼Œçœ‹å¾—å‡ºå…šå’Œå›½å®¶å¯¹æ–‡åŒ–çš„ä¼ æ‰¿å‘å±•é«˜åº¦é‡è§†ï¼Œå¦‚ä»Šä¸­åä¼ ç»Ÿæ–‡åŒ–æ­£åœ¨ç¥å·å¤§åœ°ä¸Šå¤è‹ã€‚ ä¸‹åˆï¼ŒåŒ—å¤§æ³•å­¦å­¦å£«ã€æ¸¯ä¸­æ–‡æ–‡å­¦å’Œå†å²å­¦åŒç¡•å£«æ›¹ç‰éªè€å¸ˆä¸ºæˆ‘ä»¬ä½œäº†ã€Šè¯»ä¸‡å·ä¹¦ã€è¡Œä¸‡é‡Œè·¯ã€‹çš„åˆ†äº«ã€‚ ä»æ›¹è€å¸ˆçš„åˆ†äº«ä¸­ï¼Œä½¿æˆ‘æ˜ç™½ï¼Œä¸‡å·ä¹¦å’Œä¸‡é‡Œè·¯å…¶å®éƒ½ä¸é‡è¦ï¼Œé‡è¦çš„æ˜¯ä½ èƒ½å¤Ÿé©¾é©­ä½ çš„å¿ƒï¼Œè¾¾åˆ°è¯»ä¸‡å·ä¹¦å’Œè¡Œä¸‡é‡Œè·¯çš„ç›®çš„å³å¯ï¼Œè€Œä¸æ˜¯è¢«è¿™äº›æµ®åœ¨è¡¨é¢çš„å½¢å¼ç‰µç€é¼»å­èµ°ã€‚æ¯”å¦‚å…­ç¥–æƒ èƒ½æ˜¯ä¸ªæ–‡ç›²ï¼Œä¸è¯†å­—ï¼Œæ²¡è¯»è¿‡ä¹¦ï¼›ä¼Ÿå¤§çš„å“²å­¦å®¶åº·å¾·ä¸€è¾ˆå­éƒ½æ²¡ç¦»å¼€è¿‡ä»–çš„å®¶ä¹¡ã€‚ä½†äºŒäººéƒ½æ˜¯å¤§æˆå°±è€…ã€‚ æ™šä¸Šï¼Œåå—å†œä¸šå¤§å­¦å›½å­¦é™¢å‰¯é™¢é•¿å”å…ƒå¹³è€å¸ˆç»“åˆè‡ªå·±çš„ç»å†ä¸ºæˆ‘ä»¬ä½œäº†ã€Šå„’å®¶ä¸­çš„â€œå­â€ã€‹çš„åˆ†äº«ã€‚ å”è€å¸ˆå£°ç§°è‡ªå·±å·²è¯µè¯»è¿‡ä¸Šåƒéè®ºè¯­ï¼Œä¸”å¯¹é’±ç©†å…ˆç”Ÿååˆ†æ¨å´‡ã€‚æˆ‘ç¿»äº†ä¸‹æˆ‘åšçš„ç¬”è®°ï¼Œä¼¼ä¹æˆ‘ä»è®²è¯¾çš„å†…å®¹æ²¡æœ‰å­¦åˆ°æ¯”è¾ƒæ–°æˆ–è€…é‡è¦çš„ä¸œè¥¿ï¼Œä½†è€å¸ˆæäº†ä¸¤ä¸ªå»ºè®®æˆ‘è§‰å¾—å¯¹æˆ‘è¿˜è›®é‡è¦çš„ã€‚ä¸€æ˜¯å»ºè®®æˆ‘ä»¬è¯»ä¸€è¯»é’±ç©†çš„ã€Šè®ºè¯­æ–°è§£ã€‹èƒ½å¤Ÿå¯¹è®ºè¯­ä¼šé€šï¼Œæ¨ä¼¯å³»çš„ã€Šè®ºè¯­è¯‘æ³¨ã€‹åªæ˜¯ç¿»è¯‘ç½¢äº†ã€‚äºŒæ˜¯æ´»çš„ä¹…ã€ä¿æŒèº«ä½“å¥åº·å¾ˆé‡è¦ï¼Œä¸è¦ç†¬å¤œï¼Œä»€ä¹ˆäº‹éƒ½å¯ä»¥ç•™åˆ°æ˜å¤©åšğŸ˜‰ã€‚ 7.6ä¸Šåˆï¼Œæµ™æ±Ÿçœå„’å­¦å­¦ä¼šå¸¸ç†äº‹å…¼ç§˜ä¹¦é•¿ï¼Œæµ™æ±Ÿå·¥å•†å¤§å­¦å‰¯æ•™æˆç‹æ™“å¹³è€å¸ˆä¸ºæˆ‘ä»¬ä½œäº†ã€Šåœ¨å„’å­¦çš„å¤©ç©ºä¸‹ï¼Œè¿½å¯»ä¸­å›½æ¢¦ã€‹çš„åˆ†äº«ã€‚ ç‹è€å¸ˆè®²çš„å¾ˆè´´è¿‘ç”Ÿæ´»ï¼Œå¥¹é€šè¿‡åˆ†æå„’å®¶ç»å…¸ï¼Œä¸ºæˆ‘ä»¬åœ¨ç”Ÿæ´»ä¸­å¦‚ä½•äº¤æœ‹å‹ã€è°ˆæ‹çˆ±ã€æ•™è‚²ç­‰æ–¹é¢æäº†å¾ˆå¤šå®ç”¨çš„å»ºè®®ã€‚æ­¤å¤–ï¼Œå¥¹å…³äºå„’å®¶ç»å…¸çš„ä¸€äº›ç‹¬åˆ›æ€§çš„é˜è¿°å¾ˆæœ‰æ„æ€ï¼Œæ¯”å¦‚åœ¨å½“ä»Šç¤¾ä¼šï¼Œç‹¬å–„å…¶èº«å’Œå…¼æµå¤©ä¸‹å…¶å®æ˜¯éƒ½éœ€è¦çš„ï¼Œæœ‰çš„äººä¼ä¸šåšçš„å¾ˆå¥½ï¼Œä½†å®¶åº­å…³ç³»å¤„ç†å¾ˆå·®ã€‚ ä¸‹åˆï¼Œå®‰å¾½ç§‹æµ¦ä¹¦é™¢é™¢é•¿å§šèˆœé›¨è€å¸ˆä¸ºæˆ‘ä»¬ä½œäº†ã€Šæ–‡åº™é‡Šå¥ ç¤¼çš„å†å²æ²¿é©ã€‹çš„è®²åº§ã€‚ å§šè€å¸ˆä»å•†å‘¨æ—¶ä»£è®²èµ·ï¼Œè´¯ç©¿åˆ°æ˜æ¸…æ—¶æœŸï¼Œæ•´ä¸ªè®²åº§å¾ˆåå‘äºè€ƒæ®å­¦ï¼Œä½†æˆ‘å¹¶æ˜¯å¾ˆæœ‰å…´è¶£ï¼Œå†åŠ ä¸Šåœ¨ä¹¦é™¢æ€»æ˜¯ç¡ä¸å¥½ï¼Œäºæ˜¯ğŸ˜´ã€‚ã€‚ã€‚ä½†å§šè€å¸ˆæœ¬äººå¾ˆæœ‰é­…åŠ›ï¼Œé…·çˆ±è¯»ä¹¦ï¼Œè—ä¹¦æœ‰ä¸‰åƒå¤šæœ¬ï¼Œå’Œä»–èŠå¤©éå¸¸æœ‰æ„æ€ï¼Œè®²èµ·è¯æ¥æ»”æ»”ä¸ç»ï¼Œè€å¸ˆä¼¼ä¹ä»€ä¹ˆéƒ½çŸ¥é“ï¼Œå¦‚åŒä¸€æœ¬è¡Œèµ°çš„ç™¾ç§‘ï¼Œå¾ˆæœ‰å¤ä»£æ–‡äººä¹‹é£ã€‚ 7.7ä¸Šåˆï¼Œå­”å­ç¬¬78ä»£å­™ï¼Œæ›²é˜œå­”å­ä¹¦é™¢é™¢é•¿å­”ä¼—å…ˆç”Ÿä¸ºæˆ‘ä»¬ä½œäº†ã€Šç”Ÿå‘½è§‰è€… å¤§å­¦ä¹‹é“ã€‹çš„åˆ†äº«ã€‚ å­”ä¼—å…ˆç”Ÿéå¸¸å¹³æ˜“è¿‘äººï¼Œä»–å¾ˆå–œæ¬¢å’ŒåŒå­¦ä»¬äº’åŠ¨ï¼Œä»–æ€»æ˜¯èµ°ä¸‹è®²å°ï¼Œæ¥åˆ°å­¦ç”Ÿä»¬ä¸­é—´ï¼Œå’ŒåŒå­¦è®¨è®ºäº’åŠ¨ã€‚æˆ‘è®¤ä¸ºå­”ä¼—å…ˆç”Ÿæƒ³å‘Šè¯‰æˆ‘ä»¬æ ¸å¿ƒçš„ä¸€ç‚¹æ˜¯ï¼Œè«å‘å¤–æ±‚ï¼Œè¦å›å½’æœ¬å¿ƒï¼Œé€šè¿‡å­¦ä¹ åœ£è´¤æ™ºæ…§ï¼Œæ‰¾åˆ°å¯¹ç”Ÿå‘½çš„ä¿¡å¿ƒå’Œè‡ªå·±çš„ä¿¡ä»°ï¼Œæ˜å¿ƒè§æ€§ï¼Œæ‰¾åˆ°è‡ªå·±çš„æœ¬æ¥é¢ç›®ã€æœ¬çœŸã€‚ ä¸‹åˆï¼Œä¸»è¦æ˜¯é‚€è¯·äº†ä¸¤ä½å—ä¼ ç»Ÿæ–‡åŒ–å½±å“è¾ƒæ·±çš„ä¼ä¸šå®¶ã€å­”ä¼—å…ˆç”Ÿã€å­¦ç”Ÿè¿›è¡Œæé—®å’Œè®¨è®ºï¼Œé—®é¢˜å’Œå›ç­”åœ¨æ­¤ä¾¿ä¸ä¸€ä¸€åˆ—ä¸¾äº†ã€‚ æ™šä¸Šï¼ŒåŒ—äº¬å¤§å­¦ç»å…¸ä¸æ–‡æ˜ç ”ç©¶ä¸­å¿ƒç§˜ä¹¦é•¿æˆ´ç†™å®è€å¸ˆä¸ºæˆ‘ä»¬ä½œäº†ã€Šä¸­å›½å¼ç°ä»£åŒ–çš„æ–‡æ˜æœºç†ã€‹ï¼Œæˆ´è€å¸ˆåœ¨è®ºè¿°è§‚ç‚¹æ—¶éå¸¸æœ‰é€»è¾‘æ€§ï¼Œæ€ç»´ååˆ†ç¼œå¯†ï¼Œç»™æˆ‘ä¸€ç§ç†ç§‘å‡ºèº«çš„æ–‡ç§‘ç”Ÿçš„æ„Ÿè§‰ã€‚å¯¹äºé‚£äº›æˆ‘æ„Ÿå…´è¶£çš„éƒ¨åˆ†ï¼Œæˆ‘éƒ½èšç²¾ä¼šç¥åœ°å¬ç€ï¼Œç”Ÿæ€•æœ‰æ¼æ‰è€Œè·Ÿä¸ä¸Šä»–çš„èŠ‚å¥ã€‚ æˆ´è€å¸ˆä»è¥¿æ–¹çš„æ–‡æ˜è®²èµ·ï¼Œåˆ°ä¸­åæ–‡æ˜ï¼Œå¹¶å°†äºŒè€…è¿›è¡Œå¯¹æ¯”ã€‚åœ¨æœ€åè®¨è®ºä¸­åæ–‡æ˜æ—¶ï¼Œç‰¹åˆ«æ˜¯å…³äºå„’å®¶æ€æƒ³éƒ¨åˆ†ï¼Œä»–æå‡ºäº†ä¸€ä¸ªæ¨¡å‹ï¼Œæ¥è¯´æ˜å„’å®¶æ€æƒ³å…·æœ‰åŒ…å®¹æ€§ï¼Œè¿›è€Œè¡¨æ˜æ•´ä¸ªä¸­åæ–‡æ˜èƒ½å¤Ÿå¸æ”¶å¤–æ¥æ–‡åŒ–ï¼Œæµ·çº³ç™¾å·ï¼Œä¸ºæˆ‘æ‰€ç”¨ã€‚ æ­¤å¤–ï¼Œæˆ´è€å¸ˆè¿˜æåˆ°é‡å­ç‰©ç†ä¸åŒäºç‰›é¡¿æ‰€æ„å»ºçš„ç§‘å­¦ä½“ç³»ï¼Œå…¶èƒŒåçš„å“²å­¦æ€æƒ³æ˜¯ä¸ä¸­åæ–‡åŒ–ç›¸å¥‘åˆçš„ã€‚ 7.8ä¸ŠåˆåŒ—äº¬å¤§å­¦è€•è¯»ç¤¾ç¬¬å…­ä»»ç¤¾é•¿å´åº†å‰è€å¸ˆä¸ºæˆ‘ä»¬è¿›è¡Œäº†æˆè¯¾ã€‚ å´è€å¸ˆè®²è¯¾æ²¡æœ‰ä¸»é¢˜ï¼Œä»–é¦–å…ˆç®€å•ä»‹ç»äº†ä¸€ä¸‹è‡ªå·±çš„æ±‚å­¦å’Œå·¥ä½œæƒ…å†µï¼Œç„¶åè®©åŒå­¦ä»¬æé—®é¢˜ï¼Œä»–è¿›è¡Œå›ç­”ï¼Œè¯¾å ‚ç›¸å…³æˆ–è€…ä¸ç›¸å…³çš„é—®é¢˜éƒ½è¡ŒğŸ˜ƒã€‚æ®è¯´å´è€å¸ˆä»¥å‰åœ¨åŒ—å¤§æ±‚å­¦æ—¶ï¼Œä»–çš„è€å¸ˆæˆè¯¾æ–¹å¼ä¾¿æ˜¯å¦‚æ­¤ã€‚ å´è€å¸ˆçš„æ±‚å­¦ç»å†è®©æˆ‘æ„Ÿåˆ°å¾ˆæƒŠè®¶ï¼Œæœ¬ç§‘å¤æ—¦åŠ›å­¦-\u003eåŒ—å¤§å¤–å›½å“²å­¦ç¡•-\u003eåŒ—å¤§å›½å­¦åš-\u003eæ¸…åç»æµç®¡ç†å­¦åšåã€‚äºæ˜¯ï¼Œæˆ‘å‘ä»–æé—®å¦‚ä½•çœ‹å¾…é€šæ‰å’Œä¸“æ‰ï¼Ÿè€å¸ˆçš„å»ºè®®æ˜¯ç”±ä¸“åˆ°é€šï¼Œä½†ä½ åœ¨æˆä¸ºä¸“æ‰åï¼Œå¯èƒ½ä¼šå˜å¾—ä¸æ„¿æ„èˆå¼ƒå·²æœ‰çš„ï¼Œå»æ¢ç´¢æ–°é¢†åŸŸï¼Œå› ä¸ºä½ å·²è¢«è´´ä¸Šæ ‡ç­¾ã€‚ å´è€å¸ˆç›®å‰æ˜¯è·Ÿç€æŸé™¢å£«ç ”ç©¶é‡å­è®¡ç®—èƒŒåçš„å“²å­¦æ€æƒ³ï¼Œå› æ­¤ï¼Œæœ‰ä½åŒå­¦é—®åˆ°æœ‰å…³é‡å­è®¡ç®—æœºçš„é—®é¢˜ï¼Œå´è€å¸ˆæåˆ°é‡å­è®¡ç®—æœºæœ‰éå¸¸å¤§çš„å‘å±•æ½œåŠ›ã€‚æ¯”å¦‚åƒGPT4çš„è®­ç»ƒæ˜¯éå¸¸è€—æ—¶çš„ï¼Œè€Œé‡å­è®¡ç®—çš„æˆåŠŸåº”ç”¨èƒ½å¤Ÿä½¿è®­ç»ƒæ—¶é—´ç¼©å°å‡ ç™¾å€ã€‚ è¿˜è®°å¾—åŠä¸ªæœˆå‰å»Amazonçš„ä¸­å›½äº‘å³°ä¼šä¸Šå¬é‡å­è®¡ç®—çš„è®²åº§ï¼ŒAmazonçš„é‡å­è®¡ç®—ç§‘å­¦å®¶è®²åˆ°ï¼Œé‡å­è®¡ç®—æ˜¯ä¸€ç§åˆ©ç”¨é‡å­åŠ›å­¦çš„è®¡ç®—æ¨¡å¼ï¼Œå®ƒä¸ºæˆ‘ä»¬è§£å†³é—®é¢˜æä¾›äº†ä¸€ç§æ–°çš„æ–¹å¼ã€‚æ¯”å¦‚ï¼Œåœ¨ä¸€å¼ çº¸ä¸Šçš„ä¸¤ç‚¹ï¼Œé€šå¸¸æˆ‘ä»¬è®¤ä¸ºä¸¤ç‚¹ç›´çº¿è·ç¦»æ˜¯æœ€çŸ­çš„ï¼Œä½†å¦‚æœæˆ‘ä»¬å°†è¿™å¼ çº¸å¯¹æŠ˜ï¼Œä¸¤ä¸ªç‚¹çš„è·ç¦»å¯èƒ½å°±ä¸º0ä¸¤ç‚¹é‡åˆï¼Œè€Œé‡å­è®¡ç®—éœ€è¦è§£å†³çš„å°±æ˜¯ç±»ä¼¼å¦‚ä½•å°†è¿™å¼ çº¸å¯¹æŠ˜ã€‚ ä¸‹åˆä¸»è¦é‚€è¯·äº†ä»ä¼ ç»Ÿæ–‡åŒ–èµ°ä¸Šè‡ªå­¦ä¸­åŒ»çš„æŸ¯å¬æ°‘åŒ»ç”Ÿå’Œæœ‰è¿‘12å¹´å…¬ç›Šé¢†åŸŸä»ä¸šç»éªŒçš„æ­¦æ½‡è€å¸ˆç»“åˆè‡ªèº«ç»å†åšäº†åˆ†äº«ã€‚ æŸ¯è€å¸ˆåŠ›èã€Šä¼¤å¯’è®ºã€‹è¿™æœ¬ä¹¦ï¼Œè®¤ä¸ºå­¦ç²¾æ­¤ä¹¦ï¼Œæ°´å¹³å¯ä»¥è¶…è¿‡å¤–é¢ç™¾åˆ†ä¹‹å…«åçš„ä¸­åŒ»ï¼Œå·å¬åŒå­¦ä»¬â€œç«‹å‘½â€ä»è‡ªå­¦ä¸­åŒ»å¼€å§‹ï¼Œå¬å®Œä»–çš„è®²åº§ï¼Œæˆ‘è¿˜çœŸæƒ³åœ¨è¯¾ä½™æ—¶é—´å»å­¦å­¦ä¸­åŒ»ï¼Œè‡³å°‘æŒæ¡ä¸€äº›åŒ»å­¦å¸¸è¯†æ˜¯å¿…é¡»çš„ï¼Œè¯´ä¸å®šå“ªå¤©èƒ½æ´¾ä¸Šç”¨åœºã€‚ğŸ˜‡ æ­¦è€å¸ˆåˆ™æ˜¯ä»è‡ªèº«åšå…¬ç›Šçš„ç»å†å‡ºå‘ï¼Œå‘åŒå­¦ä»¬å±•ç°äº†å¦‚ä½•å®è·µã€æ´»å‡ºä¼ ç»Ÿæ–‡åŒ–çš„ä»·å€¼å’Œç²¾ç¥ã€‚ 7.9ä¸Šåˆæµ™æ±Ÿå½“ä»£ä¸­å›½ç”»ç ”ç©¶é™¢é™¢å£«å¾ç‰æ­¦è€å¸ˆä¸ºæˆ‘ä»¬ä½œäº†ã€Šå¤ä»£å®¡ç¾ä¸ç°ä»£å®¡ç¾ã€‹çš„è®²åº§ã€‚ å¾è€å¸ˆå†œæ‘å‡ºèº«ï¼Œä»å°å–œæ¬¢ç”»ç”»ï¼Œå¬ä»–è¯´å°æ—¶å€™ç©·ï¼Œä¹°ä¸èµ·ç¬”å¢¨ï¼Œä¾¿ç”¨æ ‘æåœ¨åœ°ä¸Šä½œç”»ã€‚ä»–40å¤šå²æ‰å»ä¸­å›½ç¾é™¢è¿›ä¿®ï¼Œå±äºå¤§å™¨æ™šæˆã€‚ä»å¾è€èº«ä¸Šï¼Œæˆ‘æ˜ç™½äº†å­¦ä¸œè¥¿è®²æ±‚â€œæ¬²é€Ÿåˆ™ä¸è¾¾â€ï¼Œæ…¢æ…¢æ¥ã€‚çƒ­çˆ±ä¹¦ç”»å¯¿å‘½æ™®éè¾ƒé•¿ï¼Œå› ä¸ºæœ‰åŠ©äºæ’é£å¿ƒä¸­çš„å‹åˆ¶çš„æƒ…ç»ªğŸ˜¯ã€‚ å¾è€ç»™æˆ‘ä¸€ç§æ±ªæ›¾ç¥ºçš„æ„Ÿè§‰ï¼Œåœ¨ä»–èº«ä¸Šï¼Œæˆ‘ä¼¼ä¹çœ‹è§äº†è‡ªå·±å‘å¾€çš„ä¸­è€å¹´ç”Ÿæ´»ï¼Œæ¸¸äºè‰ºï¼Œåšä¸€ä¸ªç”»å®¶ï¼Œå¾œå¾‰äºå±±æ°´è‡ªç„¶ä¹‹ä¸­ï¼Œå†™èŠ±å†™é¸Ÿï¼Œç”»èŠ±ç”»é¸Ÿï¼Œä½•ä¹è€Œä¸ä¸ºå‘¢ï¼Ÿ ä¸‹åˆéŸ³ä¹å®¶ä½•æ€¡è€å¸ˆï¼Œä¸ºæˆ‘ä»¬åšäº†ã€Šç°ä»£äººå¿ƒä¸­çš„é‚£ç‰‡ç«¹æ—ã€‹çš„è®²åº§ï¼Œä¸»è¦ä»‹ç»äº†ä¸­å›½ç´æ­Œçš„å‘å±•å†å²ï¼Œå¹¶ç°åœºè¿›è¡Œå¼¹å”±äº†è‹è½¼çš„ã€Šå®šé£æ³¢ã€‹ã€æç™½çš„ã€Šç§‹é£è¯ã€‹ç­‰ã€‚ åœ¨è€å¸ˆå¼¹å”±çš„è¿‡ç¨‹ï¼Œæˆ‘ä¸€ç›´æ˜¯é—­ä¸Šçœ¼å»äº«å—ç´æ­Œä¹‹ç¾ã€‚è®°å¾—è‡ªå·±ä»åˆä¸­å¼€å§‹å°±å¾ˆå–œæ¬¢æœ—è¯µå¤æ–‡ã€è¯—è¯ï¼Œä¸ä»…ä»…æ˜¯å› ä¸ºè¯ç« æŠ¼éŸµï¼Œè¿˜å› ä¸ºå¤æ–‡è¯—è¯æ‰€ä¼ è¾¾çš„æ–‡äººæ·±æ²‰çš„æƒ…æ„Ÿã€é‚£æ˜¯è¿™äº›ä½œå“å†…åœ¨çš„çµé­‚ã€‚è€Œè€å¸ˆç”¨ç´æ­Œå¼¹å”±çš„å½¢å¼ï¼Œå°†å¤ä»£è¯—è¯æ¼”ç»å‡ºæ¥ï¼ŒçœŸæ˜¯å¤ªç¾äº†ã€‚æ­£å¦‚è€å¸ˆåœ¨å¼€ç¯‡æ‰€è¯´ï¼Œâ€œç´æ­Œæ˜¯ä¸€ç‰‡å¿ƒåº•çš„ç«¹æ—ï¼Œå¯ä»¥è®©å¿ƒåœé ï¼Œç»™äººå®—æ•™æ”¾çš„è™”è¯šå†¥æƒ³ã€å“²å­¦ä¸Šçš„å†·é™æ²‰æ€ã€‚â€ åœ¨æ•´ä¸ªå‚åŠ è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä¹Ÿåœ¨æ€è€ƒæœªæ¥æˆ‘æƒ³åšçš„å·¥ä½œä»¥åŠä»¥è¿™ç§æ¨¡å¼å¼˜æ‰¬ä¼ ç»Ÿæ–‡åŒ–èƒ½å¤Ÿè¾¾åˆ°æ€æ ·çš„æ•ˆæœï¼Ÿ æ€»çš„æ¥è¯´ï¼Œç»è¿‡æ­¤æ¬¡æ´»åŠ¨ï¼Œè‡ªå·±çš„ç›®æ ‡æ›´åŠ æ¸…æ™°ï¼Œä»æ˜¯å°†ä¼ ç»Ÿæ–‡åŒ–å½“ä½œä¸ªäººä¿®èº«å…»æ€§çš„æ–¹å¼ï¼Œä¸»ä½“è¿˜æ˜¯åšè®¡ç®—æœºç§‘å­¦æ–¹é¢çš„ç ”ç©¶ã€‚ å› ä¸ºç›¸è¾ƒäºåƒè®²è¯¾è€å¸ˆé‚£æ ·å…¨èº«å¿ƒæŠ•å…¥ä¸­å›½å“²å­¦ç ”ç©¶ä¸å¼˜æ‰¬ï¼Œæˆ‘æ˜¯æ›´å–œæ¬¢åšè®¡ç®—æœºç ”ç©¶å·¥ä½œçš„ã€‚ä¸€æ–¹é¢ï¼Œåœ¨åšç ”ç©¶çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ€»æƒ³å»åŠ¨æ‰‹åšäº›ä»€ä¹ˆï¼Œä¾‹å¦‚å†™ä»£ç ã€‚å¦ä¸€æ–¹é¢ï¼Œå­¦ç§‘çš„æ·±åº¦å’Œæœ‰è¶£æ€§ä¹Ÿæ˜¯å¸å¼•æˆ‘åŠªåŠ›å»åšçš„ã€‚æ­¤å¤–ï¼Œæˆ‘å‘ç°å„ä½è€å¸ˆå…±åŒç‚¹åœ¨äºå‡å®ç°äº†ç»æµä¸Šçš„ç‹¬ç«‹ã€‚æ‰€ä»¥ï¼Œå¯èƒ½å½“æˆ‘æœ‰æ‰€æˆå°±ï¼Œæœ‰ä½™åŠ›æ—¶ä¼šå»å¼˜æ‰¬å§ï¼Œè¿™æ ·æˆ–è®¸ä¹Ÿèƒ½å¤Ÿä¼šå½±å“æ›´å¤šäººã€‚ ä½†æˆ‘å’Œè€å¸ˆä»¬ä¹Ÿæœ‰å…±é€šä¹‹å¤„ï¼Œå³æˆ‘ä»¬éƒ½è®¤ä¸ºå­¦é—®å’Œé“å¾·ä¿®å…»éƒ½éœ€è¦å…±åŒå‘å±•ã€æå‡ï¼Œä¸åŒä¹‹å¤„åœ¨äºè€å¸ˆä»¬çš„å­¦é—®ä¸»è¦æ˜¯ä¸­å›½å“²å­¦ï¼Œè€Œæˆ‘ä¸»è¦æ˜¯è®¡ç®—æœºç§‘å­¦ç½¢äº†ã€‚ è€Œå°†æˆ‘ä»¬è¿æ¥åœ¨ä¸€èµ·çš„åˆ™æ˜¯ä¸­å›½å“²å­¦ï¼Œæˆ‘ä»¬éƒ½å¸Œæœ›èƒ½å¤Ÿå¼˜æ‰¬ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–ï¼Œä»ä¸­å›½å“²å­¦ä¸­æ±²å–åŠ›é‡ï¼Œä½¿å¾—å›½äººèƒ½å¤Ÿè·å¾—ç²¾ç¥ä¸Šçš„ç‹¬ç«‹ã€‚ è€Œå¯¹äºè¿™ç§å¼˜æ‰¬ä¼ ç»Ÿæ–‡åŒ–ï¼Œä¼ æ’­å„’å®¶æ€æƒ³çš„å¤ä»¤è¥å¼çš„æ¨¡å¼ï¼Œæˆ‘è®¤ä¸ºæœ‰åˆ©ä¹Ÿæœ‰å¼Šï¼Œå¾ˆéš¾åšåˆ°å°½å–„å°½ç¾ï¼Œåœ¨æ´»åŠ¨çš„è¿‡ç¨‹ä¸­ï¼Œæœ‰äººæ„¤ç„¶ç¦»å»ï¼Œä¹Ÿæœ‰äººä¹æ­¤ä¸ç–²ã€‚ ä½†è‡³å°‘æœ‰ä¸€ç‚¹æˆ‘è§‰å¾—å¾ˆå¥½ï¼Œè¿™æ¬¡æ´»åŠ¨è®©äººæ„Ÿåˆ°åœ¨ä¼ ç»Ÿæ–‡åŒ–é¢å‰äººäººå¹³ç­‰ï¼Œæ²¡æœ‰å°Šå‘è´µè´±ã€‚ä¸ç®¡ä½ æ˜¯å¤æ—¦ã€æ­¦å¤§åæ ¡åšå£«ç”Ÿï¼Œè¿˜æ˜¯èŒä¸šå­¦é™¢çš„æœ¬ç§‘ç”Ÿï¼Œä¸ç®¡ä½ æ˜¯è€å¸ˆï¼Œè¿˜æ˜¯å­¦ç”Ÿï¼Œå¤§å®¶éƒ½èƒ½å¤Ÿåƒæœ‹å‹èˆ¬å¦è¯šåœ°è®¨è®ºé—®é¢˜ï¼Œäº’ç›¸å¸®åŠ©ï¼Œå…¶ä¹èèã€‚ ","title":"ç™¸å¯å¹´å¿—å¿ƒé’å¹´ç«‹å¿ƒè¥çºªå½•ä¸æ„Ÿæƒ³","uri":"/posts/zhixin-academy-2023summer/"},{"content":"å¤§å­¦æ¯•ä¸šäº†ï¼Œå››å¹´çš„æ—¶å…‰ä»…åœ¨å¼¹æŒ‡ä¹‹é—´ã€‚\næ¯•ä¸šè¿™å¤©çœŸæ­£æ¥ä¸´æ—¶ï¼Œè‡ªå·±å¹¶æ²¡æœ‰åƒç”µå½±æƒ…èŠ‚ä¸­å“­çš„ç¨€é‡Œå“—å•¦çš„ï¼Œé‚£æ ·æ„Ÿæƒ…çˆ†å‘ï¼Œåªæ˜¯å¾ˆå¹³å’Œåœ°é¢å¯¹è¿™ä¸€åˆ‡ï¼Œäººç”Ÿçš„å¸¸æ€å¤§æ¦‚å°±æ˜¯å¦‚æ­¤å§ï¼Œäººæ¥äººå¾€ã€‚\nå½“æˆ‘å‚åŠ æ¯•ä¸šå…¸ç¤¼ï¼Œååœ¨ä½å­ä¸Šå›é¡¾å¤§å­¦å››å¹´æ—¶ï¼Œå¥¹ä¸»è¦æ•™ä¼šã€åŸ¹å…»äº†æˆ‘ä¸¤æ ·ï¼Œä¸€æ˜¯æ±‚çŸ¥æ¬²å’Œç‹¬ç«‹çš„æ€è€ƒï¼ŒäºŒæ˜¯åšä¸€ä¸ªæ„Ÿæ©ã€å‘å–„çš„äººã€‚\nå¯ä½ ç©¶ç«Ÿæ˜¯å¹³é™å¦‚æ¹–æ°´å—ï¼Ÿå½“æ½®æ°´é€€å»ï¼Œä½ è¿›å…¥æ–°çš„ç¯å¢ƒï¼Œé‡åˆ°æ–°çš„äººäº‹ç‰©ï¼Œå’Œä»¥å‰çš„ä¸åŒäº†ï¼Œæˆ–è®¸æ‰ä¼šä½¿ä½ æ„Ÿåˆ°å¤§å­¦çš„å¯è´µä¸ç¾å¥½ï¼Œäººæ€»æ˜¯å¤±å»åæ‰æ‡‚å¾—çæƒœã€‚\näººæœ‰æ‚²æ¬¢ç¦»åˆï¼Œæœˆæœ‰é˜´æ™´åœ†ç¼ºã€‚ä¿æŒä¸€ç§ä¹è§‚ã€å¹³å’Œçš„å¿ƒæ€ï¼Œå¦ç„¶ä»¥å¯¹å°±å¥½ã€‚\nå¤§å­¦æ¯•ä¸šï¼Œå¤§å®¶å„æœ‰å„çš„è·¯è¦èµ°ï¼Œæ²¡æœ‰ä»€ä¹ˆå¥½ç‰µæŒ‚çš„ï¼Œå„è‡ªå¼€æ‹“ã€é—¯è¡å§ï¼\nã€Šå†è§ã€‹â€”â€”å¼ éœ‡å²³\næˆ‘æ€•æˆ‘æ²¡æœ‰æœºä¼š\nè·Ÿä½ è¯´ä¸€å£°å†è§\nå› ä¸ºä¹Ÿè®¸å°±å†ä¹Ÿè§ä¸åˆ°ä½ \næ˜å¤©æˆ‘è¦ç¦»å¼€\nç†Ÿæ‚‰çš„åœ°æ–¹å’Œä½ \nè¦åˆ†ç¦»\næˆ‘çœ¼æ³ªå°±æ‰ä¸‹å»\næˆ‘ä¼šç‰¢ç‰¢è®°ä½ä½ çš„è„¸\næˆ‘ä¼šçæƒœä½ ç»™çš„æ€å¿µ\nè¿™äº›æ—¥å­åœ¨æˆ‘å¿ƒä¸­æ°¸è¿œéƒ½ä¸ä¼šæŠ¹å»\næˆ‘ä¸èƒ½ç­”åº”ä½ \næˆ‘æ˜¯å¦ä¼šå†å›æ¥\nä¸å›å¤´\nä¸å›å¤´åœ°èµ°ä¸‹å»\n2023 å¹´ 6 æœˆ 17 æ—¥ æ˜ŸæœŸå…­ é›¨\nè’‹æ˜“è€• äºè®¡ç®—æœºå­¦é™¢10-631\n","title":"æ¯•ä¸šäº†","uri":"/posts/graduate-from-zstu/"},{"content":"ä»Šå¹´3æœˆä»½çš„æ—¶å€™ï¼Œå’Œæœ‹å‹çº¦å¥½å»çœ‹è«å¥ˆã€æ¢µé«˜ä¸ç°ä»£ä¸»ä¹‰å¤§å¸ˆçœŸè¿¹å±•ä¸‹æ–‡ä»¥è«æ¢µå±•ç®€ç§°ä½†ç”±äºå¿™æ¯•è®¾å’Œå…¶ä»–äº‹æƒ…ï¼Œæ‰€ä»¥ä¸€ç›´æ²¡æœ‰å»ã€‚\næ°å¥½å‰å‡ å¤©æ¯”è¾ƒæœ‰ç©ºï¼Œå¹¶ä¸”6æœˆ2æ—¥åšç‰©é¦†è¿˜æ¨å‡ºäº†çœ‹å±•äº«å…è´¹å¤å…¸ä¹æ¼”å¥çš„ä½“éªŒï¼Œäºæ˜¯å†³å®šå½“å¤©å»äº†ã€‚\næ—¢ç„¶å¥½ä¸å®¹æ˜“å‡ºæ¥ä¸€è¶Ÿï¼Œåªçœ‹ä¸€ä¸ªå±•æ€ä¹ˆèƒ½å¤Ÿå‘¢ï¼Ÿ^.^å› æ­¤ï¼Œæˆ‘å’Œæœ‹å‹å†³å®šå…ˆå»çœ‹éå­ªç”Ÿä¸»ä¹‰æ•°å­—è‰ºæœ¯è”å±•ä¸‹æ–‡ä»¥æ•°å­—è‰ºæœ¯å±•ç®€ç§°ï¼Œç„¶åå†å»çœ‹è«å¥ˆã€‚\næˆ‘å¯¹äººæ–‡è‰ºæœ¯çš„å…´è¶£ä¼¼ä¹æ˜¯å¤©ç”Ÿçš„ï¼Œè®°å¾—ä¸Šå°å­¦çš„æ—¶å€™å°±å–œæ¬¢åœ¨ä¹¦ä¸Šçš„æ’ç”»ä¸Šè¿›è¡Œæ¶‚ç”»ï¼Œå’Œç­ä¸Šçš„åŒå­¦æ¯”è¾ƒçœ‹è°ç”»çš„å°äººæ›´ç”ŸåŠ¨ã€‚åœ¨å¤–é¢è¡¥å®Œè¯¾ï¼Œå¸¸å¸¸å»æ–°åä¹¦åº—çœ‹ä¹¦ã€‚æ¯æ™šç¡è§‰å‰ï¼Œé€šå¸¸ä¼šå–ç€ç‰›å¥¶çœ‹ä¼šä¹¦å†ç¡ã€‚\nåæ¥ä¸Šäº†åˆä¸­ã€é«˜ä¸­ç»˜ç”»ä¼¼ä¹è«åä¸­æ–­äº†ï¼Œä½†è¯»è¯¾å¤–ä¹¦çš„ä¹ æƒ¯ä¸€ç›´ä¿æŒç€ã€‚\nè¿›å…¥å¤§å­¦ï¼Œæœ‰äº†æ›´å¤šå±äºè‡ªå·±çš„æ—¶é—´ï¼Œå½“æˆ‘é—²ä¸‹æ¥ï¼Œåˆå¼€å§‹è¯»èµ·è¯¾å¤–ä¹¦æ¥ã€‚ä¸²å¯æ—¶ï¼Œçœ‹è§zgfçš„ä¹¦æ¶ä¸Šæœ‰æœ¬ç‹å°æ³¢çš„ã€Šé»„é‡‘æ—¶ä»£ã€‹ï¼Œä¾¿å€Ÿæ¥ä¸€é˜…ã€‚\nåœ¨è¯»ç‹å°æ³¢ã€Šé»„é‡‘æ—¶ä»£ã€‹çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘å½»åº•è¢«ç‹å°æ³¢ä»¥åŠä»–çš„æ–‡å­—æ‰€å¾æœã€‚è¯»å®Œè¿™æœ¬ä¹¦ï¼Œæˆ‘ä¾¿è¿«ä¸åŠå¾…åœ°è¯»ä»–çš„å…¶ä»–ä¹¦ï¼Œç‰¹åˆ«æ˜¯é‚£äº›èƒ½å¤Ÿå±•éœ²ä»–çš„æ‰åå’Œæ€æƒ³çš„è‘—ä½œï¼Œä¾‹å¦‚ã€Šæ²‰é»˜çš„å¤§å¤šæ•°ã€‹ã€ã€Šæˆ‘çš„ç²¾ç¥å®¶å›­ã€‹ã€‚\nç‹å°æ³¢ä½¿æˆ‘æ˜ç™½åº”è¯¥å°†ç§‘å­¦å’Œè‰ºæœ¯æ”¾åœ¨ä¸€èµ·æ¥çœ‹å¾…ï¼Œä»–å°†ç§‘å­¦å’Œè‰ºæœ¯çœ‹ä½œæ˜¯èƒ½ä¸ºäººå¸¦æ¥æ€æƒ³å¿«ä¹çš„ä¸œè¥¿ï¼ŒäºŒè€…éƒ½æ˜¯äººç±»æ™ºæ…§è‡³é«˜çš„äº§ç‰©ã€‚\næˆ‘è®¤ä¸ºè‡ªå·±ä½“éªŒåˆ°æœ€å¤§å¿«ä¹çš„æ—¶æœŸæ˜¯åˆè¿›å¤§å­¦æ—¶ï¼Œå› ä¸ºç§‘å­¦å¯¹æˆ‘æ¥è¯´æ˜¯æ–°å¥‡çš„ï¼Œè€Œä¸”å®ƒæ€»æ˜¯é€»è¾‘å®Œå¤‡ï¼Œæ— æ‡ˆå¯å‡»ï¼Œè¿™æ˜¯è¿™ä¸ªå¹³å‡¡çš„å°˜ä¸–ä¸Šç½•è§çš„ä¸œè¥¿ã€‚ä¸æ­¤åŒæ—¶ï¼Œä¹Ÿå¾—ä»¥äº†è§£å…ˆè¾ˆç§‘å­¦å®¶çš„æ°å‡ºæ™ºåŠ›ã€‚è¿™å°±å¦‚å’Œä¸€ä½é«˜æ˜çš„æ£‹æ‰‹ä¸‹æ£‹ï¼Œè™½ç„¶è‡ªå·±æ€»è¢«å‡»è´¥ï¼Œä½†ä¹Ÿæœ‰æœºä¼šé¢†ç•¥å¦™æ‹›ã€‚åœ¨æˆ‘çš„åŒå­¦é‡Œï¼Œå‡¡å’Œæˆ‘åŒç­‰å¹´é¾„ã€æœ‰åŒç­‰ç»å†çš„äººï¼Œä¹Ÿå’Œæˆ‘æœ‰åŒæ ·çš„ä½“éªŒã€‚æŸäº›å•è°ƒæœºæ¢°çš„è¡Œä¸ºï¼Œæ¯”å¦‚åƒã€æ’æ³„ã€æ€§äº¤ï¼Œä¹Ÿèƒ½å¸¦æ¥å¿«æ„Ÿï¼Œä½†å› ä¸ºè¿‡äºç®€å•ï¼Œä¸èƒ½å’Œè¿™æ ·çš„å¿«ä¹ç›¸æ¯”ã€‚è‰ºæœ¯ä¹Ÿèƒ½å¸¦æ¥è¿™æ ·çš„å¿«ä¹ï¼Œä½†æ˜¯å¿…é¡»äº§ç”ŸäºçœŸæ­£çš„å¤§å¸ˆï¼Œè±¡ç‰›é¡¿ã€è±å¸ƒå°¼å…¹ã€çˆ±å› æ–¯å¦é‚£æ ·çº§åˆ«çš„äººç‰©ï¼Œæ—¶ä¸‹ä¸­å›½çš„è‰ºæœ¯å®¶ï¼Œå°šæ²¡æœ‰ä¸€ä½è¾¾åˆ°è¿™æ ·çº§åˆ«ã€‚æ•æˆ‘ç›´è¨€ï¼Œèƒ½å¤Ÿå¸¦æ¥æ€æƒ³å¿«ä¹çš„ä¸œè¥¿ï¼Œåªèƒ½æ˜¯äººç±»æ™ºæ…§è‡³é«˜çš„äº§ç‰©ã€‚æ¯”è¿™å†ä½ä¸€æ¡£çš„ä¸œè¥¿ï¼Œåªä¼šç»™äººå¸¦æ¥ç—›è‹¦ï¼›è€Œè¿™ç§ä½æ¡£è´§ï¼Œå°±æ˜¯å‡ºäºåŠŸåˆ©çš„ç§ç§æƒ³æ³•ã€‚â€”â€”èŠ‚é€‰è‡ªç‹å°æ³¢ã€Šæ€ç»´çš„ä¹è¶£ã€‹\næˆ–è®¸æ˜¯å› ä¸ºç‹å°æ³¢å¯¹ç§‘å­¦å’Œè‰ºæœ¯çš„æ¨å´‡ï¼Œå”¤é†’äº†æˆ‘å¿ƒä¸­é‚£é—å¤±å·²ä¹…çš„å¯¹ç¾æœ¯çš„å…´è¶£ï¼Œæˆ‘å¼€å§‹å€Ÿä¸€äº›ç”»æœ¬æ¥çœ‹ã€‚ å¤§äºŒä¸‹çš„æš‘æœŸï¼Œæˆ‘æŠ¥åå‚åŠ äº†ä¸ºæœŸ7å¤©çš„æ¾³é—¨é«˜æ ¡è®¿å­¦ã€‚åœ¨æ¾³å¤§çš„äº¤æµè¡Œç¨‹ä¸­ï¼Œæ¾³é—¨å¤§å­¦ç¾æœ¯è‰ºæœ¯è®¾è®¡ä¸­å¿ƒä¸»ä»»æ¢è“æ³¢æ•™æˆä¸ºæˆ‘ä»¬å¸¦æ¥äº†ä¸€åœºåä¸ºã€Šè·¨ç•Œèåˆåœ¨è‰ºæœ¯è®¾è®¡ä¸­çš„ä¼˜åŠ¿ã€‹çš„è®²åº§ã€‚\nè¿™åœºè®²åº§å¸¦ä½¿æˆ‘è®¤è¯†åˆ°ï¼Œè‰ºæœ¯ä¸åªæ˜¯å•æ–¹é¢ã€å±€é™äºä¸“ä¸šç”»å®¶çš„ï¼Œé€šè¿‡å°†ä¸­è¥¿æ–¹å“²å­¦ã€æ•°å­—åª’ä½“ä¸è‰ºæœ¯è®¾è®¡äº¤èï¼Œæ‰“ç ´ä¼ ç»Ÿè‰ºæœ¯è®¾è®¡çš„æƒ¯æ€§ï¼Œä»è€Œå¸¦æ¥åˆ›æ–°ã€‚è€Œè¿™æ¬¡è®²åº§ä¹Ÿè®©æˆ‘æ„Ÿåˆ°è‰ºæœ¯çœŸæ˜¯ç¾å¤§ç”šæ·±ï¼Œæ— è®ºæ˜¯è¡¨ç°å‡ºæ¥çš„ç”»é¢æˆ–è€…æ˜¯èƒŒåçš„åˆ›ä½œç†å¿µéƒ½æ˜¯å€¼å¾—æ·±æ€ç©å‘³çš„ã€‚\nç”Ÿæ´»å½“ä¸­ä¹Ÿæ— å¤„ä¸æ˜¯è‰ºæœ¯è®¾è®¡ï¼Œå»ºç­‘é£æ ¼ã€æ±½è½¦å‹ä½“ã€é“è·¯æ ·å¼ã€äººçš„æœé¥°ç­‰ç­‰ï¼Œåªè¦æ˜¯æ¶‰åŠåˆ°éœ€è¦åˆ›é€ çš„ä¸œè¥¿ï¼Œéƒ½éœ€è¦è¿›è¡Œè‰ºæœ¯è®¾è®¡ï¼Œå› æ­¤å…·æœ‰ä¸€ç§å¯¹ç¾çš„å“å‘³ä¹Ÿæ˜¾å¾—å¾ˆé‡è¦å•¦ã€‚\nå””ï¼Œå›é¡¾äº†ä¸€ä¸‹æˆ‘å…³äºè‰ºæœ¯çš„å†ç¨‹ã€‚æ¥ä¸‹æ¥è°ˆä¸€ä¸‹çœ‹æ•°å­—è‰ºæœ¯å±•å’Œè«æ¢µå±•çš„ä½“ä¼šå§ã€‚\nå¯¹äºæ•°å­—è‰ºæœ¯å±•å’Œè«æ¢µå±•ï¼Œæˆ‘è®¤ä¸ºå¯ä»¥å°†å…¶çœ‹ä½œæ–°å…´è‰ºæœ¯å’Œä¼ ç»Ÿè‰ºæœ¯çš„ä¸¤ä¸ªä»£è¡¨ã€‚è€ŒäºŒè€…çš„åŒºåˆ«åœ¨äºå‰è€…åŠ å…¥äº†æ•°å­—ç§‘æŠ€çš„å› ç´ ï¼Œä¾‹å¦‚å…ƒå®‡å®™ã€åŒºå—é“¾ã€AIç­‰ç­‰ã€‚\né‚£ä¹ˆï¼ŒAIç»˜ç”»ç›¸å¯¹äºä¼ ç»Ÿç»˜ç”»çš„åŒºåˆ«æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿåœ¨æˆ‘çœ‹æ¥ï¼ŒAIç»˜ç”»ç›¸å¯¹äºä¼ ç»Ÿç»˜ç”»ï¼Œå®ƒæ— æ³•æ•æ‰äººåœ¨åˆ›é€ ç”»çš„è¿‡ç¨‹ä¸­ï¼Œå¯¹ç»†å¾®å¤„çš„å¤„ç†ï¼Œä¾‹å¦‚ï¼Œç”»å®¶å¯¹ä¸€å¹…ç”»çš„æŸå‡ å¤„ç‚¹ç¼€å¾€å¾€æ˜¯æ•´å¹…ç”»çš„ç‚¹ç›ä¹‹ç¬”ã€‚ä½†é€šè¿‡promptè®©AIç”»å‡ºæ¥çš„ç”»ï¼Œæ˜¾å¾—é‚£ä¹ˆå®Œç¾æ— ç¼ºã€‚æ­¤å¤–ï¼Œä¸¤è€…çš„ç”Ÿå‘½å‘¨æœŸä¸åŒï¼ŒAIç»˜ç”»ä¹ƒè‡³æ•´ä¸ªæ•°å­—ç»˜ç”»ä¸€æ—¦å®Œæˆï¼Œå®ƒçš„ç”Ÿå‘½å°±ç»ˆæ­¢äº†ï¼Œä½†ä¼ ç»Ÿç»˜ç”»è‹¥ä¿å­˜å¾—å½“ï¼Œå…¶ç”Ÿå‘½å‘¨æœŸå¯ä»¥ä¸€ç›´å»¶ç»­ï¼Œå› ä¸ºä¼šæœ‰è‡ªç„¶ç¯å¢ƒä¸­çš„å„ç§å› ç´ å¯¹ç”»çš„äºŒæ¬¡åˆ›ä½œï¼Œä¾‹å¦‚å¤©æ°”çš„æ¹¿åº¦ã€æ¸©åº¦éƒ½åœ¨å¯¹ç”»ä½œè¿›è¡Œâ€œå†åˆ›ä½œâ€ã€‚\nä½†AIä½¿ç»˜ç”»å˜å¾—å®¹æ˜“ï¼Œå¯¹æœ‰æ€æƒ³æœ‰å®¡ç¾å´ç¼ºä¹åˆ›ä½œæŠ€èƒ½çš„äººæ‰“å¼€äº†åˆ›é€ å¤§é—¨ï¼Œä¹Ÿç»™ç”»å®¶å¸¦æ¥äº†çµæ„Ÿå’Œå¯å‘ï¼Œä¸ºä¼ ç»Ÿè‰ºæœ¯æ³¨å…¥äº†æ–°é²œçš„è¡€æ¶²ã€‚æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œå½“æ•°å­—ç§‘æŠ€å¼•å…¥ä¼ ç»Ÿè‰ºæœ¯ï¼ŒäºŒè€…å¼€å§‹äº¤èã€ç¢°æ’ï¼Œä¾¿ç»™è‰ºæœ¯è®¾è®¡å¸¦æ¥äº†æ–°çš„å¯èƒ½æ€§ã€‚\næœªæ¥æ˜¯å¦ä¼šäº§ç”Ÿç”±AIå¼€åˆ›çš„è‡ªæˆä¸€æ´¾çš„ç»˜ç”»é£æ ¼å‘¢ï¼Ÿæˆ‘æƒ³è‚¯å®šä¼šçš„ã€‚\n","title":"è§‚æ•°å­—è‰ºæœ¯ä¸è«æ¢µå±•çš„ä½“ä¼š","uri":"/posts/digital-traditional-arts/"},{"content":"ç»„å†…éœ€è¦æˆ‘æ¥æ‰‹åšä¸€ä¸ªå¼ºåŒ–å­¦ä¹ çš„é¡¹ç›®ï¼Œç”±äºæ˜¯ç¬¬ä¸€æ¬¡æ¥è§¦å¼ºåŒ–å­¦ä¹ ï¼Œå¾ˆå¤šä¸œè¥¿éƒ½ä¸æ‡‚ï¼Œäºæ˜¯æ‰¾äº†ä¸€äº›ç›¸å…³èµ„æ–™æ¥çœ‹ã€‚ åœ¨é˜…è¯»ç‹æ ‘æ£®çš„ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‹ä¸€ä¹¦ä¸­ï¼Œä½œè€…å°†è’™ç‰¹å¡æ´›æ–¹æ³•ä½œä¸ºå­¦ä¹ å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†è¿›è¡Œäº†ä»‹ç»ï¼Œå¹¶ä¸¾ä¾‹è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨è’™ç‰¹å¡æ´›è¿‘ä¼¼ $\\pi$ ã€‚ä½†æˆ‘å¯¹äºä¹¦ä¸­çš„è§£é‡Šä¸æ˜¯å¾ˆç†è§£ï¼Œåœ¨ç½‘ä¸Šä¹Ÿå¹¶æœªæ‰¾åˆ°åˆé€‚çš„è’™ç‰¹å¡æ´›è¿‘ä¼¼ $\\pi$ çš„æ•°å­¦è§£é‡Šï¼Œåœ¨ä¸æœ‹å‹çš„è®¨è®ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘è§‰å¾—è‡ªå·±ä¼¼ä¹æ‰¾åˆ°äº†ä¸€ç§è¾ƒä¸ºåˆç†çš„æ•°å­¦è§£é‡Šæ–¹æ³•ã€‚ å…ˆæ¥ç®€å•ä»‹ç»ä¸€ä¸‹è’™ç‰¹å¡æ´›æ–¹æ³•ã€‚è’™ç‰¹å¡æ´›æ–¹æ³•ï¼ˆMonte Carlo methodsï¼‰æ˜¯ä¸€ç±»éšæœºç®—æ³•çš„æ€»ç§°ï¼Œå®ƒä»¬ä¾é é‡å¤éšæœºé‡‡æ ·æ¥ä¼°ç®—çœŸå®å€¼ã€‚å…¶æå‡ºè€…ä¸ºå†¯Â·è¯ºä¼Šæ›¼ã€æ–¯å¡”å°¼æ–¯æ‹‰å¤«Â·ä¹Œæ‹‰å§†å’Œå°¼å¤æ‹‰æ–¯Â·æ¢…ç‰¹ç½—æ³¢åˆ©æ–¯ï¼Œç”±äºä¹Œæ‹‰å§†çš„å”å”ç»å¸¸åœ¨æ‘©çº³å“¥çš„è’™ç‰¹å¡æ´›èµŒåœºè¾“é’±å¾—åã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•ä¼°ç®—åœ†å‘¨ç‡ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªéšæœºæ•°ç”Ÿæˆå™¨ï¼Œå¯ä»¥å‡åŒ€åœ°ç”Ÿæˆ $[-1,1]$ åŒºé—´çš„æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´$[-1,1]$åŒºé—´å†…çš„ä»»ä½•æ•°è¢«æŠ½ä¸­çš„æ¦‚ç‡æ˜¯ç›¸ç­‰çš„ã€‚ æˆ‘ä»¬åˆ©ç”¨è¿™ä¸ªéšæœºæ•°ç”Ÿæˆå™¨ç”Ÿæˆä¸¤ä¸ªæ•°åˆ†åˆ«è®°ä¸º $x$ å’Œ $y$ ï¼Œå¹¶å°†å…¶ä½œä¸ºå¹³é¢åæ ‡ç³»ä¸­çš„ä¸€ä¸ªç‚¹$(x, y)$ ç”¨ä¸‰è§’å½¢è¡¨ç¤ºã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œç”±äº$x$ å’Œ $y$ åœ¨$[-1,1]$ä¸Šå‡åŒ€åˆ†å¸ƒï¼Œå› æ­¤æ­£æ–¹å½¢å†…çš„ç‚¹è¢«æŠ½ä¸­çš„æ¦‚ç‡æ˜¯ç›¸ç­‰çš„ã€‚ è®¾äº‹ä»¶ $A$ è¡¨ç¤ºç‚¹ä½äºåœ†å†…ã€‚ç”±äºæŠ½æ ·æ˜¯å‡åŒ€çš„ï¼Œå¯¹äºæ¯æ¬¡éšæœºç”Ÿæˆä¸€ä¸ªç‚¹è€Œè¨€ï¼Œäº‹ä»¶Aå‘ç”Ÿçš„æ¦‚ç‡ä¸ºåœ†çš„é¢ç§¯ä¸æ­£æ–¹å½¢çš„é¢ç§¯ä¹‹æ¯”ï¼Œä¹Ÿå°±æ˜¯ $$ P(A) = \\frac{\\pi}{4} $$ æˆ‘ä»¬é‡å¤è¯•éªŒ $n$ æ¬¡ï¼Œç”Ÿæˆ $n$ ä¸ªç‚¹ã€‚åœ¨æ¯æ¬¡è¯•éªŒä¸­ï¼Œäº‹ä»¶ $A$ æˆ–è€…å‘ç”Ÿï¼Œæˆ–è€…ä¸å‘ç”Ÿã€‚æ˜¾ç„¶ï¼Œè¿™ $n$ æ¬¡è¯•éªŒç»“æœäº’ä¸å½±å“ï¼Œç›¸äº’ç‹¬ç«‹ã€‚ è®¾éšæœºå˜é‡ $X$ è¡¨ç¤ºè¿™ $n$ æ¬¡ç‹¬ç«‹é‡å¤è¯•éªŒä¸­äº‹ä»¶ $A$ å‘ç”Ÿçš„æ¬¡æ•°ï¼Œä¹Ÿå°±æ˜¯åœ¨è¿™ $n$ ä¸ªç‚¹ä¸­ä½äºåœ†å†…çš„ç‚¹çš„æ•°é‡ã€‚æ¯æ¬¡è¯•éªŒä¸­äº‹ä»¶ $A$ å‘ç”Ÿçš„æ¦‚ç‡ä¸º $p$ ï¼Œåˆ™ $X$ æœä»ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œå³ $X ï½ B(n,p)$. æ¯æ¬¡è¯•éªŒåªæœ‰ä¸¤ç§å¯èƒ½ç»“æœï¼Œå³äº‹ä»¶Aå‘ç”Ÿæˆ–è€…ä¸å‘ç”Ÿï¼Œä»¤ $$ X_i=\\left\\{\\begin{array}{l} 1, åœ¨ç¬¬iæ¬¡è¯•éªŒä¸­äº‹ä»¶Aå‘ç”Ÿ \\\\ 0, åœ¨ç¬¬iæ¬¡è¯•éªŒä¸­äº‹ä»¶Aä¸å‘ç”Ÿ \\end{array}\\right.(i = 1,2, ...n) $$ åˆ™æ¯ä¸€ä¸ª $X_i(i = 1,2,â€¦,n)$æœä»$0-1$åˆ†å¸ƒï¼Œä¸”æœ‰ç›¸åŒçš„åˆ†å¸ƒå¾‹ $$ \\begin{array}{l|ll} X_i \u0026 0 \u0026 1 \\\\ \\hline p_i \u0026 1-\\frac{\\pi}{4} \u0026 \\frac{\\pi}{4} \\end{array} $$ å…¶ä¸­$i = 1, â€¦ , n$ ï¼Œ$n$ æ¬¡ä¼¯åŠªåˆ©è¯•éªŒä¸­åœ†å†…ç‚¹çš„æ•°é‡ $$ X = X_1 + X_2 + â€¦ + X_n $$ å³ä¼¯åŠªåˆ©åˆ†å¸ƒéšæœºå˜é‡å¯ä»¥åˆ†è§£æˆ $n$ ä¸ª å–å€¼äº’ä¸å½±å“çš„$0-1$åˆ†å¸ƒéšæœºå˜é‡ä¹‹å’Œã€‚ ç”±ä¼¯åŠªåˆ©å¤§æ•°å®šç†å¯å¾— $$\\lim_{n \\rightarrow \\infty} P\\left\\{\\left|\\frac{X}{n}-p\\right|\u003c\\varepsilon\\right\\}=1$$ ä¸Šå¼è¡¨æ˜ï¼Œäº‹ä»¶Aå‘ç”Ÿçš„é¢‘ç‡æ”¶æ•›äºäº‹ä»¶Aå‘ç”Ÿçš„æ¦‚ç‡ã€‚æ¢è¨€ä¹‹ï¼Œå‡å¦‚æˆ‘ä»¬è¿›è¡Œäº† $n$ æ¬¡è¯•éªŒï¼Œç”Ÿæˆäº† $n$ ä¸ªç‚¹ï¼Œå…¶ä¸­ä½äºåœ†å†…çš„æœ‰ $m$ ä¸ªç‚¹ã€‚å¦‚æœ $n$ è¶³å¤Ÿå¤§ï¼Œ$m$ ä¸ $n$ çš„æ¯”å€¼å°±ä¼šéå¸¸æ¥è¿‘ç‚¹ä½äºåœ†å†…çš„æ¦‚ç‡: $$ \\frac{m}{n} \\approx \\frac{\\pi}{4} $$ ç”±æ­¤å¾—åˆ° $$ \\pi \\approx \\frac{4m}{n} $$ ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•è¿‘ä¼¼ $\\pi$ çš„æ•°å­¦è§£é‡Šåˆ°æ­¤ç»“æŸï¼Œç¼–ç¨‹å€’æ˜¯å¾ˆå®¹æ˜“å•¦ï¼Œä»£ç å¦‚ä¸‹ def approxiate_pi(n): m = 0 for i in range(n): x = np.random.uniform(-1, 1) y = np.random.uniform(-1, 1) if x**2 + y**2 \u003c= 1: m += 1 pi = 4.0 * m / n return pi åœ¨è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†np.random.uniformæ–¹æ³•ä»ç»™å®šçš„åŒºé—´ä¸­å‡åŒ€æŠ½æ ·ï¼Œåˆ©ç”¨åœ†çš„è§£ææ–¹ç¨‹ $x^2 + y^2 = 1$ æ¥åˆ¤æ–­ç‚¹æ˜¯å¦ä½äºåœ†å†…ã€‚ References è‹å¾·çŸ¿ å¼ ç»§æ˜Œ. æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡[M]. 1. é«˜ç­‰æ•™è‚²å‡ºç‰ˆç¤¾, 2006-6-1. ç‹æ ‘æ£® é»å½§å› å¼ å¿—å. æ·±åº¦å¼ºåŒ–å­¦ä¹ [M]. 1. äººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾, 2022-11. ","title":"è’™ç‰¹å¡æ´›è¿‘ä¼¼åœ†å‘¨ç‡çš„æ•°å­¦åŸç†","uri":"/posts/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E8%BF%91%E4%BC%BC%E5%9C%86%E5%91%A8%E7%8E%87/"},{"content":"å‰è¨€ æœ€è¿‘åœ¨çœ‹ä¸€äº›æ·±åº¦å­¦ä¹ ç›¸å…³çš„ä¹¦ï¼Œæ„Ÿè§‰å¯¹äºå‚è€ƒæ–‡çŒ®1ä¸­çš„mini-batchéƒ¨åˆ†ç†è§£å¾—ä¸æ˜¯å¾ˆé€å½»ï¼Œä¸»è¦æ˜¯å› ä¸ºç¥ç»ç½‘ç»œçš„è¾“å…¥å¼€å§‹å˜æˆæ‰¹æ•°æ®ï¼ŒåŠ ä¹‹å¯¹pythonçš„numpyä¸æ˜¯å¾ˆç†Ÿäº†ã€‚æ‰€ä»¥æ€»æƒ³å†™ç‚¹ä»€ä¹ˆï¼Œä¸€æ¥æœ‰åŠ©äºåŠ æ·±å¯¹äºçŸ¥è¯†çš„ç†è§£ï¼ŒäºŒæ¥ä¹Ÿç®—æ˜¯åˆ†äº«çŸ¥è¯†^.^å’¯ã€‚ é—²è¯å°‘å™ï¼Œè®©æˆ‘ä»¬è¿›å…¥æ­£é¢˜ã€‚\næ­£æ–‡ åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå­¦ä¹ çš„ç›®æ ‡æ˜¯é€‰æ‹©æœŸæœ›é£é™©$R_{exp}$(expected loss)æœ€å°çš„æ¨¡å‹ï¼Œä½†åœ¨å®é™…æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸çŸ¥é“æ•°æ®çš„çœŸå®åˆ†å¸ƒï¼ˆåŒ…å«å·²çŸ¥æ ·æœ¬å’Œè®­ç»ƒæ ·æœ¬ï¼‰ï¼Œä»…çŸ¥é“è®­ç»ƒé›†ä¸Šçš„æ•°æ®åˆ†å¸ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ç›®æ ‡è½¬åŒ–ä¸ºæœ€å°åŒ–è®­ç»ƒé›†ä¸Šçš„å¹³å‡æŸå¤±ï¼Œè¿™ä¹Ÿè¢«ç§°ä¸ºç»éªŒé£é™©$R_{emp}$(empirical loss)ã€‚\nä¸¥æ ¼åœ°è¯´ï¼Œæˆ‘ä»¬åº”è¯¥è®¡ç®—æ‰€æœ‰è®­ç»ƒæ•°æ®çš„æŸå¤±å‡½æ•°çš„æ€»å’Œï¼Œä»¥æ­¤æ¥æ›´æ–°æ¨¡å‹å‚æ•°(Batch Gradient Descent)ã€‚ä½†éšç€æ•°æ®é›†çš„ä¸æ–­å¢å¤§ï¼Œä»¥ImagNetæ•°æ®é›†ä¸ºä¾‹ï¼Œè¯¥æ•°æ®é›†çš„æ•°æ®é‡æœ‰ç™¾ä¸‡ä¹‹å¤šï¼Œè®¡ç®—æ‰€æœ‰æ•°æ®çš„æŸå¤±å‡½æ•°ä¹‹å’Œæ˜¾ç„¶æ˜¯ä¸ç°å®çš„ã€‚è‹¥é‡‡ç”¨è®¡ç®—å•ä¸ªæ ·æœ¬çš„æŸå¤±å‡½æ•°æ›´æ–°å‚æ•°çš„æ–¹æ³•(Stochastic Gradient Descent)ï¼Œä¼šå¯¼è‡´$R_{emp}$éš¾ä»¥è¾¾åˆ°æœ€å°å€¼ï¼Œè€Œä¸”åœ¨æ•°å€¼å¤„ç†ä¸Šä¸èƒ½ä½¿ç”¨å‘é‡åŒ–çš„æ–¹æ³•æé«˜è¿ç®—é€Ÿåº¦ã€‚\näºæ˜¯ï¼Œæˆ‘ä»¬é‡‡å–ä¸€ç§æŠ˜è¡·çš„æƒ³æ³•ï¼Œå³å–ä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½œä¸ºå…¨éƒ¨æ•°æ®çš„ä»£è¡¨ï¼Œè®©ç¥ç»ç½‘ç»œä»è¿™æ¯ä¸€æ‰¹æ•°æ®ä¸­å­¦ä¹ ï¼Œè¿™é‡Œçš„â€œä¸€éƒ¨åˆ†æ•°æ®â€ç§°ä¸ºmini-batchï¼Œè¿™ç§æ–¹æ³•ç§°ä¸ºmini-batchå­¦ä¹ ã€‚\nä»¥ä¸‹å›¾ä¸ºä¾‹ï¼Œè“è‰²çš„çº¿è¡¨ç¤ºBatch Gradient Descentï¼Œç´«è‰²çš„çº¿è¡¨ç¤ºStochastic Gradient Descentï¼Œç»¿è‰²çš„çº¿è¡¨ç¤ºMini-Batch Gradient Descentã€‚ ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼ŒMini-Batchç›¸å½“äºç»“åˆäº†Batch Gradient Descentå’ŒStochastic Gradient Descentå„è‡ªçš„ä¼˜ç‚¹ï¼Œæ—¢èƒ½åˆ©ç”¨å‘é‡åŒ–æ–¹æ³•æé«˜è¿ç®—é€Ÿåº¦ï¼Œåˆèƒ½åŸºæœ¬æ¥è¿‘å…¨å±€æœ€å°å€¼ã€‚\nå¯¹äºmini-batchå­¦ä¹ çš„ä»‹ç»åˆ°æ­¤ä¸ºæ­¢ã€‚ä¸‹é¢æˆ‘ä»¬å°†MINISTæ•°æ®é›†ä¸Šçš„åˆ†ç±»é—®é¢˜ä½œä¸ºèƒŒæ™¯ï¼Œä»¥äº¤å‰ç†µcross-entropyæŸå¤±å‡½æ•°ä¸ºä¾‹ï¼Œæ¥å®ç°ä¸€ä¸‹mini-bacthç‰ˆçš„cross-entropy errorã€‚\nç»™å‡ºcross-entropy errorçš„å®šä¹‰å¦‚ä¸‹: $$ E = - \\sum_{k}t_k \\log(y_k)\\tag{1} $$\nå…¶ä¸­$y_k$è¡¨ç¤ºç¥ç»ç½‘ç»œè¾“å‡ºï¼Œ$t_k$è¡¨ç¤ºæ­£ç¡®è§£æ ‡ç­¾ã€‚\nç­‰å¼1è¡¨ç¤ºçš„æ˜¯é’ˆå¯¹å•ä¸ªæ•°æ®çš„æŸå¤±å‡½æ•°ï¼Œç°åœ¨æˆ‘ä»¬ç»™å‡ºåœ¨mini-batchä¸‹çš„æŸå¤±å‡½æ•°ï¼Œå¦‚ä¸‹ $$ E = -\\frac{1}{N}\\sum_{n}\\sum_{k}t_{nk}\\log(y_{nk})\\tag{2} $$\nå…¶ä¸­Nè¡¨ç¤ºè¿™ä¸€éƒ¨åˆ†æ•°æ®çš„æ•°é‡ï¼Œ$t_{nk}$è¡¨ç¤ºç¬¬nä¸ªæ•°æ®åœ¨ç¬¬kä¸ªå…ƒç´ çš„å€¼ï¼ˆ$y_{nk}$è¡¨ç¤ºç¥ç»ç½‘ç»œè¾“å‡ºï¼Œ$t_{nk}$è¡¨ç¤ºç›‘ç£æ•°æ®ï¼‰\næˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ç”¨Pythonå¦‚ä½•å®ç°mini-batchç‰ˆçš„cross-entropy errorã€‚é’ˆå¯¹ç›‘ç£æ•°æ®$t_{nk}$çš„æ ‡ç­¾å½¢å¼æ˜¯å¦ä¸ºone-hotï¼Œè¿›è¡Œåˆ†ç±»è®¨è®ºå¤„ç†ã€‚\næ­¤å¤–ï¼Œéœ€è¦æ˜ç¡®çš„ä¸€ç‚¹æ˜¯ï¼Œå¯¹äºä¸€ä¸ªåˆ†ç±»ç¥ç»ç½‘ç»œï¼Œæœ€åä¸€å±‚ç»è¿‡softmaxå‡½æ•°å¤„ç†åï¼Œè¾“å‡º$y_{nk}$æ˜¯ä¸€ä¸ª$n$x$k$çš„çŸ©é˜µï¼Œ$y_{ij}$è¡¨ç¤ºç¬¬iä¸ªæ•°æ®è¢«é¢„æµ‹ä¸º$j(0 \\leq j\\leq10)$çš„æ¦‚ç‡ï¼Œç‰¹åˆ«åœ°ï¼Œå½“$N=1$æ—¶ï¼Œ$y$æ˜¯ä¸€ä¸ªåŒ…å«10ä¸ªå…ƒç´ çš„å‘é‡ï¼Œç±»ä¼¼äº[0.1,0.2â€¦0.3]ï¼Œå…¶ä¸­0.1è¡¨ç¤ºè¾“å…¥æ•°æ®é¢„æµ‹ä¸º0çš„æ¦‚ç‡ä¸º0.1ï¼Œ0.2è¡¨ç¤ºå°†è¾“å…¥æ•°æ®é¢„æµ‹ä¸º1çš„æ¦‚ç‡ä¸º0.2ï¼Œå…¶ä»–æƒ…å†µä»¥æ­¤ç±»æ¨ã€‚\né¦–å…ˆï¼Œå¯¹äº$t_{nk}$ä¸ºone-hotè¡¨ç¤ºçš„æƒ…å†µï¼Œä»£ç å—1å¦‚ä¸‹\ndef cross_entropy_error(y,t): batch_size = y.shape[0] return -np.sum(t * np.log(y + 1e-7)) / batch_size åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬åœ¨$y$ä¸ŠåŠ äº†ä¸€ä¸ªå¾®å°å€¼ï¼Œé˜²æ­¢å‡ºç°np.log(0)çš„æƒ…å†µï¼Œå› ä¸ºnp.log(0)ä¼šå˜æˆè´Ÿæ— ç©·å¤§-infï¼Œä»è€Œå¯¼è‡´åç»­çš„è®¡ç®—æ— æ³•ç»§ç»­è¿›è¡Œã€‚åœ¨ç­‰å¼2ä¸­$y_{nk}$ä¸$t_{nk}$ä¸‹æ ‡ç›¸åŒï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥ä½¿ç”¨*åšelement-wiseè¿ç®—ï¼Œå³å¯¹åº”å…ƒç´ ç›¸ä¹˜ã€‚\nä½†å½“æˆ‘ä»¬å¸Œæœ›åŒæ—¶èƒ½å¤Ÿå¤„ç†å•ä¸ªæ•°æ®å’Œæ‰¹é‡æ•°æ®æ—¶ï¼Œä»£ç å—1è¿˜ä¸èƒ½æ»¡è¶³æˆ‘ä»¬çš„è¦æ±‚ã€‚å› ä¸ºå½“$N=1$æ—¶ï¼Œ$y$æ˜¯ä¸€ä¸ªåŒ…å«10ä¸ªå…ƒç´ çš„ä¸€ç»´å‘é‡ï¼Œè¾“å…¥åˆ°å‡½æ•°ä¸­ï¼Œbatch_sizeå°†ç­‰äº10è€Œä¸æ˜¯1ï¼Œäºæ˜¯æˆ‘ä»¬å°†ä»£ç å—1è¿›è¡Œè¿›ä¸€æ­¥å®Œå–„ï¼Œå¦‚ä¸‹ï¼š\ndef cross_entropy_error(y,t): if y.ndim == 1: y = y.reshape(1,y.size) t = t.reshape(1,t.size) batch_size = y.shape[0] return -np.sum(t * np.log(y + 1e-7)) / batch_size æœ€åï¼Œæ¥è®¨è®ºä¸€ä¸‹$t_{nk}$ä¸ºéone-hotè¡¨ç¤ºçš„æƒ…å†µã€‚åœ¨one-hotæƒ…å†µçš„è®¡ç®—ä¸­ï¼Œtä¸º0çš„å…ƒç´ cross-entropy errorä¹Ÿä¸º0ï¼Œæ‰€ä»¥å¯¹äºè¿™äº›å…ƒç´ çš„è®¡ç®—å¯ä»¥å¿½ç•¥ã€‚æ¢è¨€ä¹‹ï¼Œåœ¨éone-hotè¡¨ç¤ºçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªéœ€è¦è®¡ç®—æ­£ç¡®è§£æ ‡ç­¾çš„äº¤å‰ç†µè¯¯å·®å³å¯ã€‚ä»£ç å¦‚ä¸‹ï¼š\ndef cross_entropy_error(y,t): if y.ndim == 1: y = y.reshape(1,y.size) t = t.reshape(1,t.size) batch_size = y.shape[0] return -np.sum(1 * np.log(y[np.arange(batch_size),t]+1e-7))/batch_size åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œy[np.arange(batch_size),t]è¡¨ç¤ºå°†ä»ç¥ç»ç½‘ç»œçš„è¾“å‡ºä¸­æŠ½å‡ºä¸æ­£ç¡®è§£æ ‡ç­¾ç›¸å¯¹åº”çš„å…ƒç´ ã€‚\nç»“è¯­ åœ¨å†™è¿™ç¯‡åšæ–‡çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ„Ÿè§‰è‡ªå·±å…¶å®å’Œmachine learningè¿˜éš”ç€ä¸€å±‚çº¸çª—ï¼Œéœ€è¦é€šè¿‡æ•°å­¦æ…ç ´ï¼Œä¸è¿‡ï¼Œè¿™ä»¶äº‹æˆ‘æƒ³æ”¾åœ¨å‡æœŸæ¥åšï¼Œåšæ¯•è®¾è¦ç´§T_Tã€‚æ­¤å¤–ï¼Œç¨‹åºè®¾è®¡èƒ½åŠ›è¿˜éœ€è¦æé«˜å‘€~0.0bb\nå‚è€ƒæ–‡çŒ® [1] æ·±åº¦å­¦ä¹ å…¥é—¨\n[2] DeepLearning.aiæ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°\n[3] ç»Ÿè®¡å­¦ä¹ æ–¹æ³•\n","title":"Learning with Mini-Batch","uri":"/posts/learning-with-minibbatch/"},{"content":"å…³äºæˆ‘ï¼ˆAbout meï¼‰ æˆ‘å« è’‹æ˜“è€• ï¼Œyigeng æ˜¯æˆ‘åœ¨ç½‘ä¸Šçš„æ˜µç§°ã€‚2022å¹´æ¨å…è‡³å¦é—¨å¤§å­¦MACå®éªŒå®¤æ”»è¯»äººå·¥æ™ºèƒ½ç¡•å£«ï¼Œæˆ‘çš„ç ”ç©¶æ–¹å‘æ˜¯LLM Agentã€‚AI ä½œä¸ºæ•°å­¦ã€è®¡ç®—æœºã€ç”Ÿç‰©ç­‰å­¦ç§‘çš„äº¤é›†ï¼Œæˆ‘è§‰å¾—è¿™äº›éƒ½æ˜¯å¾ˆæœ‰è¶£ä¸”å…·æœ‰ç¾æ„Ÿçš„ä¸œè¥¿ã€‚\nMy name is Yigeng Jiang, and yigeng is my nickname on the Internet.In 2022, I was admitted to Media Analytics and Computing Lab, Xiamen University to pursue a masterâ€™s degree in artificial intelligence without entrance examination. My research interests are in automatic machine learning and model compression related areas. As the intersection of mathematics, computer science, biology and other disciplines, I think AI is very interesting and beautiful.\nå­¦ä¹ ä¹‹å¤–ï¼Œæˆ‘çƒ­çˆ±è¿åŠ¨å’Œé˜…è¯»ã€‚è¿åŠ¨èƒ½å¤Ÿä½¿æˆ‘æ›´åŠ ä¸“æ³¨ä¸”æé«˜å›¢é˜Ÿåä½œèƒ½åŠ›ã€‚é™¤äº†çœ‹ä¸ç ”ç©¶ç›¸å…³çš„ä¹¦ï¼Œæˆ‘ä¸»è¦çˆ±çœ‹ä¸€äº›å†å²ã€å“²å­¦ã€æ–‡å­¦ç­‰æ–¹é¢çš„ä¹¦ã€‚è¯»è¿™äº›ä¹¦èƒ½å¤Ÿä½¿æˆ‘æœ‰åˆ«äºè‡ªç„¶ç§‘å­¦çš„è§’åº¦ï¼Œæ›´å…¨é¢åœ°è®¤è¯†è¿™ä¸ªä¸–ç•Œã€‚\nBesides studying, I love sports and reading. Sports can make me more focused and improve my teamwork skills. In addition to reading books related to research, I mainly enjoy reading literature, history, philosophy and other subjects. Reading these books can give me a different perspective from natural sciences and help me understand the world more comprehensively.\nå½“æˆ‘æ¯”è¾ƒæœ‰ç©ºçš„æ—¶å€™ï¼Œæˆ‘è¿˜ä¼šå»æ—…æ¸¸ã€çœ‹å±•ã€å¬éŸ³ä¹ä¼šã€‚ä¸­å›½æœ‰å¥å¤è¯â€œè¯»ä¸‡å·ä¹¦ï¼Œè¡Œä¸‡é‡Œè·¯â€ï¼Œæ—…æ¸¸è®©æˆ‘æ„Ÿåˆ°è¿™ä¸ªä¸–ç•Œçš„ä¸°å¯Œå¤šå½©ï¼Œå­¦åˆ°å¾ˆå¤šä¹¦é‡Œå­¦ä¸åˆ°çš„ã€‚çœ‹å±•è§ˆä¸å¬éŸ³ä¹ä¼šæ˜¯å› ä¸ºæˆ‘å¯¹äºäººæ–‡è‰ºæœ¯å¾ˆæœ‰å…´è¶£ï¼Œè‰ºæœ¯å’Œç§‘å­¦ä¸€æ ·éƒ½æ˜¯å¾ˆç¾çš„ã€‚\nWhen I am free, I like to travel or visit exhibitions. There is an ancient Chinese saying that goes â€˜Read ten thousand books and travel ten thousand milesâ€™. Travel makes me feel that the world is rich and colorful. I have learned a lot of things that can not be learned in books. I also enjoy visiting exhibitions because I am very interested in humanities and arts. Art, like science, is beautiful.\nå¯¹äº†ï¼Œæˆ‘è¿˜å¾ˆå–œæ¬¢ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–ã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œä¸­å›½å¤ä»£çš„æ–‡äººå£«å¤§å¤«å’Œè¿‘ç°ä»£çš„ç§‘å­¦å®¶éƒ½æœ‰ä¸€ç§åˆ«æ ·é£éª¨ã€‚ç‹å°æ³¢å†™è¿‡ä¸€æœ¬ä¹¦å«ä½œã€Šæˆ‘çš„ç²¾ç¥å®¶å›­ã€‹ï¼Œè€Œä¼ ç»Ÿæ–‡åŒ–å’Œè‡ªç„¶ç§‘å­¦åˆ™å…±åŒæ„å»ºäº†å±äºæˆ‘è‡ªå·±çš„ç²¾ç¥å®¶å›­ã€‚\nBy the way, I also like Chinese traditional culture. In my opinion, ancient Chinese literati scholars and modern scientists have their own unique style. Wang Xiaobo wrote a book called â€œMy Spiritual Homeâ€, while Chinese traditional culture and natural sciences together build my own spiritual home.\nCONTACT I do not use Instant Messenger very often, the most convenient way to contact me is sending me an email.\nEmail: yigengjiang@gmail.com\nå…¶ä»–é“¾æ¥ çŸ¥ä¹ è±†ç“£ åšå®¢å›­ ","title":"About","uri":"/about/"},{"content":"The searching is performed via fuse.js. For the search keywords, white spaces act as the AND operator, and | acts as the OR operator. To match an exact phrase, double quote it. For example, R Markdown matches articles that contain both R and Markdown, R | Markdown matches articles that contain R or Markdown, and \"R Markdown\" matches articles that contain the whole phrase R Markdown.\n","title":"Search","uri":"/search/"}]
